[{"title":"读书笔记-送魂婆","date":"2017-12-17T13:58:41.000Z","path":"2017/12/17/读书笔记-送魂婆/","text":"《送魂婆》 意大利 米凯拉 穆尔嘉 Accabadora Michela Murgia 关于死亡的故事。 故事性很好，也有异域的神秘气息承载神的旨意是需要勇气的，也是值得尊敬的生命和死亡同等重要对生命的尊重，不仅体现在生命的带来，还体现在生命的结束 有些想法是猫头鹰的眼睛，它们受不了白天的光照，只能在晚上出现，和月亮一样，他们的作用是在灵魂的这个隐蔽的角落，让情绪潮起潮落。波纳莉亚有不少这样的想法，多年来，她学会了控制它们，耐心选择可以让它们浮现的夜晚。当他带着尼克拉沉重呼吸的重负，离开巴斯迪家时，她哭的不多，但每滴泪水都在这久经沧桑的送魂魄的脸上刻下了一道新的沟痕。此时如果太阳升起，就能看到波纳莉亚比实际年龄苍老许多，而所有这些年龄，她能确切地感受到他们的重量。从她第一次目睹临终病人如愿以偿地求得安息的那天起，数十年过去了，但她能肯定，在当时和以后的岁月里，没有哪次有此次这般沉重，就仿佛湿透了的披风搭在肩头似的。","categories":[{"name":"随笔","slug":"随笔","permalink":"http://www.sillystone.info/categories/随笔/"}],"tags":[{"name":"读书笔记","slug":"读书笔记","permalink":"http://www.sillystone.info/tags/读书笔记/"},{"name":"外国文学","slug":"外国文学","permalink":"http://www.sillystone.info/tags/外国文学/"}]},{"title":"tcpdump 使用","date":"2017-12-13T09:48:29.000Z","path":"2017/12/13/tcpdump-使用/","text":"tcpdump -XvvennSs 0 -i eth0 tcp[20:2]=0x4745 or tcp[20:2]=0x48540x4745 为”GET”前两个字母”GE”0x4854 为”HTTP”前两个字母”HT” tcpdump -i eth0 -X -n -s 0 tcp dst port 9080 and src host ! 22.5.231.132 命令行格式：tcpdump [ -adeflnNOpqStvx ] [ -c 数量 ] [ -F 文件名 ][ -i 网络接口 ] [ -r 文件名] [ -s snaplen ][ -T 类型 ] [ -w 文件名 ] [表达式 ] 参数-i eth0 网卡-X 以16进制与ASCII方式输出，即可读方式显示数据包，适合http、memcached ascii等明文传输的协议，可以看到内容-s 从每个分组中读取最开始的snaplen个字节，而不是默认的68个字节。-s 0表示不限制长度，输出整个包-n 不把网络地址转换成名字-c 在收到指定的包的数目后，tcpdump就会停止； 常用表达式：关于类型的关键字，主要包括host，net，port传输方向的关键字，主要包括src , dst ,dst or src, dst and src协议的关键字，主要包括fddi,ip ,arp,rarp,tcp,udp等类型逻辑运算，取非运算是 ‘not ‘ ‘! ‘, 与运算是’and’,’&amp;&amp;’;或运算 是’or’ ,’||’其他重要的关键字如下：gateway, broadcast,less,greater 抓取http包数据指定文件进行输出packagetcpdump tcp port 80 -n -s 0 -w /tmp/tcp.cap 对应的/tmp/tcp.cap基本靠肉眼已经能看一下信息，比如http Header , content信息等 mod_proxy反向代理抓包线上服务器apache+jetty，通过apache mod_proxy进行一个反向代理，80 apache端口, 7001 jetty端口 apache端口数据抓包： tcpdump tcp port 80 -n -s 0 -X -i eth0 注意：指定eth0网络接口 jetty端口数据抓包： tcpdump tcp port 7001 -n -s 0 -X -i lo 注意：指定Loopback网络接口","categories":[{"name":"技术","slug":"技术","permalink":"http://www.sillystone.info/categories/技术/"}],"tags":[{"name":"linux命令","slug":"linux命令","permalink":"http://www.sillystone.info/tags/linux命令/"},{"name":"网络","slug":"网络","permalink":"http://www.sillystone.info/tags/网络/"}]},{"title":"项目总结","date":"2017-12-13T07:09:41.000Z","path":"2017/12/13/项目总结/","text":"背景介绍负责的项目上线一个多月，系统已经基本稳定，最近得闲做了简单总结今天组织相关人员讲了一下，大家还是很认可。PPT修改了两版，真的是费时费力，写PPT的能力有待提高。 总结概要第一部分 整体介绍 从项目功能角度描述项目亮点和特点 介绍系统拆分的过程，和最终结果。展示出新系统的特点–服务拆分，系统增多 介绍技术上的层级结构和其中使用的关键技术 第二部分 问题分析 从项目的实施和最终的形态，引出服务拆分–服务化 介绍服务拆分背景和原因 介绍服务拆分的方法 介绍服务拆分引起的问题： 数据关联查询 分布式事务 服务稳定性的相关问题和措施 服务性能和容量问题以及相关的要点，解决的思路 微服务的整体架构框架介绍：主要包括服务注册，devops，熔断机制，RPC，和异步组件，日志监控组件，API Gate介绍 第三部分 总结和工作 架构演进的思路 新技术使用的三个层级： 能用 好用 用好 实施的建议：持续优化 调整 附：文件PPT文档","categories":[{"name":"技术","slug":"技术","permalink":"http://www.sillystone.info/categories/技术/"}],"tags":[{"name":"技术架构","slug":"技术架构","permalink":"http://www.sillystone.info/tags/技术架构/"},{"name":"微服务","slug":"微服务","permalink":"http://www.sillystone.info/tags/微服务/"},{"name":"总结","slug":"总结","permalink":"http://www.sillystone.info/tags/总结/"}]},{"title":"负载均衡LVS nginx haproxy","date":"2017-11-28T06:37:03.000Z","path":"2017/11/28/负载均衡LVS-nginx-haproxy/","text":"lvs、haproxy、nginx 负载均衡的比较分析 应用实例门户网站: 使用F5硬件负载内部管理系统：使用nginx/ IBM Http Server内部通用支撑系统： LVS + nginx 以下为文摘对软件实现负载均衡的几个软件，小D详细看了一下，从性能和稳定上还是LVS最牛，基本达到了F5硬件设备的60%性能，其他几个10%都有点困难。 不过就因为LVS忒牛了，配置也最麻烦了，而且健康检测需要另外配置Ldirector，其他HAPROXY和NGINX自己就用，而且配置超级简单。 所以小D建议，如果网站访问量不是门户级别的用HAPROXY或者NGINX就OK了，到了门户级别在用LVS+Idirector吧 哈哈 lvs和nginx都可以用作多机负载的方案，它们各有优缺，在生产环境中需要好好分析实际情况并加以利用。 首先提醒，做技术切不可人云亦云，我云即你云；同时也不可太趋向保守，过于相信旧有方式而等别人来帮你做垫被测试。把所有即时听说到的好东西加以钻研，从而提高自己对技术的认知和水平，乃是一个好习惯。 下面来分析一下两者： 一、lvs的优势： 1、抗负载能力强，因为lvs工作方式的逻辑是非常之简单，而且工作在网络4层仅做请求分发之用，没有流量，所以在效率上基本不需要太过考虑。在我手里的 lvs，仅仅出过一次问题：在并发最高的一小段时间内均衡器出现丢包现象，据分析为网络问题，即网卡或linux2.4内核的承载能力已到上限，内存和 cpu方面基本无消耗。 2、配置性低，这通常是一大劣势，但同时也是一大优势，因为没有太多可配置的选项，所以除了增减服务器，并不需要经常去触碰它，大大减少了人为出错的几率。 3、工作稳定，因为其本身抗负载能力很强，所以稳定性高也是顺理成章，另外各种lvs都有完整的双机热备方案，所以一点不用担心均衡器本身会出什么问题，节点出现故障的话，lvs会自动判别，所以系统整体是非常稳定的。 4、无流量，上面已经有所提及了。lvs仅仅分发请求，而流量并不从它本身出去，所以可以利用它这点来做一些线路分流之用。没有流量同时也保住了均衡器的IO性能不会受到大流量的影响。 5、基本上能支持所有应用，因为lvs工作在4层，所以它可以对几乎所有应用做负载均衡，包括http、数据库、聊天室等等。 另：lvs也不是完全能判别节点故障的，譬如在wlc分配方式下，集群里有一个节点没有配置VIP，会使整个集群不能使用，这时使用wrr分配方式则会丢掉一台机。目前这个问题还在进一步测试中。所以，用lvs也得多多当心为妙。 二、nginx和lvs作对比的结果 1、nginx工作在网络的7层，所以它可以针对http应用本身来做分流策略，比如针对域名、目录结构等，相比之下lvs并不具备这样的功能，所以 nginx单凭这点可利用的场合就远多于lvs了；但nginx有用的这些功能使其可调整度要高于lvs，所以经常要去触碰触碰，由lvs的第2条优点 看，触碰多了，人为出问题的几率也就会大。 2、nginx对网络的依赖较小，理论上只要ping得通，网页访问正常，nginx就能连得通，nginx同时还能区分内外网，如果是同时拥有内外网的 节点，就相当于单机拥有了备份线路；lvs就比较依赖于网络环境，目前来看服务器在同一网段内并且lvs使用direct方式分流，效果较能得到保证。另 外注意，lvs需要向托管商至少申请多一个ip来做Visual IP，貌似是不能用本身的IP来做VIP的。要做好LVS管理员，确实得跟进学习很多有关网络通信方面的知识，就不再是一个HTTP那么简单了。 3、nginx安装和配置比较简单，测试起来也很方便，因为它基本能把错误用日志打印出来。lvs的安装和配置、测试就要花比较长的时间了，因为同上所述，lvs对网络依赖比较大，很多时候不能配置成功都是因为网络问题而不是配置问题，出了问题要解决也相应的会麻烦得多。 4、nginx也同样能承受很高负载且稳定，但负载度和稳定度差lvs还有几个等级：nginx处理所有流量所以受限于机器IO和配置；本身的bug也还是难以避免的；nginx没有现成的双机热备方案，所以跑在单机上还是风险较大，单机上的事情全都很难说。 5、nginx可以检测到服务器内部的故障，比如根据服务器处理网页返回的状态码、超时等等，并且会把返回错误的请求重新提交到另一个节点。目前lvs中 ldirectd也能支持针对服务器内部的情况来监控，但lvs的原理使其不能重发请求。重发请求这点，譬如用户正在上传一个文件，而处理该上传的节点刚 好在上传过程中出现故障，nginx会把上传切到另一台服务器重新处理，而lvs就直接断掉了，如果是上传一个很大的文件或者很重要的文件的话，用户可能 会因此而恼火。 6、nginx对请求的异步处理可以帮助节点服务器减轻负载，假如使用apache直接对外服务，那么出现很多的窄带链接时apache服务器将会占用大 量内存而不能释放，使用多一个nginx做apache代理的话，这些窄带链接会被nginx挡住，apache上就不会堆积过多的请求，这样就减少了相 当多的内存占用。这点使用squid也有相同的作用，即使squid本身配置为不缓存，对apache还是有很大帮助的。lvs没有这些功能，也就无法能 比较。 7、nginx能支持http和email（email的功能估计比较少人用），lvs所支持的应用在这点上会比nginx更多。 在使用上，一般最前端所采取的策略应是lvs，也就是DNS的指向应为lvs均衡器，lvs的优点令它非常适合做这个任务。 重要的ip地址，最好交由lvs托管，比如数据库的ip、webservice服务器的ip等等，这些ip地址随着时间推移，使用面会越来越大，如果更换ip则故障会接踵而至。所以将这些重要ip交给lvs托管是最为稳妥的，这样做的唯一缺点是需要的VIP数量会比较多。 nginx可作为lvs节点机器使用，一是可以利用nginx的功能，二是可以利用nginx的性能。当然这一层面也可以直接使用squid，squid的功能方面就比nginx弱不少了，性能上也有所逊色于nginx。 nginx也可作为中层代理使用，这一层面nginx基本上无对手，唯一可以撼动nginx的就只有lighttpd了，不过lighttpd目前还没有 能做到nginx完全的功能，配置也不那么清晰易读。另外，中层代理的IP也是重要的，所以中层代理也拥有一个VIP和lvs是最完美的方案了。 nginx也可作为网页静态服务器，不过超出了本文讨论的范畴，简单提一下。 具体的应用还得具体分析，如果是比较小的网站（日PV&lt;1000万），用nginx就完全可以了，如果机器也不少，可以用DNS轮询，lvs所耗费的机器还是比较多的；大型网站或者重要的服务，机器不发愁的时候，要多多考虑利用lvs。 Nginx的优点:性能好，可以负载超过1万的并发。功能多，除了负载均衡，还能作Web服务器，而且可以通过Geo模块来实现流量分配。社区活跃，第三方补丁和模块很多支持gzip proxy缺点:不支持session保持。对后端realserver的健康检查功能效果不好。而且只支持通过端口来检测，不支持通过url来检测。nginx对big request header的支持不是很好，如果client_header_buffer_size设置的比较小，就会返回400bad request页面。Haproxy的优点:它的优点正好可以补充nginx的缺点。支持session保持，同时支持通过获取指定的url来检测后端服务器的状态。支持tcp模式的负载均衡。比如可以给mysql的从服务器集群和邮件服务器做负载均衡。缺点：不支持虚拟主机(这个很傻啊)目前没有nagios和cacti的性能监控模板LVS的优点:性能好，接近硬件设备的网络吞吐和连接负载能力。LVS的DR模式，支持通过广域网进行负载均衡。这个其他任何负载均衡软件目前都不具备。缺点：比较重型。另外社区不如nginx活跃。 现在网络中常见的的负载均衡主要分为两种：一种是通过硬件来进行进行，常见的硬件有比较昂贵的NetScaler、F5、Radware和Array等商用的负载均衡器，也有类似于LVS、Nginx、HAproxy的基于Linux的开源的负载均衡策略,商用负载均衡里面NetScaler从效果上比F5的效率上更高。对于负载均衡器来说，不过商用负载均衡由于可以建立在四~七层协议之上，因此适用 面更广所以有其不可替代性，他的优点就是有专业的维护团队来对这些服务进行维护、缺点就是花销太大，所以对于规模较小的网络服务来说暂时还没有需要使用。另一种负载均衡的方式是通过软件：比较常见的有LVS、Nginx、HAproxy等，其中LVS是建立在四层协议上面的，而另外Nginx和HAproxy是建立在七层协议之上的，下面分别介绍关于LVS：使用集群技术和Linux操作系统实现一个高性能、高可用的服务器，它具有很好的可伸缩性（Scalability）、可靠性（Reliability）和可管理性（Manageability）。LVS的特点是：1、抗负载能力强、是工作在网络4层之上仅作分发之用，没有流量的产生；2、配置性比较低，这是一个缺点也是一个优点，因为没有可太多配置的东西，所以并不需要太多接触，大大减少了人为出错的几率；3、工作稳定，自身有完整的双机热备方案；4、无流量，保证了均衡器IO的性能不会收到大流量的影响；5、应用范围比较广，可以对所有应用做负载均衡；6、LVS需要向IDC多申请一个IP来做Visual IP，因此需要一定的网络知识，所以对操作人的要求比较高。Nginx的特点是：1、工作在网络的7层之上，可以针对http应用做一些分流的策略，比如针对域名、目录结构；2、Nginx对网络的依赖比较小；3、Nginx安装和配置比较简单，测试起来比较方便；4、也可以承担高的负载压力且稳定，一般能支撑超过1万次的并发；5、Nginx可以通过端口检测到服务器内部的故障，比如根据服务器处理网页返回的状态码、超时等等，并且会把返回错误的请求重新提交到另一个节点，不过其中缺点就是不支持url来检测；6、Nginx对请求的异步处理可以帮助节点服务器减轻负载；7、Nginx能支持http和Email，这样就在适用范围上面小很多；8、不支持Session的保持、对Big request header的支持不是很好，另外默认的只有Round-robin和IP-hash两种负载均衡算法。HAProxy的特点是：1、HAProxy是工作在网络7层之上。2、能够补充Nginx的一些缺点比如Session的保持，Cookie的引导等工作3、支持url检测后端的服务器出问题的检测会有很好的帮助。4、更多的负载均衡策略比如：动态加权轮循(Dynamic Round Robin)，加权源地址哈希(Weighted Source Hash)，加权URL哈希和加权参数哈希(Weighted Parameter Hash)已经实现5、单纯从效率上来讲HAProxy更会比Nginx有更出色的负载均衡速度。6、HAProxy可以对Mysql进行负载均衡，对后端的DB节点进行检测和负载均衡。 现在网站发展的趋势对网络负载均衡的使用是随着网站规模的提升根据不同的阶段来使用不同的技术：第一阶段：利用Nginx或者HAProxy进行单点的负载均衡，这一阶段服务器规模刚脱离开单服务器、单数据库的模式，需要一定的负载均衡，但是 仍然规模较小没有专业的维护团队来进行维护，也没有需要进行大规模的网站部署。这样利用Nginx或者HAproxy就是第一选择，此时这些东西上手快， 配置容易，在七层之上利用HTTP协议就可以。这时是第一选择第二阶段：随着网络服务进一步扩大，这时单点的Nginx已经不能满足，这时使用LVS或者商用F5就是首要选择，Nginx此时就作为LVS或者 F5的节点来使用，具体LVS或者F5的是选择是根据公司规模，人才以及资金能力来选择的，这里也不做详谈，但是一般来说这阶段相关人才跟不上业务的提 升，所以购买商业负载均衡已经成为了必经之路。第三阶段：这时网络服务已经成为主流产品，此时随着公司知名度也进一步扩展，相关人才的能力以及数量也随之提升，这时无论从开发适合自身产品的定制，以及降低成本来讲开源的LVS，已经成为首选，这时LVS会成为主流。最终形成比较理想的状态为：F5/LVS&lt;—&gt;Haproxy&lt;—&gt;Squid/Varnish&lt;—&gt;AppServer。","categories":[{"name":"技术","slug":"技术","permalink":"http://www.sillystone.info/categories/技术/"}],"tags":[{"name":"负载均衡","slug":"负载均衡","permalink":"http://www.sillystone.info/tags/负载均衡/"}]},{"title":"面包和汤和猫咪 好天气","date":"2017-11-26T10:58:40.000Z","path":"2017/11/26/面包和汤和猫咪-好天气/","text":"作者： 群阳子 应该算是女性小说吧， 搜了一下，居然已经拍了电视剧 一个人， 一只猫， 一家小店，简单食谱 不是讲故事 只是介绍一种生活 简单，绿色，原味， 淳朴，体验自然 看的很快想开家店好吧，明天还要上班。。。。。。。","categories":[{"name":"随笔","slug":"随笔","permalink":"http://www.sillystone.info/categories/随笔/"}],"tags":[{"name":"读书笔记","slug":"读书笔记","permalink":"http://www.sillystone.info/tags/读书笔记/"}]},{"title":"妥协的完美主义-产品经理实践","date":"2017-11-26T07:59:03.000Z","path":"2017/11/26/妥协的完美主义-产品经理实践/","text":"产品设计项目管理项目阶段：立项-&gt; 概念 计划 开发 验证 发布 关闭 项目组织准备阶段：从资源技术组织等多方面评估和准备，项目立项计划书项目概念阶段： 初步的项目计划，，完成设计需求和备选需求项目计划阶段： 详细的项目计划， 架构设计和概要设计开发阶段： 执行项目计划， demo开发项目验证阶段: 执行项目计划，完成可用性评估和beta测试项目发布阶段： 执行项目计划，完成交付和维护支持项目关闭阶段：完成项目总结，关闭 项目文档化（输入，输出，模型，相关影响分析），规范化 产品设计团队能力需求有效识别用户需求的能力： 需求和解决方案:提出需求的目标和动机，需求是否合理，对产品有无帮助 认清目标：重塑和分解需求的能力收集资料和整理数据的能力提高专业素养和沟通协调能力 需求分析的工作方法功能定位: 四象图紧急/重要期望值和边界值 重要功能确认： 卡片法用户研究的工作方法用户建模的过程：从用户收集数据-&gt; 把信息建立模型-&gt; 分析设计方案-&gt; 根据设计方案实施开发项目 用户使用轨迹分析服务器日志，客户端（APP）获取 指标： 总体性指标： 使用总量，时间分布，内容分布单流程统计: 重点流程监控（购物车-&gt;付款）单用户统计： 典型用户使用路径，使用次数，频率，停留总时间路径分析 关键词 勾画典型用户新手 专家 和中间用户竞品和市场分析分析维度： 市场趋势和业内现状竞争对手的产品定位和企业期待目标用户是否一致，是否有差异核心功能，核心竞争力，盈利模式对比交互设计 流程 页面的对比产品各自的优缺点运营 渠道 和推广 策略等方面的比较可以吸收借鉴 和总结 交互设计的共工作方法视觉界面设计的工作方法界面视觉元素：形状 尺寸 颜色 纹理 情感化设计Emotional Design本能设计（关注外形和视觉效果）行为设计（使用乐趣和效率）反思设计（产品合理化理智化） 可用性评估经验值： 7+2 原则导航菜单选项数据通常最多为7 2秒规则响应时间2秒内 3次点击3次点击可以找到所需信息，强调导航的清晰 8/2法则交互设计的八大法则尽量保持一致性让熟手用户使用快捷键提供信息化反馈设计对话框提示结束提供简易错误处理允许简单的恢复操作提供控制的感觉减少短时记忆载入 倒金字塔无视横幅广告产品优化的减法","categories":[{"name":"技术","slug":"技术","permalink":"http://www.sillystone.info/categories/技术/"}],"tags":[{"name":"书摘","slug":"书摘","permalink":"http://www.sillystone.info/tags/书摘/"},{"name":"产品设计","slug":"产品设计","permalink":"http://www.sillystone.info/tags/产品设计/"}]},{"title":"IHS plugin-cfg best pratices","date":"2017-11-22T12:18:43.000Z","path":"2017/11/22/IHS-plugin-cfg-best-pratices/","text":"reference from IBM web best pratices for IBM plugin-cfg.xml , include: MaxConnectionsLoadBalanceWeightConnectTimeoutServerIOTimeout QuestionIn the web server plug-in, what do the LoadBalanceWeight, MaxConnections, ConnectTimeout, ServerIOTimeout, RetryInterval, IgnoreAffinityRequests, and GetDWLMTable options mean and what are the recommended settings for these options? What affect does Session Affinity have? How are connections handled during plug-in fail-over? What is the effect of using more than one web server child process?Answer AnswerTo understand how load balancing works in the web server plug-in, see Understanding IBM HTTP Server plug-in Load Balancing in a clustered environment. To understand how fail-over works in the web server plug-in, see Understanding HTTP plug-in failover in a clustered environment. LoadBalanceWeightis a starting “weight”. The value is dynamically changed by the plug-in during runtime. The “weight” of a server (or clone) is lowered each time a request is assigned to that clone. When all weights for all servers drop to 0 or below, the plug-in has to readjust all of the weights so that they are above 0. Using a starting value of only 2 (default), means that the weights will get to 0 very quickly and the plug-in will constantly be readjusting the weights. Therefore, It is recommended to start with a higher LoadBalanceWeight. The IBM WebSphere Application Server administrative console will allow a value up to 20 for this. However, it is certainly possible to manually edit the plugin-cfg.xml file and specify some other value for LoadBalanceWeight that is higher than 20. Note: At runtime, the LoadBalanceWeight of each appserver in a cluster are normalized by their highest common factor. For example, 100, 90, 80 have a common factor of 10. So, these configured weights would be divided by 10 at runtime, resulting in actual starting weights of only 10, 9, 8. Setting all clones to the same starting LoadBalanceWeight (for example: 20, 20, 20) will result in an actual starting weight of only 1 for each, because of normalization. So, it is recommended to set the weight of at least one of the clones to be off by a value of 1. For example, if there are 3 clones, you might choose the starting LoadBalanceWeights to be: 20, 20, 19. After normalization the weights will be unchanged.Recommended values = all clones the same, except one clone off by one (for example: 20, 20, 19) MaxConnectionsis used to gauge when a server is “starting to become overwhelmed”. It is not used to determine when to fail-over (mark the server “down”). When a request is sent from the plug-in to the WAS appserver, it is called a “PendingRequest”, until the response comes back. If the application running in WebSphere Application Server is handling requests quickly, each request will only be PENDING for a very short time. So, under ideal conditions, MaxConnections is not needed and therefore the default is (-1) meaning unlimited. However, sometimes an application may start to become overwhelmed and the application may not be able to handle the requests as quickly. Consequently Pending Requests start to build up. MaxConnections can be used to put a limit on the number of PENDING requests per server. When the MaxConnections limit is reached, the plug-in will stop sending requests to that appserver, but it is not marked down. The optimal value for MaxConnections will depend on how quickly the application and appserver respond to each request. If normal responses are returned in less than one second, it may be appropriate to set a low value for MaxConnections, like 20 or so. However, if it normally takes several seconds to get a response from the application, then it would be prudent to use a higher value for MaxConnections, like 100. Please note that if the MaxConnections limit has been reached the plug-in will not send ANY more requests to that server until responses come back for the current PENDING requests, and the pendingRequests count drops back down below the MaxConnections limit.Recommended value = 20 - 100 depending on application response times *Best Practices: with MaxConnections=”-1” use LogLevel=”Stats” to monitor the pendingRequests numbers in the plug-in log, under normal conditions. Then, choose a value for MaxConnections that is significantly higher than the highest number shown in the log. This method will help you to determine a MaxConnections value that is right for your specific environment. ConnectTimeout means“how long should the plug-in wait when trying to open a socket to the Application Server”? If there are streams already open and available to the Application Server, the plug-in will use one of those. However, sometimes the plug-in needs to open a new stream to the Application Server. That should not take very long, so the value for ConnectTimeout should be very small. A ConnectTimeout value of 0 means never time-out. In that case, the time-out is left up to the OS TCP layer, which is NOT ideal. It is much better to specify a small positive number (like 5 seconds).Recommended value = 5 ServerIOTimeoutmeans “how long should the plug-in wait for a response from the application”. After the socket is opened, the plug-in sends the request to the Application Server. The application processes the request and a response is sent back to the client, through the plug-in. How long should that take? What is reasonable, based on the application? There is no single correct answer here. It depends on the application. If the application is very quick to respond, then you can use a lower value for ServerIOTimeout. However, if the application requires more time to process the request (maybe to retrieve data from a database), then you should use a higher number for ServerIOTimeout. Using a value of 0 means that the plug-in will NOT time-out the request. This is often NOT ideal. A positive value means that the plug-in will NOT mark the appserver down after a ServerIOTimeout pops. So, if you want the plug-in to continue sending requests to the timed-out appserver, use a positive value. On the other hand, a negative value means that the plug-in WILL mark the appserver down after a ServerIOTimeout pops. So, if you want the plug-in to immediately mark the appserver down and fail-over to another appserver in the same cluster, use a negative value.Recommended value = -900 (that is negative 900) Note: The ability to use a negative ServerIOTimeout value was introduced in plug-in apar PK72097. *Best Practices: use traces to determine the amount of time it takes for your application to respond to requests under normal conditions. Be sure to include the longest running requests that take the most time to respond. Then choose a value for ServerIOTimeout that is much larger (2X or 3X or more) than the longest response time. This method will ensure that your ServerIOTimeout is high enough to allow adequate time for the application to respond normally. Make it a negative value so that if the ServerIOTimeout pops, the plug-in will immediately mark the server down, and retry the request to a different appserver. ServerIOTimeoutRetrycan be used to decrease the number of retries after ServerIOTimeout has fired. By default, the Plug-in will try a request equal to the number of members in the cluster. For example, if the cluster has four members, and there is a ServerIOTimeout, the Plug-in will try it a second time. If the retry fails with ServerIOTimeout fired, then it will try a third time, and a fourth time if needed. But after four attempts, the Plug-in will give up and stop retrying. If you want to override this default behavior and reduce the number of retries after ServerIOTimeout, you can set ServerIOTimeoutRetry to a value that is less than the number of members in the cluster.Recommended value = -1 (this is the default) Note: This property was introduced by Plug-in apar PM70559. RetryInterval is the time that the plug-in will wait before trying again to use an appserver that was marked down. The optimal value for RetryInterval depends on the number of appservers in the cluster, and the value used for ServerIOTimeout. You can use the following formula to determine the maximum RetryInterval value for your plug-in config: (number of appservers in cluster - 1) x (absolute ServerIOTimeout) - 1 For example, if there are two appservers in the cluster, and the value of ServerIOTimeout is -900, then the maximum RetryInterval setting would be:(2 - 1) x (900) - 1 = 899 seconds or less Another example, if there are four appservers in the cluster, and the value of ServerIOTimeout is -900, then the maximum RetryInterval setting would be:(4 - 1) x (900) -1 = 2699 seconds or less Warning: Setting RetryInterval to a value higher than the recommended maximum, based on the formula above, can lead to an undesirable situation where all of the appservers in the cluster may be marked down simultaneously resulting in all requests temporarily failing.Recommended value = 60 (this is the default) Affinity requests are requests that contain a session cookie (ie. JSESSIONID). The session cookie is set by the Session Manager in WAS to ensure that all subsequent requests from the same client return to the same app server in the cluster. The session cookie contains the clone ID (or partition ID) of that specific app server. The web server Plug-in will look for the session cookie and use the clone ID to send the request to that specific WAS app server. An affinity request is not load balanced. In the plug-in config there is a property called IgnoreAffinityRequests. This property determines if affinity requests will affect the load balance weights, or not. The default value for IgnoreAffinityRequests is True, which means that affinity requests will not have any affect on the load balance weights. This is best for environments where there are no, or few, affinity requests. On the other hand, for an environment with a lot of affinity requests, it may be better to set IgnoreAffinityRequests to False so that the load balance weights will accurately reflect the effect of having a lot of affinity requests. Fail-over occurs when the plug-in marks a cluster member appserver (or clone) as “down”, and then sends the pending requests to other members of the same cluster. This can happen if the plug-in is unable to open a new connection to the appserver within the ConnectTimeout. Or fail-over can happen if the plug-in has already sent the request to the appserver, but does not receive a response from the application within ServerIOTimeout. When the plug-in marks a cluster member appserver “down”, it will handle the PENDING requests in one of two ways: Prior to plug-in apar PM12112, the plug-in would send all of the pending requests to the very next appserver in the cluster. However, after plug-in apar PM12112, the plug-in will randomly send the pending requests to any of the available appservers in the cluster. While the appserver is marked “down” the plug-in will no longer send any requests to it. After RetryInterval the plug-in will check to see if that appserver can be used successfully again. If so, the “down” flag will be removed and the appserver will be used again. Note: By default, the number of attempts to handle a request is limited by the number of appservers in the cluster. For example, if there are only two appservers in the cluster, and the request fails once, the plug-in will only attempt that request one more time (total of two attempts). Or another example, if there are five appservers in the same cluster, and the request fails once, then the plug-in will attempt to retry that same request up to four more times (total of five attempts). That number includes retries sent to the same appserver (session affinity), or attempts sent to different appservers (fail-over). Update: The plug-in apar PM70559 introduced a new setting called “ServerIOTimeoutRetry” that can be used to control the number of retries due to ServerIOTimeout. If Memory-to-Memory (M2M) session replication is enabled in WebSphere Application Server, then the GetDWLMTable setting in the plug-in config must be changed to “true”. Memory-to-Memory replication uses partition IDs rather than clone IDs. This can lead to broken session affinity if GetDWLMTable is set to false (which is the default). So it is very important to set GetDWLMTable=”true” whenever using M2M in WebSphere Application Server.Recommendation = GetDWLMTable=”true” whenever M2M is used in WebSphere Application Server. Each web server child process loads a separate instance of the web server plug-in. And multiple running instances of the web server plug-in do not share information with each other. For example if the IBM HTTP Server web server is configured to start 3 child processes (StartServers 3), then there will be 3 instances of the web server plug-in running (one for each IBM HTTP Server child process). The dynamically changing LoadBalanceWeight of each cluster member is not shared between the plug-in instances. So, in one instance of the plug-in “member1” might be considered UP with a weight of 5, when in another instance of the plug-in “member1” might be considered DOWN and unusable. This can result in possibly different behaviors depending on which child process / plug-in instance handles each incoming request. For this reason it is recommended that you should configure the web server to use only a few web server child processes with many threads on each. See Tuning IBM HTTP Server to maximize the number of client connections to WebSphere Application Server. If you choose to use more than one web server child process, keep in mind that the plug-in settings are handled on a per instance basis. For example, MaxConnections means the number of pending requests that will be allowed on that server, for each plug-in instance. If MaxConnections = 20, and there are 3 web server child processes (3 plug-in instances), then each instance will allow 20 pending connections to that Application Server for a total of 60 pending connections. configIBM webpath: websphere application server -&gt; server11 -&gt; web服务器插件属性(页面最下) -","categories":[{"name":"技术","slug":"技术","permalink":"http://www.sillystone.info/categories/技术/"}],"tags":[{"name":"IBM","slug":"IBM","permalink":"http://www.sillystone.info/tags/IBM/"}]},{"title":"Redis使用总结","date":"2017-11-16T08:34:31.000Z","path":"2017/11/16/Redis使用总结/","text":"Redis数据变更和使用的整体原则： 数据（数据字典数据）以 数据库为准 Redis 作为内存数据库 用以提高系统性能，Redis中的数据可清理，可重新加载。Redis中的数据粒度尽量小，避免存放大对象。 应用对Redis中的数据不强依赖，Redis无返回，支持从数据库读取 数据（数据字典数据）变更： 少量数据变更 原则上通过页面维护，维护后实时更新数据库和Redis大量数据变更/数据导入 可通过数据库导入； 导入后Redis需重新加载数据 Redis中的数据变更： 除清理Redis全部数据可直接操作Redis外； 通过程序 覆盖写Redis程序写Redis方式：a. 全量加载数据（包括覆盖写）： a1: 数据加载耗时：rule_reload参数为true; 集群环境下 使用参数Redis_init_server指定某个server执行加载操作， a2: 数据加载不耗时： 所有服务执行写Redis（重复写）b. 部分加载数据：程序功能支持 Redis数据部分加载","categories":[{"name":"技术","slug":"技术","permalink":"http://www.sillystone.info/categories/技术/"}],"tags":[{"name":"数据库","slug":"数据库","permalink":"http://www.sillystone.info/tags/数据库/"},{"name":"Redis","slug":"Redis","permalink":"http://www.sillystone.info/tags/Redis/"}]},{"title":"The Stories","date":"2017-11-14T15:15:57.000Z","path":"2017/11/14/The-Stories/","text":"每一部小说，都是一个故事好的故事，简单，直接好的作品，不玩辞藻 开始往往是最难的也是作者功力的体现 每个故事是作家的镜子你可以看到他的世界，他的家庭，他的喜恶，他的一切好的作品可以很快带你进入作者的世界 法国作家：《DIEU VOYAGE TOUJOURS INCOGNITO》 by Laurent Gounelle 洛朗 古奈儿《6点27分的朗读者》 日本作家：《斜阳》 1947年 by 太宰治 中国作家：","categories":[{"name":"随笔","slug":"随笔","permalink":"http://www.sillystone.info/categories/随笔/"}],"tags":[{"name":"随笔","slug":"随笔","permalink":"http://www.sillystone.info/tags/随笔/"}]},{"title":"软件设计之道-那些值得借鉴的实践案例","date":"2017-11-14T06:04:11.000Z","path":"2017/11/14/软件设计之道-那些值得借鉴的实践案例/","text":"书摘 工程实践第3章 代码评审代码评审关注点需求理解偏差架构一致性，除正确性以外的其他属性设计思路的盲点，场景缺失接口核对可测试性简洁性后期难以检测的问题 自动化测试的关注点人对计算机运算结果的预期错误逻辑复杂度高的功能容易受影响，需要频繁回归的功能 设计模式创新模式-5， 结构模式-7 行为模式-11 熟练掌握类图，类与类之间的关系掌握每种模式的构成件以及构成件之间的相互关系识别每种模式中稳定部分和变化部分，每种模式应用的场景和局限亲手应用模式，编写代码 DDD领域驱动开发第6 百度外卖物流智能调度数据建模对于多目标动态优化问题，采取逐层建模的方式降低复杂度。降维：通用的参数变量，需要在底层作为基础约束条件经行采集特化：多变的场景变量，在高层作为调优参数进行优化 场景优化：商圈 城市 时段 天气 。价格 –&gt; 场景调参 – 最优配送骑士及路径动态规划：空间开销函数，时间开销，惩罚函数 –&gt; 函数建模 – 多项函数分值约束条件：商户 用户 骑士，订单（起止时间 地点） –&gt; 数据采集 – 试试场景下的约束变量 第7 当当用户画像第8 当当推荐团队机器学习总结： 重视学习模型的同时 重视整体系统 正确认识并充分利用可视化分析工具 算法优势与人工经验知识相结合 重视系统结构，周期性重构 重视团队完整性建设，团队无短板 重视工具和数据的抽象和重用 重视流程，项目推进方法 互联网高可用架构变迁第11 魅族应用商店服务端架构实践第一代架构服务器集群： LVS（双备） -》 nginx -》 jetty使用缓存： 热点数据，高频数据 使用memcache读写分离： 读多写少CDN： 静态文件CDN 微服务架构数据量增加 1000万用户 DB性能问题单服务，并行开发低效 开源产品FASTDFS： 轻量级分布式文件系统，解决大数据量存储和高并发问题Zookeeper：分布式应用程序协调服务，用于服务发现和调度MetaQ: 淘宝java消息中间件RPC： 自研 Kiev框架通信，基于Netty，串行化协议支持Hessian Protobuffer分片：DB， Redis（基于Twemproxy的Redis集群方案， jedis做封装，监控，大Key限制保护）分片和集群 微服务的改变途径业务梳理，减少不必要的跨系统调用业务解耦，功能模块化，服务独立部署开发人员增加，微服务提升效率使用zookeeper实现服务配置中心接入层，服务层，存储层不允许跨层调用 多级缓存到主动缓存业务热点数据，读多写少Task 实现排行，详情数据刷新到Redis访问量大的查询接口，只访问Redis 不访问数据库缓存策略从被动缓存到主动缓存Mysql挂掉不影响用户浏览和下载等主要业务功能添加JVM本地缓存，通过日志统计命中率高90%动态页面静态化为文件，放到CDN引入Android本地缓存，版本号方式验新 数据库分库分表按照当前用户10倍量评估采用分库而非分表用户hash分库一台mysql实例可以同时安装100+数据库数据库连接到实例，每次sql执行前 添加 use db每台服务采用双master模式按用户分库，用户记录在同一DB减少夸库访问。 标准化环境标准化： 标准化公用组件，运行环境，配置文件，文件目录，差异部分 提取配置平台日志标准化：日志集中跨系统日志遵从统一规范单元测试覆盖80% 多机房架构单机房无法容灾，扩展困难，用户无法就近接入 用户流量调度使用智能DNS 多机房数据双向同步binlog日志 主从数据库同步， 通过task刷新缓存 ，机房间通过联通电信双VPN线路只有主DB写入，容错和重试跨机房通过MQ进行数据传递，比较实时的更新缓存Redis持久化到mysql 未来异地多活，多点写入基于大数据用户画像，推荐，筛选，内容甄别个性化推荐，基于用户画像 第14 架构演化和业务增长的领悟分治，解耦 引入队列通过反转注入IOC采用事件驱动，观察者模式，消息链模式扩容数据写瓶颈：内存聚合，一定量后统一写入采用 nosql技术水平分/垂直分 计算瓶颈:复杂数学模型，feature增加，运算力需求增加；内存换时间，分布式计算，分级服务 存储瓶颈： nosql es 微服务 组件化业务组织团队服务就是产品去中心化基础设施自动化容错设计计划设计服务质量保证 第15 Mico的朴素架构之旅mysql作为主要的持久化存储， 大部分业务落在mysql，采用主从拓扑，按业务分库；（从用来读）Mogodb 文件系统使用GridFS； 使用GraphicsMagick js binding 处理图片压缩 缩略图 异步拆分服务 对话场景：发消息： 服务端写cache，同时更新消息协议中的redis，再写队列。 （落地，派发后台处理）使用队列 实现 已送达，已阅读 socket server长连接 的水平扩展，会话双方不在同一实例， socket server通信也使用队列 ELK 监控 RPC（Thrift）云端第16 Hulu全平台视频系统演进第17 基于 perReq 提升微博图片访问质量云计算和大数据第18 云计算的核心业务系统建设（南天，戴敏）复杂系统建设实践 分离关注点安全 并发 故障处理 伸缩 服务类型服务代理 服务管理 性能实施角度: 概念设计 架构设计 总体设计 复杂系统引入云计算 soa 大数据很困难，不能 为了引入而引入实践中，不能束缚于新技术 架构分离主题关注各个主题 自底向上分析 设计， 从主题推演架构设计针对关键主题， 自底向上 采纳新技术， 调整策略实施过程中 架构调整 实施管理关键： 整体规划能力 分解能力 第19 数据迁移 AWS第21 东软 SaCa Aclome 云管理平台架构演进产品交付角度： 无法按需交付，持续交付产品生产： 难以做到 “规模化” 跨团队 跨组织合作产品质量： 难以应对潜在性能问题产品发展： 难以“可持续”产品改良 持续化交付： 产品按功能分割为多组件，根据需求提供必要的组件，组件装配技术快速交付；高可用： 自动管理监控，容器话 热部署 保证高可用 基于Dubbo分布式服务框架，提供高性能 透明化rpc远程调用 以及服务治理 微内核，缓存，菜单，日志，组织结构，权限，采集，分析 第22 计算广告大数据核心技术 （卢亿雷）高可靠： 多分存储，不丢失 – HDFS高可用： 7*24 –LVS 负载高扩展：扩容服务 – Hadoop高性能：高并发 低延迟 – Nginx Redis高安全： IDC管理制度，分布式密钥管理 – Kerberos SSL 公私钥 分布式密钥 程序沙箱隔离高性价： – Hadoop 分布式计算和存储监控维护： 简单 – Nagios Ganglia","categories":[{"name":"技术","slug":"技术","permalink":"http://www.sillystone.info/categories/技术/"}],"tags":[{"name":"读书笔记","slug":"读书笔记","permalink":"http://www.sillystone.info/tags/读书笔记/"}]},{"title":"python something","date":"2017-10-26T10:46:54.000Z","path":"2017/10/26/python-something/","text":"","categories":[],"tags":[]},{"title":"数据挖掘与数据化运营实战：思路 方法 技巧和应用","date":"2017-10-21T03:24:00.000Z","path":"2017/10/21/数据挖掘与数据化运营实战：思路-方法-技巧和应用/","text":"2 数据挖掘概述2.2 数据分析和数据挖掘对具体的业务分析需求，确定分析思路，挑选和匹配适合的分析算法和分析技术； 一个具体的分析需求一般会有两种以上不同的思路和算法可以去探索，最后可根据验证的效果和资源匹配等因素经行综合权衡。 2.3 数据挖掘成熟技术2.3.1 决策树不依赖领域知识，适合探索式挖掘，可以处理高维度数据，对数据分不宽容，不受极值影响 CHAIDCART Classification and Regression TreeID3 Iterative Dichotomiser 用户划分，行为预测，规则梳理。 可以作为其他模型的变量筛选方法 2.3.2 神经网络机器学习的典型代表。 是通过输入多个非线性模型以及不同模型之间的加权互联（加权的过程在隐蔽层完成） 最终得到一个输出模型。隐蔽层包含的是非线性函数。 神经网络算法：反馈传播 Backpropagation. 应用：信号处理，模式识别，专家系统，预测系统影响因素： 层数， 每层输入变量的数量，联系的种类， 联系的程度， 转换函数 用户划分，行为预测，营销响应 2.3.3 回归回归：Regression 包括 线性回归（Linear Regression） 多元线性回归和逻辑斯蒂回归（Logistic Regression） 2.3.4 关联规则Association Rule 目的： 找出数据集中的频繁模式（Frequent Pattern）并发关系（Concurrence Relationships）案例; 购物篮分析 Basket Analysis， 通过分析用户购物篮中的商品之间的关系，挖掘用户习惯从而制定更好的营销策略。 支持度 Support 和置信度Confidence是衡量关联规则强度的两个重要指标 支持度 规则X-&gt;Y 指事物全集包含X并Y的事物百分比。 衡量规则的有用性置信度 规则X-&gt;Y 指即包含X又包含Y的事物数量占所有包含X的事物数量的百分比 衡量确定性/可预测性 算法：Apriori算法：1.生成所有的频繁项目集。一个频繁项目集Frequent Itemset是一个支持度高于最小支持阈值min-sup 的项目集2.从频繁项目集中生成所有的可信关联规则。 可信关联规则是指置信度大于最小置信阈值的规则 min-conf 2.3.5 聚类Clustering算法：划分方法(partitioning Method) 层次方法(Hierarchical Method) 基于密度的方法(Density-based Method) 基于网络的方法(Grid-based Method) 基于模型的方法(Model-based Method) k-means方法（划分方法）；首先 随机选择K个对象，并且所选择的每个对象都代表一个组的初始均值或初始的组中心值； 对剩余的每个对象 根据其与各个组初始均值的距离，将他们分配给最近的小组。然后重新计算每个小组新的均值；这个过程不断重复，直到所有的对象在k组分布中都找到了离自己最近的组 层次方法：依次让最相似的数据对象两两合并，这样不断合并，最终形成一颗聚类树 2.3.6 贝叶斯分类方法Bayesian Classifier 2.3.7 支持向量机Support Vector Machine 神经网络相比，它不仅结构简单，各项技术的性能也得到提升 2.3.8 主成成分分析Principal components Analysis 属于传统的统计分析技术 主要用于数据处理，降维，变量间关系的探索。 2.3.9 假设检验Hypothesis Test用于 运营效果的评估 3 数据化运营中常见的数据分析项目类型3.1 目标客户的特征分析3.2 目标客户的预测（响应，分类）模型流失预警模型，付费预测模型，续费预测模型等逻辑回归 决策树 神经网络 支持向量机 3.3. 运营群体的活跃度定义 主成分分析 多个核心行为转换为一个或者少数几个主成分，最终转化为综合的分数 数据的标准化 不同的指标有不同的度量尺度，只有标准化后 才可以将数据按比例缩放 3.4 用户路径分析运营部门 产品设计部门PD 用户体验设计部门 User Experience Design UED 数据来源与：web服务器的日志数据 运营部门：提升用户点击页面的效率，调整运营策略产品： 产品优化，冷僻功能是否有必要取消或者优化 3.5 交叉销售模型3.6 信息质量模型3.7 服务保障模型3.8 用户（买家，卖家）分层模型3.9 卖家（买家）交易模型3.10 信用风险模型3.11 商品推荐模型3.12 数据产品3.13 决策支持4 数据化运营是跨专业 跨团队的协调与合作4.1.1 提出业务分析需求胜任基本的数据分析图表处理能力：针对具体的运营场景，制作趋势图 分布图 透视表 二维交叉图读懂报表能力：日报 周报 监控报表发现异常，合理解释数据波动细分用户能力：按合理的维度切分用户群体，针对用户群细分运营运营监控能力：设计 制作简单的监控报表，埋点 控制运营节奏简单SQl能力：分析总结能力：目标预测能力： 典型运营活动场景：运营团队根据数据分析师提供的目标用户的特征和运营受众的规模，为目标群体制定运营方案，包括：运营计划书，文案创作，运营刺激方案的制定，活动页面的框架，配合统计的页面布点活动页面的定稿，订购流程的优化（与CRM团队协调），运营活动的上线（IM通讯团队，网站技术团队协调），活动效果的监控（数据分析团队，数据仓库团队合作）活动节奏把控和页面切换，活动后的总结，讨论，反馈。 5 分析师常见的错误观念和对应的管理策略影响数据挖掘模型和数据分析成果价值的因素很多，技术（算法，数据质量，设施），分析师对于数据分析的思想观念，态度，商业意识，企业层的数据化运营意识和氛围。 错误观念包括: 轻视业务论 技术万能论 技术尖端论 建模与应用两段论 机器万能 数据分析项目前期的专家小组评估机制。 对需求的合理性，课题分析技术的把握性，数据分析预计产出物，相关业务因素的判断。 数据挖掘过程：80%时间熟悉数据 6 数据挖掘项目案例演示传递的内容： 按流程进行挖掘是数据分析严谨性的体现 数据挖掘和建模是数据化运营的一个环节 运营方案对于模型的应用效果影响极大 流程： 项目背景和业务分析需求的提出 数据分析师参与需求讨论 制定需求分析框架和分析计划 抽取样本数据 熟悉数据 数据清晰和摸底 按计划初步搭建数据模型 与业务讨论模型的初步结论，提出新的思路和模型优化方案 按优化方案重新抽取样本并建模，提炼结论并验证模型 完成分析报告和落地应用建议 制定具体的落地应用发难和评估方案 业务实施应用发难并跟踪，评估效果 落地方案在实际效果评估后 不断修正和完善 不同运营方案的评估 总结 和反馈 项目应用后的总结和反思 案例简述： 分析客户流失群体的特征，最终采用模型统计出易流失客户群体，模型会给出客户的流失得分；运营针对得分高的客户制作方案，其中抽取5%的样本做对照组，以便对运营效果做比较，同时对于目标客户做细分，针对性的制作运营方案，对于同一细分用户，制作不同的运营方案，并评估各个方案的实施效果 7 数据挖掘建模额优化和限度模型优化遵循有效，适度的原则 如何优化模型1.业务思路上优化： 明显直观的规则，指标可以替代复杂的建模； 明显的业务逻辑被疏忽；通过建模和数据分析，是否可以颠覆某一业务推测或业务直觉；目标变量的定义是否稳定 建模技术 建模技巧 模型效果评估指标ROC曲线 Receiver Operating characteristicKS 值Lift值 响应率 %Response 捕获率%Captured Response8 常见的数据处理技巧数据我挖掘 60%时间 熟悉 清理 转换数据 抽样主要用于降低数据分析的规模，同时可以用于人工提高低概率事件在样本中的比例数据转换 产生衍生变量 改善变量分布特征，主要是对不对症分布的转换: log; Square Root; Inverse; Squaer; Exponential 区间型变量的分箱转换 区间型变量的标准化操作: Min-Max标准化，离差标准化【0-1】 x-min/max-min 筛选有效的输入变量业务筛选线性相关性筛选皮尔逊相关系数 [-1, +1] x与y的协方差/x标准差与y标准差的乘积|r| &lt; 0.3 低线性相关性0.3 |r| 0.5 中低线性相关0.5 0.8 中度相关0.8 1 高度线性相关 R平方[0, 1] 越大，说明模型的拟合越好 卡方检验Chi-Square Statistics IV和WOE共线性问题多个自变量之间存在较强的 甚至完全的线性相关关系。自变量之间高度相关时，模型参数会变得不稳定，预测能力降低 发现共线性 采用 皮尔逊相关系数 模型结论观察，回归系数标准差太大，可能存在共线性问题 主成分分析法 对变量进行聚类 解决取舍，组合变量-》新变量 9 聚类分析的典型应用和技术目标用户的分群体不同产品的价值组合探测 发现孤立点 异常值 划分方法： K-means（异常值，噪点的影响) K-Medoids层次方法： 凝聚层次聚类（自底向上） 分裂层次（自顶向下）密度网格 STING算法 10 预测响应模型的典型应用和技术神经网络决策树 CHAID CART ID3逻辑回归多元线性回归技术模型过拟合及对策11 用户特征分析的典型应用和技术12 运营效果分析的典型应用和技术AB Test 对运营效果比较 13 漏斗模型和路径分析网络日志和布点布点： 页面级别布点： ip 用户 cookie 浏览器 点击布点 追踪日志：多渠道 入口布点漏斗模型和路径分析的主要区别和联系漏斗是路径分析的特殊形式，对关键环节进行 漏斗模型的主要应用场景浏览-》购物-》下单-》支付 路径分析的应用场景 用户典型的频繁的路径模式识别 用户行为特征识别 网站产品设计和优化的依据和参考 运营监督和管理 路径分析的主要算法社会网络分析 Social Network Analysis基于序列的关联分析遍历分析15 换位思考16 数据分析师的品质和思维模式态度商业意识是核心方法论：做假设 定标准 作比较看趋势 观全局 辨真伪 下结论 18 数据挖掘的质量保障流程和制度 需求提出/分析 （明确责任人，需求确认） 评估需求优先级 （需求评估小组） 课题组成立 向业务提交正式课题计划书 课题开展 向业务提交结论报告和业务落地应用的建议 落地应用和效果监控反馈 组织架构措施： 数据分析师双线管理， 业务和技术主管双管 需求评估小组：数据分析部门负责人，资深分析和建模专家，资深项目经理，业务专家 项目管理：周报制度，周会制度，阶段性分享和讨论制度。 19 经典数据挖掘方法论SEMMA方法论， CRISP-DM方法论 Tom Khabaza的挖掘9律","categories":[{"name":"技术","slug":"技术","permalink":"http://www.sillystone.info/categories/技术/"}],"tags":[{"name":"文摘","slug":"文摘","permalink":"http://www.sillystone.info/tags/文摘/"},{"name":"数据挖掘","slug":"数据挖掘","permalink":"http://www.sillystone.info/tags/数据挖掘/"}]},{"title":"使用python实现网站交互","date":"2017-10-11T13:11:35.000Z","path":"2017/10/11/使用python实现网站交互/","text":"要点大致看了一下《 Web Scraping with Python book by Packt Publications》刚好单位需要在线学习课程，练手写了一个自动学习的脚本。 python 版本： 2.7主要技术问题包括： 用户登录 以及网站sessionid处理 –使用cookielib网站http交互，包括cookie，http header处理 –使用urlib2关键网页要素的抓取 –使用re 正则表达式网站交互报文分析 –使用fiddler工具 功能 必修课 自动选课查看已选课列表学习每节课，置通过 关键技术总结python 网络交互模块12345678910import urlibimport urlib2import cookielibdef run(): cookie=cookielib.MozillaCookieJar(_cookie_file) cookie.load(ignore_discard=True, ignore_expires=True) handler=urllib2.HTTPCookieProcessor(cookie) opener=urllib2.build_opener(handler) opener.addheaders = [('User-Agent',user_agent),('Accept-Language','zh-CN')] opener.open(url, data) 说明： cookie文件处理，使用MozillaCookieJar； CookieJar不可以处理文件 addheaders 方法可以添加header； 该方法多次调用，每次会丢弃上次的header设置 open方法，仅送url，HTTP-GET； 送data HTTP-POST python 字符串处理 raw string: 多行注释 多行字符串 其中的单双引号不转义； 只对其内的反斜杠起作用 三个引号 包含多行字符串 中文字符，需要在文件开头设置 coding=utf-8 数组处理代码python 实现网站交互","categories":[{"name":"技术","slug":"技术","permalink":"http://www.sillystone.info/categories/技术/"}],"tags":[{"name":"python","slug":"python","permalink":"http://www.sillystone.info/tags/python/"},{"name":"爬虫","slug":"爬虫","permalink":"http://www.sillystone.info/tags/爬虫/"}]},{"title":"网站术语","date":"2017-09-25T07:57:19.000Z","path":"2017/09/25/网站术语/","text":"大型分布式网站术语分析 I/O优化 增加缓存，减少磁盘的访问次数。优化磁盘的管理系统，设计最优的磁盘方式策略，以及磁盘的寻址策略，这是在底层操作系统层面考虑的。设计合理的磁盘存储数据块，以及访问这些数据库的策略，这是在应用层面考虑的。例如，我们可以给存放的数据设计索引，通过寻址索引来加快和减少磁盘的访问量，还可以采用异步和非阻塞的方式加快磁盘的访问速度。应用合理的RAID策略提升磁盘I/O。 Web前端调优 减少网络交互的次数（多次请求合并）减少网络传输数据量的大小(压缩)尽量减少编码（尽量提前将字符转化为字节，或者减少从字符到字节的转化过程。）使用浏览器缓存减少Cookie传输合理布局页面使用页面压缩延迟加载页面CSS在最上面，JS在最下面CDN反向代理页面静态化异地部署3.服务降级（自动优雅降级） 拒绝服务和关闭服务 4.幂等性设计 有些服务天然具有幂等性，比如讲用户性别设置为男性，不管设置多少次，结果都一样。但是对转账交易等操作，问题就会比较复杂，需要通过交易编号等信息进行服务调用有效性校验，只有有效的操作才能继续执行。 （注：幂等性是系统的接口对外一种承诺(而不是实现), 承诺只要调用接口成功, 外部多次调用对系统的影响是一致的. 声明为幂等的接口会认为外部调用失败是常态, 并且失败之后必然会有重试.） 5.失效转移 若数据服务器集群中任何一台服务器宕机，那么应用程序针对这台服务器的所有读写操作都需要重新路由到其他服务器，保证数据访问不会失败，这个过程叫失效转移。失效转移包括：失效确认（心跳检测和应用程序访问失败报告）、访问转移、数据恢复。失效转移保证当一个数据副本不可访问时，可以快速切换访问数据的其他副本，保证系统可用。 6.性能优化 根据网站分层架构,性能优化可分为：web前端性能优化、应用服务器性能优化、存储服务器性能优化。 web前端性能优化浏览器访问优化：减少http请求;使用浏览器缓存;启用压缩;css放在页面最上面、javaScript放在页面最下面;减少Cookie传输CDN加速反向代理应用服务器性能优化分布式缓存（Redis等）异步操作（消息队列）使用集群（负载均衡）代码优化存储性能优化机械硬盘vs固态硬盘B+树 vs LSM树RAID vs HDFS 代码优化 多线程（Q:怎么确保线程安全？无锁机制有哪些？）资源复用（单例模式，连接池，线程池）数据结构垃圾回收 负载均衡 HTTP重定向负载均衡当用户发来请求的时候，Web服务器通过修改HTTP响应头中的Location标记来返回一个新的url，然后浏览器再继续请求这个新url，实际上就是页面重定向。通过重定向，来达到“负载均衡”的目标。例如，我们在下载PHP源码包的时候，点击下载链接时，为了解决不同国家和地域下载速度的问题，它会返回一个离我们近的下载地址。重定向的HTTP返回码是302。优点：比较简单。缺点：浏览器需要两次请求服务器才能完成一次访问，性能较差。重定向服务自身的处理能力有可能成为瓶颈，整个集群的伸缩性国模有限；使用HTTP302响应码重定向，有可能使搜索引擎判断为SEO作弊，降低搜索排名。DNS域名解析负载均衡DNS（Domain Name System）负责域名解析的服务，域名url实际上是服务器的别名，实际映射是一个IP地址，解析过程，就是DNS完成域名到IP的映射。而一个域名是可以配置成对应多个IP的。因此，DNS也就可以作为负载均衡服务。事实上，大型网站总是部分使用DNS域名解析，利用域名解析作为第一级负载均衡手段，即域名解析得到的一组服务器并不是实际提供Web服务的物理服务器，而是同样提供负载均衡服务的内部服务器，这组内部负载均衡服务器再进行负载均衡，将请求分发到真是的Web服务器上。优点：将负载均衡的工作转交给DNS，省掉了网站管理维护负载均衡服务器的麻烦，同时许多DNS还支持基于地理位置的域名解析，即会将域名解析成举例用户地理最近的一个服务器地址，这样可以加快用户访问速度，改善性能。缺点：不能自由定义规则，而且变更被映射的IP或者机器故障时很麻烦，还存在DNS生效延迟的问题。而且DNS负载均衡的控制权在域名服务商那里，网站无法对其做更多改善和更强大的管理。反向代理负载均衡反向代理服务可以缓存资源以改善网站性能。实际上，在部署位置上，反向代理服务器处于Web服务器前面（这样才可能缓存Web相应，加速访问），这个位置也正好是负载均衡服务器的位置，所以大多数反向代理服务器同时提供负载均衡的功能，管理一组Web服务器，将请求根据负载均衡算法转发到不同的Web服务器上。Web服务器处理完成的响应也需要通过反向代理服务器返回给用户。由于web服务器不直接对外提供访问，因此Web服务器不需要使用外部ip地址，而反向代理服务器则需要配置双网卡和内部外部两套IP地址。优点：和反向代理服务器功能集成在一起，部署简单。缺点：反向代理服务器是所有请求和响应的中转站，其性能可能会成为瓶颈。LVS-NAT:修改IP地址LVS-TUN: 一个IP报文封装在另一个IP报文的技术。LVS-DR:将数据帧的MAC地址改为选出服务器的MAC地址，再将修改后的数据帧在与服务器组的局域网上发送。9.缓存 缓存就是将数据存放在距离计算最近的位置以加快处理速度。缓存是改善软件性能的第一手段，现在CPU越来越快的一个重要因素就是使用了更多的缓存，在复杂的软件设计中，缓存几乎无处不在。大型网站架构设计在很多方面都使用了缓存设计。 CDN: 及内容分发网络，部署在距离终端用户最近的网络服务商，用户的网络请求总是先到达他的网络服务商哪里，在这里缓存网站的一些静态资源（较少变化的数据），可以就近以最快速度返回给用户，如视频网站和门户网站会将用户访问量大的热点内容缓存在CDN中。反向代理：反向代理属于网站前端架构的一部分，部署在网站的前端，当用户请求到达网站的数据中心时，最先访问到的就是反向代理服务器，这里缓存网站的静态资源，无需将请求继续转发给应用服务器就能返回给用户。本地缓存：在应用服务器本地缓存着热点数据，应用程序可以在本机内存中直接访问数据，而无需访问数据库。分布式缓存：大型网站的数据量非常庞大，即使只缓存一小部分，需要的内存空间也不是单机能承受的，所以除了本地缓存，还需要分布式缓存，将数据缓存在一个专门的分布式缓存集群中，应用程序通过网络通信访问缓存数据。使用缓存有两个前提条件，一是数据访问热点不均衡，某些数据会被更频繁的访问，这些数据应该放在缓存中；二是数据在某个时间段内有效，不会很快过期，否则缓存的数据就会因已经失效而产生脏读，影响结果的正确性。网站应用中，缓存处理可以加快数据访问速度，还可以减轻后端应用和数据存储的负载压力，这一点对网站数据库架构至关重要，网站数据库几乎都是按照有缓存的前提进行负载能力设计的。 负载均衡算法 轮询 Round Robin加强轮询 Weight Round Robin随机 Random加强随机 Weight Random最少连接 Least Connections加强最少连接源地址散列 Hash 其他算法 最快算法(Fastest)：传递连接给那些响应最快的服务器。当其中某个服务器发生第二到第7 层的故障，BIG-IP 就把其从服务器队列中拿出，不参加下一次的用户请求的分配，直到其恢复正常。观察算法(Observed)：连接数目和响应时间以这两项的最佳平衡为依据为新的请求选择服务器。当其中某个服务器发生第二到第7 层的故障，BIG-IP就把其从服务器队列中拿出，不参加下一次的用户请求的分配，直到其恢复正常。预测算法(Predictive)：BIG-IP利用收集到的服务器当前的性能指标，进行预测分析，选择一台服务器在下一个时间片内，其性能将达到最佳的服务器相应用户的请求。(被BIG-IP 进行检测)动态性能分配算法(Dynamic Ratio-APM):BIG-IP 收集到的应用程序和应用服务器的各项性能参数，动态调整流量分配。动态服务器补充算法(Dynamic Server Act.):当主服务器群中因故障导致数量减少时，动态地将备份服务器补充至主服务器群。服务质量算法(QoS):按不同的优先级对数据流进行分配。服务类型算法(ToS): 按不同的服务类型(在Type of Field中标识)负载均衡对数据流进行分配。规则模式算法：针对不同的数据流设置导向规则，用户可自行 扩展性和伸缩性的区别 扩展性：指对现有系统影响最小的情况下，系统功能可持续扩展或替身的能力。表现在系统基础设施稳定不需要经常变更，应用之间较少依赖和耦合，对需求变更可以敏捷响应。它是系统架构设计层面的开闭原则（对扩展开放，对修改关闭），架构设计考虑未来功能扩展，当系统增加新功能时，不需要对现有系统的结构和代码进行修改。 衡量网站架构扩展性好坏的主要标准就是在网站增加新的业务产品时，是否可以实现对现有产品透明无影响，不需要任何改动或者很少改动既有业务功能就可以上线新产品。不同产品之间是否很少耦合，一个产品改动对其他产品无影响，其他产品和功能不需要受牵连进行改动。 伸缩性：所谓网站的伸缩性指是不需要改变网站的软硬件设计，仅仅通过改变部署的服务器数量就可以扩大或者缩小网站的服务处理能力。 指系统能够增加（减少）自身资源规模的方式增强（减少）自己计算处理事务的能力。如果这种增减是成比例的，就被称作线性伸缩性。在网站架构中，通常指利用集群的方式增加服务器数量、提高系统的整体事务吞吐能力。 衡量架构伸缩性的主要标准就是可以用多台服务器构建集群，是否容易向集群中添加新的服务器。加入新的服务器后是否可以提供和原来服务无差别的服务、集群中的可容纳的总的服务器数量是否有限制。 12.分布式缓存的一致性hash 具体算法过程：先构造一个长度为2^32的整数环（这个环被称作一致性Hash环）根据节点名称的Hash值（其分布范围为[0,2^32 - 1]）将缓存服务器阶段设置在这个Hash环上。然后根据需要缓存的数据的Key值计算得到Hash值（其分布范围也同样为[0,2^32 - 1]），然后在Hash环上顺时针查找举例这个KEY的hash值最近的缓存服务器节点，完成KEY到服务器的Hash映射查找。 优化策略：将每台物理服务器虚拟为一组虚拟缓存服务器，将虚拟服务器的Hash值放置在Hash环上，key在换上先找到虚拟服务器节点，再得到物理服务器的信息。 一台物理服务器设置多少个虚拟服务器节点合适呢？经验值：150。 网络安全 XSS攻击跨站点脚本攻击(Cross Site Script)，指黑客通过篡改网页，注入恶意的HTML脚本，在用户浏览网页时，控制用户浏览器进行恶意操作的一种攻击方式。防范手段：消毒（XSS攻击者一般都是通过在请求中嵌入恶意脚本大道攻击的目的，这些脚本是一般用户输入中不使用的，如果进行过滤和消毒处理，即对某些html危险字符转移，如“&gt;”转译为“&amp; gt;”）;HttpOnly(防止XSS攻击者窃取Cookie).注入攻击：SQL注入和OS注入SQL防范：预编译语句PreparedStatement; ORM；避免密码明文存放；处理好相应的异常。CSRF（Cross Site Request Forgery，跨站点请求伪造）。听起来与XSS有点相似，事实上两者区别很大，XSS利用的是站内的信任用户，而CSRF则是通过伪装来自受信任用户的请求来利用受信任的网站。防范：httpOnly;增加token;通过Referer识别。文件上传漏洞DDos攻击 加密技术 摘要加密：MD5, SHA对称加密：DES算法，RC算法， AES非对称加密：RSA非对称加密技术通常用在信息安全传输，数字签名等场合。HTTPS传输中浏览器使用的数字证书实质上是经过权威机构认证的非对称加密的公钥。 流控（流量控制） 流量丢弃通过单机内存队列来进行有限的等待，直接丢弃用户请求的处理方式显得简单而粗暴，并且如果是I/O密集型应用（包括网络I/O和磁盘I/O），瓶颈一般不再CPU和内存。因此，适当的等待，既能够替身用户体验，又能够提高资源利用率。通过分布式消息队列来将用户的请求异步化。","categories":[],"tags":[]},{"title":"About English","date":"2017-09-25T04:22:48.000Z","path":"2017/09/25/About-English/","text":"最近又开始看美剧， 但没有字幕 以下是艾美奖（Emmy Awards）的获奖电视剧 《The Handmaids Tale Season 1》 《Big Little Lies Season 1》 《Veep Season 6》 《Saturday.Night》 不了解美国那些事，看不懂 基本可以看懂：《The.Big.Bang.Theory.Season.10》 《Crashing 2017 Season 1》 《Game.of.Thrones.S07》 另外：youtube上有很多很好的视频教学， 科学上网很有必要。","categories":[{"name":"随笔","slug":"随笔","permalink":"http://www.sillystone.info/categories/随笔/"}],"tags":[{"name":"日记","slug":"日记","permalink":"http://www.sillystone.info/tags/日记/"}]},{"title":"管理的常识","date":"2017-09-19T09:12:22.000Z","path":"2017/09/19/管理的常识/","text":"“管理是一种实践，其本质不在于知，而在于行，其验证不在于逻辑，而在于成果，其唯一的权威性在于成就。” –德鲁克：管理的本质 目录什么是管理管理没有对错，只是面对事实，解决问题。 让下属明白什么是重要的关注解决问题，及下属解决问题的能力，不仅是分析问题原因和责任管事而非管人，人希望被尊重衡量管理水平：个人目标和组织目标一致让一线员工可以得到并使用资源 观念： 管理对绩效负责，绩效看齐管理是分配：权利 责任 利益 提高效率： 分工组织效率：专业化水平和等级制度结合个人效率：创造组织环境，满足需求，挖掘潜力 管理的主要工作是，帮助同事（包括上司和下属）发挥长处并避免短处。管理者的价值在于让同事发挥价值。管理者自己发挥绩效并替代上司/下属，不能称之位管理者。 计划管理，流程管理和组织管理是基础管理战略管理和文化管理是高层面的管理，不要把他放在企业管理的基础上做 什么是组织组织是为目标存在的，组织里的人是不平等的 公司不是一个家正式组织：用权利，责任，目标来联结人群的集合非正式组织：兴趣，爱好，情感联结人群 组织必须保证一件事由一组人承担 组织中人与人公平而非平等 分工是个人和组织联结的根本方法，分配职责和权利制度本身是成本 组织内的关系是奉献关系 组织需处于非均衡的、混沌的环境，能够实现组织学习，打破内部平衡 什么是组织结构组织结构就是让权利和责任的关系匹配组织结构的稳定才能保证效率，发展又需要组织结构变化组织结构的管理围绕责任展开。 组织结构的纵向设计，基于主线业务的展开，以考核点为准；组织结构的横向设计，基于资源的分配，职能部门不应该拥有权力 组织结构可以重建组织和个人之间的契约关系，明确个人在组织中的责任和权利 组织结构设计原则： 指挥统一，一个人只有一个上司 控制幅度，每个人能管理的跨度，5-6个人 分工。纵向按照经营分工 决定绩效的分配，权利的分配，承担绩效的人权利最大，与经理最近。横向分工 专业化分工，确保资源有效利用，尽可能简单 部门化，做同一件事情的人放在一起 什么是领导领导是指影响别人，以达到群体目标的过程。 领导是管理职能领导者是指负有指导协调群体活动的责任人。领导职能 因影响力发挥作用，影响力来源于 权利，个人魅力权利：法定权 专家权，奖赏权，惩罚权，统治权 什么是激励决策如何有效什么是计划什么是控制员工的绩效由管理者决定总结要点 管理的目的是提高效率，解决效率问题 管理是”管事”不是”管人” 让一线员工得到并可以使用资源 管理对绩效负责 组织中人与人公平而非平等 群体决策不是最好的决策，是风险小的决策 目标可以不合理 不是变化快，而是计划未包含变化","categories":[{"name":"管理","slug":"管理","permalink":"http://www.sillystone.info/categories/管理/"}],"tags":[{"name":"读书笔记","slug":"读书笔记","permalink":"http://www.sillystone.info/tags/读书笔记/"}]},{"title":"一片阳光","date":"2017-09-10T07:11:58.000Z","path":"2017/09/10/一片阳光/","text":"林徽因 放了假，春初的日子松弛下来。将午未午时候的阳光，澄黄的一片，由窗棂横浸到室内，晶莹地四处射。我有点发怔，习惯地在沉寂中惊讶我的周围。我望着太阳那湛明的体质，像要辨别它那交织绚烂的色泽，追逐它那不着痕迹的流动。看它洁净地映到书桌上时，我感到桌面上平铺着一种恬静，一种精神上的豪兴，情趣上的闲逸；即或所谓“窗明几净”，那里默守着神秘的期待，漾开诗的气氛。那种静，在静里似可听到那一处?琮的泉流，和着仿佛是断续的琴声，低诉着一个幽独者自误的音调。看到这同一片阳光射到地上时，我感到地面上花影浮动，暗香吹拂左右，人随着晌午的光霭花气在变幻，那种动，柔谐婉转有如无声音乐，令人悠然轻快，不自觉地脱落伤愁。至多，在舒扬理智的客观里使我偶一回头，看看过去幼年记忆步履所留的残迹，有点儿惋惜时间；微微怪时间不能保存情绪，保存那一切情绪所曾流连的境界。 倚在软椅上不但奢侈，也许更是一种过失，有闲的过失。但东坡的辩护：“懒者常似静，静岂懒者徒”，不是没有道理。如果此刻不倚榻上而“静”，则方才情绪所兜的小小圈子便无条件地失落了去！人家就不可惜它，自己却实在不能不感到这种亲密的损失的可哀。 就说它是情绪上的小小旅行吧，不走并无不可，不过走走未始不是更好。归根说，我们活在这世上到底最珍惜一些什么？果真珍惜万物之灵的人的活动所产生的种种，所谓人类文化？这人类文化到底又靠一些什么？我们怀疑或许就是人身上那一撮精神同机体的感觉，生理心理所共起的情感，所激发出的一串行为，所聚敛的一点智慧，那么一点点人之所以为人的表现。宇宙万物客观的本无所可珍惜，反映在人性上的山川草木禽兽才开始有了秀丽，有了气质，有了灵犀。反映在人性上的人自己更不用说。没有人的感觉，人的情感，即便有自然，也就没有自然的美，质或神方面更无所谓人的智慧，人的创造，人的一切生活艺术的表现！这样说来，谁该鄙弃自己感觉上的小小旅行？为壮壮自己胆子，我们更该相信惟其人类有这类情绪的驰骋，实际的世间才赓续着产生我们精神所寄托的文物精萃。 此刻我竟可以微微一咳嗽，乃至于用播音的圆润口调说：我们既然无疑的珍惜文化，即尊重盘古到今种种的艺术??无论是抽象的思想的艺术，或是具体的驾驭天然材料另创的非天然形象，则对于艺术所由来的渊源，那点点人的感觉，人的情感智慧（通称人的情绪），又当如何地珍惜才算合理？ 但是情绪的驰骋，显然不是诗或画或任何其他艺术建造的完成。这驰骋此刻虽占了自己生活的若干时间，却并不在空间里占任何一个小小位置！这个情形自己需完全明了。此刻它仅是一种无踪迹的流动，并无栖身的形体。它或含有各种或可捉摸的质素，但是好奇地探讨这个质素而具体要表现它的差事，无论其有无意义，除却本人外，别人是无能为力的。我此刻为着一片清婉可喜的阳光，分明自己在对内心交流变化的各种联想发生一种兴趣的注意，换句话说，这好奇与兴趣的注意已是我此刻生活的活动。一种力量又迫着我来把握住这个活动，而设法表现它，这不易抑制的冲动，或即所谓艺术冲动也未可知！只记得冷静的杜工部散散步，看看花，也不免会有“江上被花恼不彻，无处告诉只颠狂”的情绪上一片紊乱！玲珑煦暖的阳光照人面前，那美的感人力量就不减于花，不容我生硬地自己把情绪分划为有闲与实际的两种，而权其轻重，然后再决定取舍的。我也只有情绪上的一片紊乱。 情绪的旅行本偶然的事，今天一开头并为着这片春初晌午的阳光，现在也还是为着它。房间内有两种豪侈的光常叫我的心绪紧张如同花开，趁着感觉的微风，深浅零乱于冷智的枝叶中间。一种是烛光，高高的台座，长垂的烛泪，熊熊红焰当帘幕四下时各处光影掩映。那种闪烁明艳，雅有古意，明明是画中景象，却含有更多诗的成分。另一种便是这初春晌午的阳光，到时候有意无意的大片子洒落满室，那些窗棂栏板几案笔砚浴在光蔼中，一时全成了静物图案；再有红蕊细枝点缀几处，室内更是轻香浮溢，叫人俯仰全触到一种灵性。 这种说法怕有点会发生误会，我并不说这片阳光射入室内，需要笔砚花香那些儒雅的托衬才能动人，我的意思倒是：室内顶寻常的一些供设，只要一片阳光这样又幽娴又洒脱地落在上面，一切都会带上另一种动人的气息。 这里要说到我最初认识的一片阳光。那年我六岁，记得是刚刚出了水珠以后?水珠即寻常水痘，不过我家乡的话叫它做水珠。当时我很喜欢那美丽的名字，忘却它是一种病，因而也觉到一种神秘的骄傲。只要人过我窗口问问出“水珠”么？我就感到一种荣耀。那个感觉至今还印在脑子里。也为这个缘故，我还记得病中奢侈的愉悦心境。虽然同其他多次的害病一样，那次我仍然是孤独的被囚禁在一间房屋里休养的。那是我们老宅子里最后的一进房子；白粉墙围着小小院子，北面一排三间，当中夹着一个开敞的厅堂。我病在东头娘的卧室里。西头是婶婶的住房。娘同婶永远要在祖母的前院里行使她们女人们的职务的，于是我常是这三间房屋惟一留守的主人。 在那三间屋子里病着，那经验是难堪的。时间过得特别慢，尤其是在日中毫无睡意的时候。起初，我仅集注我的听觉在各种似脚步，又不似脚步的上面。猜想着，等候着，希望着人来。间或听听隔墙各种琐碎的声音，由墙基底下传达出来又消敛了去。过一会，我就不耐烦了??不记得是怎样的，我就蹑着鞋，捱着木床走到房门边。房门向着厅堂斜斜地开着一扇，我便扶着门框好奇地向外探望。 那时大概刚是午后两点钟光景，一张刚开过饭的八仙桌，异常寂寞地立在当中。桌下一片由厅口处射进来的阳光，泄泄融融地倒在那里。一个绝对悄寂的周围伴着这一片无声的金色的晶莹，不知为什么，忽使我六岁孩子的心里起了一次极不平常的振荡。 那里并没有几案花香，美术的布置，只是一张极寻常的八仙桌。如果我的记忆没有错，那上面在不多时间以前，是刚陈列过咸鱼、酱菜一类极寻常俭朴的午餐的。小孩子的心却呆了。或许两只眼睛倒张大一点，四处地望，似乎在寻觅一个问题的答案。为什么那片阳光美得那样动人？我记得我爬到房内窗前的桌子上坐着，有意无意地望望窗外，院里粉墙疏影同室内那片金色和煦绝然不同趣味。顺便我翻开手边娘梳妆用的旧式镜箱，又上下摇动那小排状抽屉，同那刻成花篮形小铜坠子，不时听雀跃过枝清脆的鸟语。心里却仍为那片阳光隐着一片模糊的疑问。 时间经过而是多年，直到今天，又是这样一泄阳光，一片不可捉摸，不可思议流动的而又恬静的瑰宝，我才明白我那问题是永远没有答案的。事实上仅是如此；一张孤独的桌，一角寂寞的厅堂。一只林巧的镜箱，或窗外断续的鸟语，和水珠–那美丽小孩子的病名–便凑巧永远同初春静沉的阳光整整复斜斜的成了我回忆中极自然的联想。","categories":[{"name":"随笔","slug":"随笔","permalink":"http://www.sillystone.info/categories/随笔/"}],"tags":[{"name":"文摘","slug":"文摘","permalink":"http://www.sillystone.info/tags/文摘/"}]},{"title":"记忆-林徽因","date":"2017-09-10T06:57:08.000Z","path":"2017/09/10/记忆-林徽因/","text":"记忆 断续的曲子，最美或最温柔的 夜，带着一天的星。 记忆的梗上，谁不有 两三朵聘婷，披着情绪的花 无名的展开 野荷的香馥， 每一瓣静处的月明。 湖上风吹过，头发乱了，或是 水面皱起像鱼鳞的锦。 四面里的辽阔，如同梦 荡漾着心中彷徨的过往 不着痕迹，谁都 认识那图画 沉在水底记忆的倒影！ 二十五年二月 林徽因","categories":[{"name":"散文","slug":"散文","permalink":"http://www.sillystone.info/categories/散文/"}],"tags":[{"name":"诗","slug":"诗","permalink":"http://www.sillystone.info/tags/诗/"},{"name":"文摘","slug":"文摘","permalink":"http://www.sillystone.info/tags/文摘/"}]},{"title":"管理？","date":"2017-09-01T14:06:28.000Z","path":"2017/09/01/管理/","text":"职业发展这事得自己做：1）自己了解自己，更合适，你凭什么愿意相信一个远隔千里的陌生人，而不相信自己？ 2）自己做规划，遇到困难更能坚持，自己约的炮含泪也得那啥；别人帮你做的，你早不干了。 而职业生涯的路总的来说，大约是两个方向：管理者和专家。 你到底选哪个方向，取决于你的工作价值观。 工作适应理论（Work Adjustment Theory，明尼苏达大学的两位学者Rene V. Dawis 和 Lloyd H.Lofquist 的研究成果）中把工作价值观细分成： 成就：你如何看待工作成就感；舒适：你是否看重稳定和舒适的工作；地位：你是否追求晋升成为管理者；利他主义：你是否想做一份帮助他人的工作；安全感：你是否希望公司更透明更一视同仁；自主权：你是否希望获得更多自由发挥的空间。 这些因素中的绝大部分和我们最后选择的方向有些关联，比如： 你如何看待成就感？自己一己之力成就大单更爽？还是看着自己提拔的年轻人拿到大单更爽？你是否追求晋升？你是否喜欢管理人？你是否希望得到更大的自主权？一般来说，作为专家的身份更具有自主权。我们通常以为做领导就会有自主权，但在很多公司领导被上级的任务压得喘不过气，下属也需要自己带，自己的自主决策空间并没有想象中大。 你去问一个大学生未来的职业发展计划，绝大多数会告诉你，ta 希望毕业 5-8 年内做到管理者，当然这个时间越短越好。 这一定好吗？不一定。 在做职业规划时，首先问自己两个问题： 你是做管理人才的料吗？做管理人才，通常需要点亮整颗技能树。 ► 沟通能力 你不可能总靠自己的权威去压制下属；更别说同级别的经理和上司。你需要有强有力的说服力，也应当有聆听别人给予及时正确反馈的技能，要会演讲，也要会妥协。 ► 利他思维 领导不是自己成功就可以了，你需要带着整个团队成功；很多成功的职场人一当上经理就变得神经紧张。他们喜欢以己度人，我能这么做，效果很好，为什么你们不行？ 但事实上你那套东西对你有用，对其他人未必。领导者可以从下属角度出发，为他们思考分析解决问题，才是真正领导力。 ► 全面的管理技能 预算安排，组织架构调整，跨部门协作…从事管理岗位要求你能在多项任务间变换角色，灵活应对。 我见过不少出色的专业人才，在进入管理岗位后变得无所适从，甚至自我质疑。 也见过挺漂亮可爱的姑娘一进办公室变得一副全办公室欠我 500 万的脸色，对着下属怒目相视。 他们可能很有才华，但至少暂时不适合做领导。 你是做专家人才的料吗？专家得往某几个专项技能上狠下功夫： ► 不停歇的学习精神 再牛的专家也要学习，一旦停下脚步或者你的知识过时了，很可能就要被组织淘汰。 ► 创新精神 你的知识领域如何与新的市场结合？如何适应新的环境？一旦有一天新的竞争对手从另一个维度杀来，你是否做好准备？ ► 共享精神 你是否愿意传播自己的知识，是否愿意为人师，是否善于做演讲。公司养专家，是因为脱离技术/知识岗位的管理者不可能再专精于技术/知识，当企业需要技术或者知识分享给普通员工时，就需要专家角色。 ► 独立解决问题的能力 以咨询行业为例，能称之为专家的顾问，谁不是能以一己之力扛着项目朝前走的超人。 职场人常见的误区 ► 以为不做领导就没有出路 实际上以企业金字塔式的结构，真正能坐上去的是极少数；角力过程的失败者，最好的生存方式就是作为专家。而且专家的路更自由更灵活，尤其是咨询公司的顾问们，如今很多是独立的高管教练，比高管还牛还自在。 ► 以为做管理会很轻松 事实上，做专家比做管理要轻松。不用背团队指标，不用挣扎在复杂的人际关系中，不用去做一些违背价值观的事情（比如裁员），有更大的灵活度和自主权。 ► 以为做管理更不容易失业 一旦需要裁员，大家觉得裁人的权利在主管手里，自然不会自裁，专家就不行了，没权利。这就忽视了专家长期浸淫知识/技术/业务第一线，他对风险的敏感度最高，一旦风吹草动他就跳槽了或者转战为独立咨询顾问了，灵活性高；管理层反而容易被蒙在鼓里，等反应过来已经迟了。况且管理层被裁后绝不像专家那么容易再就业。 ► 认为做领导有权威 真正的权威来源自我们的能力和格局。能力，一件棘手的问题你能解决别人当然会服气；格局，是指你如何保护下属，如何帮助你的团队成长。 有一种说法，一流领导招一流人才，二流领导招三流人才，因为二流领导慌啊，怕一流人才抢了饭碗。他不愿意招牛人，更不愿意把年轻人培养成牛人。 LAST我见过不少所谓的领导只是发号施令的 boss，不是帮助人成长的 leader。 我见过不少领导，虽有实权，但下属视他为笑话，他只能用职位压人干活。 我也见过毫无实权的专家，他照看好身边的小伙伴，身边人都将他看作 leader，尊敬他听从他的建议。 用美国领导力专家 Simon Sinek 的话收尾： Leadership is a choice, not a rank.","categories":[{"name":"管理","slug":"管理","permalink":"http://www.sillystone.info/categories/管理/"}],"tags":[{"name":"文摘","slug":"文摘","permalink":"http://www.sillystone.info/tags/文摘/"},{"name":"管理","slug":"管理","permalink":"http://www.sillystone.info/tags/管理/"}]},{"title":"养鱼记824","date":"2017-08-24T15:13:51.000Z","path":"2017/08/24/养鱼记824/","text":"红绿灯今早喂鱼 发现最后一条“红绿灯”消失了 找了半天 终于放弃了 应该是被大鱼吃掉了 可是 居然什么都没有剩下 好奇怪 燕儿新来的燕儿鱼 呆呆的望着鱼缸上凝结的水珠 猛地扑向流下的水珠 碰到玻璃上 晕了。。。 小熊猫卖鱼的老板说 这么大的燕儿只能和小熊猫一起养 第一天 小熊猫呆呆的在鱼缸下面 第二天 一只小熊猫追着燕儿咬 燕儿那么大，却那么笨 被咬的到处躲 我只好把他隔离出来了","categories":[{"name":"随笔","slug":"随笔","permalink":"http://www.sillystone.info/categories/随笔/"}],"tags":[{"name":"日记","slug":"日记","permalink":"http://www.sillystone.info/tags/日记/"}]},{"title":"雨后","date":"2017-08-23T15:03:11.000Z","path":"2017/08/23/雨后/","text":"我喜欢 行走在雨后的树下 不紧不慢 期待着 有点紧张 水滴来得总是很突然 虽已有准备 大大的一滴，凉凉的 脑袋一片清凉 笑着，走快几步 又慢下来 继续期待着 生活总是充满惊喜 我总是期待着","categories":[{"name":"随笔","slug":"随笔","permalink":"http://www.sillystone.info/categories/随笔/"}],"tags":[{"name":"日记","slug":"日记","permalink":"http://www.sillystone.info/tags/日记/"}]},{"title":"鸡汤文摘-成大事者","date":"2017-08-23T14:58:23.000Z","path":"2017/08/23/鸡汤文摘/","text":"微信订阅内容分享 皮毛轮廓皮毛轮廓，指最容易观察到的，可以反映创业者基本能力的一些信息。这是能做事情的一个基础。有以下几方面： 做事靠谱如果用一句白话说明就是：交给他的事情，心里面踏实。他们做事永远不需要担心，他们会充分思考，不会出现很低级的失误；他们过手的事情，永远不会打折扣交付。 这些事情不需要非得是“很大很重要”的事才可以检验，不需要是一场重量级谈判，一个生死攸关的决策。任何小事，都可以，也足以管中窥豹。小事，其实更具有考察价值，在无意中表现出来的才是真习惯。 操控力对自己，对自己想要推动的事情，有相当的操控力。他们表达自己意见时可以做到话语简洁明晰，直扣要点；他们时间观念很好824，自己的事情基本可以保证按部就班；各种事项安排有条不紊，很少见手忙脚乱；对于要推动的事情，坐言力行，执行力度惊人；对于树立的目标，总能及时的对结果跟踪反馈，赏罚分明。 如果这些做的很好，那么此人可以掌控的局面将不小，可操控的事业上限也是不可预期的。 这里需要说明的一点是，以上这些原则只可用来参考，通过这些维度来感受（注意是感受，而不是评分）创业者是不是可以较好地操控自己和自己所推动的事情，而不能当成死的标准来套在创业者身上去打分。 因为事情底层要复杂的多，绝非一两句话可以概括。 ##一个人的真实份量 创业者经常会说，他的合伙人a，是百度出来的，合伙人b，参与过百团大战……其实，这样并不能真正地了解一个人的分量。如果想了解一个人的真实份量，仅仅了解到东家是不够的。腾讯有张小龙，也有保安和保洁阿姨。 所以，如果需要了解一个人或者团队，需要更赤裸裸一些。上个东家给的薪水是多少？具体职位是什么？手底下管着几个人？ 每天的具体日常工作内容是什么？平时怎么正常运营的？有过几次升迁，职能做了哪些转变？做过最得意的成绩是什么？此类问题，穿透性会强很多。 经验经历会带来经验，经验会助于创业。 从0起步成功的毕竟是少数，“从0到1”的理论，更多时候无法直接落地大部分公司。在竞争激烈，市场透明的情形下，创业者的经验是必备条件。 要考察是真经验，还是假行家，主要是探测其认识的深刻程度，通过对业内的一些见解和“天下大势”的分析，来判断是不是该行业深度的参与者。 除此之外，还有一个比较好使的方法，就是介绍他做出来的最得意的成就，以及最大的失误。头衔是虚的，但是真刀真枪干出来的事是假不了的。最得意的成就/业绩是什么？ 最大的失误是什么，导致了什么悲剧？错误有时比成绩更能看出一个人的能力。不遭人妒是庸才，没犯过错误通常证明没有做什么事。 骨骼筋络这个，我想表达的，是创业者的硬实力。 第一条的成功，最多能说明是个很好的职业经理人，有很好的职业素养。但当跳出背后的靠山，开始领着几个兄弟自立门户的一瞬间，更重要的就是创业者的素养。 商业的常识无论是之前读书学来的，还是跟着前老板经历过的，或者作为连续创业者亲自趟过来的，基本商业常识是必修课；如果还没有修，那么就是这个团队必趟的坑。我们无法瞬间长大，创业者也不可能瞬间成熟，这跟能力无关，人性使然。 真正的商业模式，不是在屋里写写画画就可以做出来的，纸上的逻辑，十有八九不会在现实中无损耗地实现，只有体验过现实中的种种意外，才能停止闭门造车，才能学会对现实的敬畏。比如，不经历“树倒猢狲散”的无助，很难真正理解什么叫“合伙人”，也更不会做到“财散人聚”。 所以，了解一个创业者在商业常识上的“段位”，就是看他们的成熟程度，方便我们对可能发生的情形做好心理准备。据我观察，大部分时候，坑是绕不过去的，只是掉到坑里的惨烈程度不同罢了。 认真专一精益求精的素养，不轻易为外界所动，追求所做事情的完美，是个难能可贵的品质。“事必专任，乃可贵成”。这个规律自古以来就是这样，当今创业更是这样，因为越是竞争激烈，越是应该推崇匠人精神。要么做到极致，要么做到别做，现在国内任何一个创业方向都有无数公司在做，并且后浪推前浪，新团队层出不穷。创业圈太拥挤，已经没有“半瓶醋”的容身之地了。 这种情景下，一颗追求高品质的心就变得尤为重要。现在大家喊的“消费升级”也属于这个范畴。“认真搞笑”的开心麻花，充满艺术范的“大董”，死磕的“罗辑思维”，都是这种品质的时代受益者。这种品质不仅使他们受益，更使这些原本冷僻的生意模式，也受到了资本的垂青。 衡量匠心最有效的方法，就是看产品的品质和细节。拿出公司的第一重点产品，横向对比市面上的同类，只要体验得够认真，产品的区别很容易看出来。用心的东西，是可以被感知的，即便不是那么轻易地被观察。 决策的素养决策是决定一个公司命运的基本单位。无论是是否该停止烧钱，还是估值定在多少，节奏怎么把握，一切都是决策。决策力决定了一个创始人是英明的领路人，还是糊涂蛋。 如何去衡量一个人的决策力呢？那就把“决策”这个事解剖开了判断：信息收集的方式，信息处理的方式，和坚决执行的力度。 收集信息的方式：我们需要了解到足够多的方面，才可以有基础做一个正确的决定。当一个难题摆在眼前，需要智慧提取出来决策目的是什么？哪些方面会影响此目标的实现？通过什么渠道和方式去获取最真实准确的信息？ 了解此项能力最好的方式，就是观察一个人在面对比较陌生的状况时，他了解情况的思路是不是清晰，选择的路径是不是正确，顾虑到的方方面面是不是周密。 处理信息的方式：这就是常说的，理性处理问题还是感性处理问题。判断一个人是不是能够正确处理信息，关键是看当信息摆在眼前，讨论处理办法时，这个人纠结的点到底是在放在解决问题产生的利弊上，还是相关人的感受上。这个有些反人性，但确实，老好人是一个坏的决策者。 坚决执行的力度： 好多正确的决策，都是七分利三分弊，而三分弊通常伤到的是人情。创业不是慈善，要做就必须黑得下脸，狠得下心。这就是所有优秀创业者无情一面的由来。 精神魂魄当我们讨论做一件有点“大” 的事时，开门第一件事，就是用人。 用人的本事用人可以简单分为两部分，团聚众人，和激励督促众人。 先说团聚人。团聚人的终极法则很简单，就是满足其所欲。这就是一个领导者要团聚众人最基础的一条，要有智慧看透，并运用这一基本原理。当然我们可以义字当头，揭竿而起，但是如果想持久，摆脱乌合之众的气质，那大伙的基本愿望，必须得到满足，或者说有希望满足。 所以，一个聪明的领导者，一定深谙其道，明白周围这帮兄弟图什么，并且将每个人的需求的满足，设计到整个组织的运行机制当中。 这就是那句赤裸裸的名言的来历：“财散人聚。” 聚起来之后，需要保证这帮人聚而不散，那么就需要领导者可以服众。他在能力、人格、品质上，是否可为表率；对公司大方向，和关键问题的判断上，要比其他人高明；他的敬业和勤奋，足以感化众人，立为风向标，好压制务虚的风气；当出现重大危机时，是不是那个镇得住场的人，做他人主心骨。某种意义上讲，领导者的水准，就是整个公司水准的上限。 关于激励，督促大家各司其职，众志成城前行的方法，市面上有无数书籍、理论可以参考。判断一个人在这方面的水平，只需要观察他在赏罚手段上的表现。在这方面做得好的表现，借用一句话就是：雷霆手段，菩萨心肠。 格局与气度公司的层次，永远定格在创始人的格局上。 格局大的创业者，通常伴随的是挥斥方遒的潇洒气度。怎么判断一个人格局的大小呢？观察他的“被满足”和“能承担”。 各个活动（尤其与自己关系不大的活动），还有媒体上出镜率很高的人，经常被证明，事业的巅峰期基本已经过了。背后的原理是什么呢？ 因为他意识到或没有意识到，他已经满足了。没满足的人什么样呢？尚未满足的人目标高远，他们每天的生活是平淡的，但精神状态是饱满的；反之，已经鸣鸣自得的人，每天的生活内容是饱满的，但是精神状态是平淡的。 所以，他们目标明确，很清晰自己下一步该干什么；不纠缠于小事，因为很清晰自己重要的是什么，所以无关紧要的得失，处理得很潇洒；不细算自己股份到底几个点，不一味追求虚高的估值；一切都在按部就班进行，所以没什么可炫耀的，无论公司账面价值多少钱，生活状态没什么变化。 古人为什么讲“胸有激雷而面如平湖”的可拜为上将军呢？因为可以担当的沉重，才可以成就的高远。 那些危难面前不改色，困境当头仍从容的人，才有更大的心脏，撑得起更大的局面，熬得过更大的坎。与此相对应，那些经常处于匆匆忙忙，慌慌张张的人，是缺乏历练的表现。 自我进化的基因我们要承认作为一个人的局限性。创业项目不同的阶段，侧重的是创业者不同的技能。一个初创公司和最终的独角兽公司的掌舵者，一定拥有完全不一样的见识、胸怀和价值观。 一个创业者做成功了，他自己其实也早已经蜕了无数层的皮。我们拿着当代商业英雄的气度和表象去对照一个小公司的创始人，是没有意义的；更实际的做法或许应该是看他有没有自我更新的潜质；无论是自己读书，还是员工的规劝，或是对高人的请教，到底多大程度在促使着创始人的变化。 在观测这个变化过程中，我们又需要很细致入微地分辨，他是毫无主见迎合，还是心悦诚服的虚心，是刚愎自用、固步自封，还是坚定果决地捍卫真理。 独立的思考出类拔萃之辈，对事物本质的见解一定高于旁人。因此，他的认识，理念一定不是听来的，而是自己总结出来的。只有具有独立思考习惯的人，才可能总结出独立的理念和见解。 在任何领域探寻本质的路上，走得很深很远的人是孤独的，但目光是笃定的。因为在他们眼里，大部分的“专家”都是认识肤浅的小学生。我们可以从无数有所成就的人身上看到这一点。不是因为成功了才笃定，是通常笃定的人才能成功。 这种人怎么识别呢？ 这种人经常的表现是，你的任何问题，他都能对答如流；你可以不认同，甚至觉得很荒谬，但是他们对于你的质疑只是含笑点头，不慌张，不飘忽；他们对于自己下一步做什么，怎么做异常清晰，对于业内失败案例的点评，一般不是类似于“他产品做的烂”这样的“一元化”的概括；他们不会把自己的商业模式当个宝，捂得紧紧的怕人知道。 时运命数本来，我以为自己历数经历，可以总结得更多，更全面，以期完成一个非常完整的“手册”。但我忽然想到两个问题，戛然而止，没有继续下去的动力：1、我们可以穷尽这些“成大事”者的所有特质吗？ 2、假设有具备这些特质的人，就一定会成吗？ 或者说在很多关键环节有致命短板的人就一定一事无成吗？ 答案都是否定的。 面对这个茫茫宇宙，我们太过于渺小，无论是在时间上、空间上、还是认知上，以至于我们的一切文明成就都不过是基于观察而做的规律的总结，而从未运用宇宙的最基本原理，主动创造什么。 比如，哪怕是关于人类自己，我们是怎么来到世界上的，我们也不过是只能观察一个婴儿从一个受精卵逐步发育成人，到分娩的全过程，而人为干预的成分实在太少了。 就像是一个软件程序，我们一般人只能通过使用，观察总结出来，你点击哪里，会得到怎么样的回馈，而没有办法知道其背后的源代码是怎么写的，更不可能懂得编译后的class文件。 人类的喜怒哀乐，一代代的更新交替，又何尝不是一种更高等生命程序员的杰作？ 人类也是一种程序，我们按照既定的规律运行，设定了很多人性参数，也会抛出异常。我们把那个看不见的神秘的“人类程序”的编程者，称之为“上帝”。 跑题了？ 其实没有。 明白了我们的渺小，就会改变看待事情的态度。尽管前边写了好多“成大事”者总结，但是，所有的因素中，最关键的一点，就是命运。在此因素面前，一切都是不值一提。 古人讲，一命二运三风水四积德五读书。 这不是迷信。 读书改变命运，是一般人一眼可以看穿的现象；然而积德是帮我们越走越宽，逐步改变生活的，那就需要有推理能力和洞察力才可以明白了；至于风水已经不是我们人这个层面可以轻松看明白的东西了；至于运，甚至命，我们只能祈祷了，这是现在人类想理解都理解不了的。 创业这个事，永远不存在英雄造时势。 那么，在“天命”面前，我们可以做什么呢？ 首先存敬畏之心，就不用一味地奢望十拿九稳的结果，投资也好，创业也罢，学会用一种“概率论”的思维，去代替那种极端的“人定胜天”的思维，是我能想到的最好的处理方式。 总结写到最后，我发现一个现象，这些看似松散的褒义词的词汇，其实是有某种关联和共性的。 一个人，他以身作则，坚持制度，保障各司其职，有序推进，可以组织好众人，我们可以简称为：“礼”； 他树立正确是非观，价值观，赏罚分明，公平开明，言出必行，足以服众，我们可以简称为：“义”； 他有胸怀，慈悲心肠，有成全周围众人之心，足以凝聚众人，我们可以简称为：“仁”； 他有智慧感知，发现众人的愿景和欲望，知道如何才能满足其所欲，我们可以简称为：“得（德）”； 他不断学习，独立思考，尊重本质，遵循这些本质的规律，并顺应它们，我们可以称之为：“道”。 尊重本质规律（道），明白众人之所欲（得/德），并有胸怀和慈悲之心满足他们（仁），用一种公正、诚信的价值观凝聚众人（义），用以身作则的表率和赏罚分明的制度来约束，督促众人（礼）， 这就是成就任何伟大事业的必备逻辑。我们所总结的“成大事者”的任何品质，从来没有跳出过这个范畴。 《素书》的开篇第一句：“夫道、德、仁、义、礼五者，一体也。”以上是我的理解。","categories":[{"name":"随笔","slug":"随笔","permalink":"http://www.sillystone.info/categories/随笔/"}],"tags":[{"name":"文摘","slug":"文摘","permalink":"http://www.sillystone.info/tags/文摘/"},{"name":"鸡汤","slug":"鸡汤","permalink":"http://www.sillystone.info/tags/鸡汤/"}]},{"title":"ELK","date":"2017-08-14T06:16:28.000Z","path":"2017/08/14/ELK/","text":"案例背景介绍本来想学用一下flume， 把多台服务器的日志做统一处理，查阅资料后发现ELK更适合就尝试着搭建了ELK服务， 其实是ELKF（Elasticsearch logstash kibana Filebeat） 日志来源于两台服务器上的2个（4个： 2*2）应用； 日志采用log4j格式打印，目前设置日志级别为INFO，因此日志量比较大。 解决的问题： 登录多个服务器上查找日志 环境&amp;部署filebeat分别部署在2台应用服务器上，logstash单独部署（grok耗费资源），es和kibana部署在一台服务器（es作为存储 需提前分配存储空间） Filebeat介绍使用filebeat是因为 主要担心logstash与应用服务器 抢占资源。filebeat支持直接输出到elasticsearch（日志文件为json格式可以直接输出到es），也可以输出到logstash（本案例使用grok解析日志格式），也支持Redis 和 RocketMQ 安装 -linux x86_641wget https://artifacts.elastic.co/downloads/beats/filebeat/filebeat-6.0.0-beta1-linux-x86_64.tar.gz 官网下载 其他版本 配置编辑 filebeat.yml 直接按照注释的说明就可以配置文件路径支持通配符123456# 日志文件路径-path /opt/../../../server*/System*.log# elasticsearch 配置# logstatsh 配置 运行12./filebeat -e -c filebeat.ymlnohup ./filebeat -e -c filebeat.yml &gt;/dev/null 2&gt;&amp;1 &amp; logstash介绍logstash 可以读流文件（socket读取），也可以多个logstash agent输出到logstash汇总应用本案例主要使用logstash解决两个问题： grok解析日志 生成json格式 多行输入的解析处理 安装1wget https://artifacts.elastic.co/downloads/logstash/logstash-5.5.1.tar.gz 依赖： jdk 1.8 配置 config文件config文件主要定义用户的处理规则注意： conf目录下的配置文件是logstash的基础配置文件，主要包括jvm配置和服务配置主要的工作量： 配置grok表达式以解析应用日志。 参考官网的配置示例最终的配置如下：12 grok说明说明： 自定义的pattern 可自定义存储，比如：patterns/extra, grok引入即可使用123456789# contents of ./patterns/postfix:POSTFIX_QUEUEID [0-9A-F]&#123;10,11&#125;# filter &#123; grok &#123; patterns_dir =&gt; [\"./patterns\"] match =&gt; &#123; \"message\" =&gt; \"%&#123;SYSLOGBASE&#125; %&#123;POSTFIX_QUEUEID:queue_id&#125;: %&#123;GREEDYDATA:syslog_message&#125;\" &#125; &#125;&#125; 正则说明\\s：匹配任何不可见字符，包括空格、制表符、换页符等等。等价于[ \\f\\n\\r\\t\\v]。+表示匹配次数为1次或者多次 (?:pattern)非获取匹配，匹配pattern但不获取匹配结果，不进行存储供以后使用。这在使用或字符“(|)”来组合一个模式的各个部分是很有用。例如“industr(?:y|ies)”就是一个比“industry|industries”更简略的表达式。(?=pattern)非获取匹配，正向肯定预查，在任何匹配pattern的字符串开始处匹配查找字符串，该匹配不需要获取供以后使用。例如，“Windows(?=95|98|NT|2000)”能匹配“Windows2000”中的“Windows”，但不能匹配“Windows3.1”中的“Windows”。预查不消耗字符，也就是说，在一个匹配发生后，在最后一次匹配之后立即开始下一次匹配的搜索，而不是从包含预查的字符之后开始。(?!pattern)非获取匹配，正向否定预查，在任何不匹配pattern的字符串开始处匹配查找字符串，该匹配不需要获取供以后使用。例如“Windows(?!95|98|NT|2000)”能匹配“Windows3.1”中的“Windows”，但不能匹配“Windows2000”中的“Windows”。(?&lt;=pattern)非获取匹配，反向肯定预查，与正向肯定预查类似，只是方向相反。例如，“(?&lt;=95|98|NT|2000)Windows”能匹配“2000Windows”中的“Windows”，但不能匹配“3.1Windows”中的“Windows”。(?&lt;!pattern)非获取匹配，反向否定预查，与正向否定预查类似，只是方向相反。例如“(?&lt;!95|98|NT|2000)Windows”能匹配“3.1Windows”中的“Windows”，但不能匹配“2000Windows”中的“Windows”。这个地方不正确，有问题 .\\d+：表示点后面跟一个或者多个 数字，(?:.\\d+)?表示点后面跟一个或多个数字这种情况出现0次或者多次，如果为0次，则request_time为一个整数。所以匹配到的结果可能为123.456或者123或者123.4.5.6，这些都满足条件 分组语法 捕获(exp) 匹配exp,并捕获文本到自动命名的组里(?exp) 匹配exp,并捕获文本到名称为name的组里，也可以写成(?’name’exp)(?:exp) 匹配exp,不捕获匹配的文本位置指定(?=exp) 匹配exp前面的位置(?&lt;=exp) 匹配exp后面的位置(?!exp) 匹配后面跟的不是exp的位置(?&lt;!exp) 匹配前面不是exp的位置注释(?#comment) 这种类型的组不对正则表达式的处理产生任何影响，只是为了提供让人阅读注释 grok使用测试网站：grokdebug.herokuapp.com参考示例 运行123bin/logstash -f logstash.conf [-path conf]nohup bin/logstash -f etc/ &amp; 详细的命令行参数说明 ES介绍安装1wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-5.5.1.tar.gz 依赖 jdk1.8 运行12bin/elasticsearchbin/elasticsearch -d #后台运行 说明： 不能使用root 启动，为es单独建用户 vim /etc/sysctl.confvm.max_map_count=655360 vim /etc/security/limits.conf hard nofile 65536 soft nofile 65536 es使用curl –silent ‘http://127.0.0.1:9200/_cat/indices‘ | cut -d\\ -f2 /_aliases?pretty=1 /_stats/_stats/{metric}/_stats/{metric}/{indexMetric}/{index}/_stats/{index}/_stats/{metric} Elasticsearch关键概念根据官网自己的介绍，Elasticsearch是一个分布式搜索服务，提供Restful API，底层基于Lucene，采用多shard的方式保证数据安全，并且提供自动resharding的功能，加之github等大型的站点也采用Elasticsearch作为其搜索服务，我们决定在项目中使用Elasticsearch。 数据：Index：Elasticsearch用来存储数据的逻辑区域，它类似于关系型数据库中的db概念。一个index可以在一个或者多个shard上面，同时一个shard也可能会有多个replicas。Document：Elasticsearch里面存储的实体数据，类似于关系数据中一个table里面的一行数据。document由多个field组成，不同的document里面同名的field一定具有相同的类型。document里面field可以重复出现，也就是一个field会有多个值，即multivalued。Document type：为了查询需要，一个index可能会有多种document，也就是document type，但需要注意，不同document里面同名的field一定要是相同类型的。Mapping：存储field的相关映射信息，不同document type会有不同的mapping。对于熟悉MySQL的童鞋，我们只需要大概认为Index就是一个db，document就是一行数据，field就是table的column，mapping就是table的定义，而document type就是一个table就可以了。 服务层：Node: 一个server实例。Cluster：多个node组成cluster。Shard：数据分片，一个index可能会存在于多个shards，不同shards可能在不同nodes。Replica：shard的备份，有一个primary shard，其余的叫做replica shards。Elasticsearch之所以能动态resharding，主要在于它最开始就预先分配了多个shards（貌似是1024），然后以shard为单位进行数据迁移。这个做法其实在分布式领域非常的普遍，codis就是使用了1024个slot来进行数据迁移。 因为任意一个index都可配置多个replica，通过冗余备份的方式保证了数据的安全性，同时replica也能分担读压力，类似于MySQL中的slave Lucene关键概念Document：用来索引和搜索的主要数据源，包含一个或者多个Field，而这些Field则包含我们跟Lucene交互的数据。Field：Document的一个组成部分，有两个部分组成，name和value。Term：不可分割的单词，搜索最小单元。Token：一个Term呈现方式，包含这个Term的内容，在文档中的起始位置，以及类型。 作者：siddontang链接：http://www.jianshu.com/p/05cff717563c來源：简书著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。 kibana介绍安装 linux x86_641wget https://artifacts.elastic.co/downloads/kibana/kibana-5.5.1-linux-x86_64.tar.gz 其他版本下载 配置 config/kibana.yml Set elasticsearch.url to point at your Elasticsearch instance 运行1nohup bin/kibana &amp; 使用索引设置filebeat-*日志正常解析为多个域后， kibana会自动识别field并作为查询条件 query附：log4j 输出格式%n - 换行 %m - 日志内容 %p - 日志级别(FATAL, ERROR, WARN, INFO, DEBUG or custom) %r - 程序启动到现在的毫秒数 %% - percent sign in output %t - 当前线程名 %d - 日期和时间, 常用的格式有 %d{DATE}, %d{ABSOLUTE}, %d{HH:mm:ss,SSS}, %d{ddMMyyyy HH:mm:ss,SSS}。。。 %l - 同 %F%L%C%M %F - java源文件名 %L - java源码行数 %C - java类名,%C{1} 输出最后一个元素 %M-java方法名 待补充： es集群配置 kibana es认证设置 es中文分词","categories":[{"name":"技术","slug":"技术","permalink":"http://www.sillystone.info/categories/技术/"}],"tags":[{"name":"ELK","slug":"ELK","permalink":"http://www.sillystone.info/tags/ELK/"}]},{"title":"公交车上","date":"2017-08-12T14:12:42.000Z","path":"2017/08/12/公交车上/","text":"下雨的周末 路上车很少 我在公车上看一本书 书名叫 “坐公交车的人” 应该没什么名气 但是本很舒服的书 ， 窗外的雨有时大 有时小 偶尔几道闪电挑逗你的视线 前面的小朋友 背着一把大大的吉他 下雨的夏天 很舒服 ， 平日拥挤的城市 今天很冷清 车开的很快 我读的很慢 窗外，雨点在跳跃 ~ 书","categories":[{"name":"散文","slug":"散文","permalink":"http://www.sillystone.info/categories/散文/"}],"tags":[{"name":"散文","slug":"散文","permalink":"http://www.sillystone.info/tags/散文/"}]},{"title":"Excel","date":"2017-08-08T11:30:36.000Z","path":"2017/08/08/Excel/","text":"如何快速成为数据分析师函数技巧实战 函数清洗处理类主要是文本、格式以及脏数据的清洗和转换。很多数据并不是直接拿来就能用的，需要经过数据分析人员的清理。数据越多，这个步骤花费的时间越长。 Trim 清除掉字符串两边的空格。 MySQL有同名函数，Python有近似函数strip。 Concatenate =Concatenate(单元格1，单元格2……) 合并单元格中的内容，还有另一种合并方式是&amp; 。”我”&amp;”很”&amp;”帅” ＝ 我很帅。当需要合并的内容过多时，concatenate的效率快也优雅。 MySQL有近似函数concat。 Replace =Replace（指定字符串，哪个位置开始替换，替换几个字符，替换成什么） 替换掉单元格的字符串，清洗使用较多。 MySQL中有同名函数，Python中有同名函数。 Substitute 和replace接近，区别是替换为全局替换，没有起始位置的概念 Left／Right／Mid =Mid(指定字符串，开始位置，截取长度) 截取字符串中的字符。Left/Right（指定字符串，截取长度）。left为从左，right为从右，mid如上文示意。 MySQL中有同名函数。 Len／Lenb 返回字符串的长度，在len中，中文计算为一个，在lenb中，中文计算为两个。MySQL中有同名函数，Python中有同名函数。 Find =Find（要查找字符，指定字符串，第几个字符） 查找某字符串出现的位置，可以指定为第几次出现，与Left／Right／Mid结合能完成简单的文本提取MySQL中有近似函数 find_in_set，Python中有同名函数。 Search 和Find类似，区别是Search大小写不敏感，但支持＊通配符 Text 将数值转化为指定的文本格式，可以和时间序列函数一起看 关联匹配类在进行多表关联或者行列比对时用到的函数，越复杂的表用得越多。多说一句，良好的表习惯可以减少这类函数的使用。 Lookup =Lookup（查找的值，值所在的位置，返回相应位置的值） 最被忽略的函数，功能性和Vlookup一样，但是引申有数组匹配和二分法。 Vlookup =Vlookup(查找的值，哪里找，找哪个位置的值，是否精准匹配) Excel第一大难关，因为涉及的逻辑对新手较复杂，通俗的理解是查找到某个值然后黏贴过来。 Index ＝Index（查找的区域，区域内第几行，区域内第几列） 和Match组合，媲美Vlookup，但是功能更强大。 Match ＝Match（查找指定的值，查找所在区域，查找方式的参数） 和Lookup类似，但是可以按照指定方式查找，比如大于、小于或等于。返回值所在的位置。 Row 返回单元格所在的行 Column 返回单元格所在的列 Offset ＝Offset（指定点，偏移多少行，偏移多少列，返回多少行，返回多少列） 建立坐标系，以坐标系为原点，返回距离原点的值或者区域。正数代表向下或向右，负数则相反。 逻辑运算类数据分析中不得不用到逻辑运算，逻辑运算返回的均是布尔类型，True和False。很多复杂的数据分析会牵扯到较多的逻辑运算 IF 经典的如果但是，在后期的Python中，也会经常用到，当然会有许多更优雅的写法。也有ifs用法，取代if(and())的写法。 MySQL中有同名函数，Python中有同名函数。 And 全部参数为True，则返回True，经常用于多条件判断。 MySQL中有同名函数，Python中有同名函数。 Or 只要参数有一个True，则返回Ture，经常用于多条件判断。 MySQL中有同名函数，Python中有同名函数。 IS系列 常用判断检验，返回的都是布尔数值True和False。常用ISERR，ISERROR，ISNA，ISTEXT，可以和IF嵌套使用。 计算统计类常用的基础计算、分析、统计函数，以描述性统计为准。具体含义在后续的统计章节再展开。 Sum／Sumif／Sumifs 统计满足条件的单元格总和，SQL有中同名函数。 MySQL中有同名函数，Python中有同名函数。 Sumproduct 统计总和相关，如果有两列数据销量和单价，现在要求卖出增加，用sumproduct是最方便的。 MySQL中有同名函数。 Count／Countif／Countifs 统计满足条件的字符串个数 MySQL中有同名函数，Python中有同名函数。 Max 返回数组或引用区域的最大值 MySQL中有同名函数，Python中有同名函数。 Min 返回数组或引用区域的最小值 MySQL中有同名函数，Python中有同名函数。 Rank 排序，返回指定值在引用区域的排名，重复值同一排名。 SQL中有近似函数row_number() 。 Rand／Randbetween 常用随机抽样，前者返回0~1之间的随机值，后者可以指定范围。 MySQL中有同名函数。 Averagea 求平均值，也有Averageaif，Averageaifs MySQL中有同名函数，python有近似函数mean。 Quartile =Quartile（指定区域，分位参数） 计算四分位数，比如1~100的数字中，25分位就是按从小到大排列，在25%位置的数字，即25。参数0代表最小值，参数4代表最大值，1~3对应25、50（中位数）、75分位 Stdev 求标准差，统计型函数，后续数据分析再讲到 Substotal =Substotal（引用区域，参数） 汇总型函数，将平均值、计数、最大最小、相乘、标准差、求和、方差等参数化，换言之，只要会了这个函数，上面的都可以抛弃掉了。 Int／Round 取整函数，int向下取整，round按小数位取数。 round(3.1415,2) =3.14 ; round(3.1415,1)=3.1 时间序列类专门用于处理时间格式以及转换，时间序列在金融、财务等数据分析中占有较大比重。时机序列的处理函数比我列举了还要复杂，比如时区、分片、复杂计算等。这里只做一个简单概述。 Year 返回日期中的年 MySQL中有同名函数。 Month 返回日期中的月 MySQL中有同名函数。 Weekday =Weekday(指定时间，参数) 返回指定时间为一周中的第几天，参数为1代表从星期日开始算作第一天，参数为2代表从星期一开始算作第一天（中西方差异）。我们中国用2为参数即可。 MySQL中有同名函数。 Weeknum =Weeknum(指定时间，参数) 返回一年中的第几个星期，后面的参数类同weekday，意思是从周日算还是周一。 MySQL中有近似函数 week。 Day 返回日期中的日（第几号） MySQL中有同名函数。 Date =Date（年，月，日） 时间转换函数，等于将year()，month()，day()合并 MySQL中有近似函数 date_format。 Now 返回当前时间戳，动态函数 MySQL中有同名函数。 Today 返回今天的日期，动态函数 MySQL中有同名函数。 Datedif =Datedif（开始日期，结束日期，参数） 日期计算函数，计算两日期的差。参数决定返回的是年还是月等。 MySQL中有近似函数 DateDiff。","categories":[],"tags":[]},{"title":"db2 问题汇总","date":"2017-08-08T09:37:22.000Z","path":"2017/08/08/db2-问题汇总/","text":"创建数据库创建数据库失败， 报错： 解决:数据库名称不能和主机名相同， 修改主机名解决。 DATA CAPTURE数据库运行缓慢， 存在等待的内容是： ALTER TABLE t_table_name DATA CAPTURE NONE 以下是查询出来的 关于DATA CAPTURE解释：For updates, DB2 records undo/ redo records in the log. There’s an option on a CREATE or ALTER TABLE definition called DATA CAPTURE. The two settings are DATA CAPTURE CHANGES or DATA CAPTURE NONE, the default being NONE. For inserts and deletes, DB2 is always recording a full image of the row affected, but for updates, DB2 can minimize the data recorded in the log. The DATA CAPTURE CHANGES feature tells DB2 you’re planning to use the log information for some sort of data replication or log analysis. There are several data replication tools that can read log records or use a DB2 log exit to replicate database changes to other databases or processes. In order for the replication to work properly for updates, it needs the entire before and after image of the rows changed. So, DATA CAPTURE CHANGES will cause DB2 to log the entire before and after images of rows changed via update statements in the undo/redo records in the log. DB2 will minimize the information logged during updates if DATA CAPTURE NONE is set for a table. A good performance practice is to specify DATA CAPTURE NONE for a table unless you’re specifically planning on replicating the table via a product that reads log records.","categories":[{"name":"技术","slug":"技术","permalink":"http://www.sillystone.info/categories/技术/"}],"tags":[{"name":"db2","slug":"db2","permalink":"http://www.sillystone.info/tags/db2/"}]},{"title":"数据架构","date":"2017-08-05T05:25:10.000Z","path":"2017/08/05/数据架构/","text":"读完数据架构 摘要 封面 典型企业架构模型 词汇","categories":[{"name":"技术","slug":"技术","permalink":"http://www.sillystone.info/categories/技术/"}],"tags":[{"name":"数据架构","slug":"数据架构","permalink":"http://www.sillystone.info/tags/数据架构/"}]},{"title":"Das Leben der Anderen","date":"2017-08-04T16:35:38.000Z","path":"2017/08/05/Das-Leben-der-Anderen/","text":"Das Leben der Anderen– 79th Academy Awards 最佳外语片 从此喜欢上德国电影 HGW XX/7","categories":[{"name":"散文","slug":"散文","permalink":"http://www.sillystone.info/categories/散文/"}],"tags":[{"name":"日记","slug":"日记","permalink":"http://www.sillystone.info/tags/日记/"}]},{"title":"一只蚊子","date":"2017-08-02T12:30:21.000Z","path":"2017/08/02/一只蚊子/","text":"等公车的时候，猛地觉得手背有点疼， 发现一只黑色的蚊子在我手背上 我是那种手背血管凸起的体质， 它伏在一根凸起的血管上，享受着 我把手中的伞放下， 飞起一巴掌，留下一滩血迹 我的血，比我想象中要红，也更大 迅速擦掉，我忍不了血色 今天是个下雨天，闷热潮湿的桑拿天 蚊子活跃的天气 可能他们也不喜欢这么热 太热了就需要解渴的饮料 就得忙碌着找我这样的 不幸的是它遇到了我 其实我还算是个好人 一般被叮一两下也无所谓 忍几天就慢慢好了 也不是我心肠特好 主要是一般察觉不到被咬 这只蚊子，也是个没心眼的家伙 中了头彩遇到我 还找到了血管 开心的昏头了吧，吸这么大口 吸得我都觉得 被吸走三成功力 活该被拍死啊 雨莫名的下大了，车还不来。。。 它也真是不走运 为什么要吸那么大口呢，慢慢喝就好了 可能因为晚饭没吃饭吧，血糖估计很低 慢慢吸估计不过瘾 我就不喜欢慢慢吸，喝酸奶喜欢用勺 哎，可怜的家伙 公车终于来了， 已经快8点了，车上没几个人 有了空调舒服多了。 手背上慢慢肿了一点 不过还好，没有肿很高。 我对南方的蚊子过敏，手会肿的和馒头一样 它是北方的 可怜的家伙，死了都留不下一个包 哎，这个下雨的夜晚 突然想起了你 饭好了，我去吃了。","categories":[{"name":"散文","slug":"散文","permalink":"http://www.sillystone.info/categories/散文/"}],"tags":[{"name":"日记","slug":"日记","permalink":"http://www.sillystone.info/tags/日记/"}]},{"title":"AWS 技术峰会","date":"2017-07-26T14:59:59.000Z","path":"2017/07/26/AWS-技术峰会/","text":"AWS峰会，国家会议中心，逃班散心 AWS 产品基础服务 计算： EC2， EC2 container service，AWS Lambda 数据： Amazon Aurora， Amazon RDS，Amazon ElastiCache， Amazon Redshift 运维相关 存储： S3 网络： 管理工具 安全身份合规：AWS Shield 开发应用支撑 人工智能： Amazon lex, Amazon Rekognition, Amazon Polly Iot: 大数据（分析）：Amazon Athena Amazon ERM（hadoop） Kinesis Redshift NOTE 云服务： Amazon Microsoft google 云上的数据中心方案，混合云方案，本地数据&amp;云数据结合方案（关键：网络，安全） 基于云服务的开发测试部署方案 Iot 照片","categories":[{"name":"技术","slug":"技术","permalink":"http://www.sillystone.info/categories/技术/"}],"tags":[{"name":"AWS技术峰会","slug":"AWS技术峰会","permalink":"http://www.sillystone.info/tags/AWS技术峰会/"}]},{"title":"我的前半生","date":"2017-07-25T03:44:17.000Z","path":"2017/07/25/wo-de-qian-ban-sheng/","text":"讲的太透彻，活的太精明，能有多少快乐。","categories":[{"name":"随笔","slug":"随笔","permalink":"http://www.sillystone.info/categories/随笔/"}],"tags":[{"name":"日记","slug":"日记","permalink":"http://www.sillystone.info/tags/日记/"}]},{"title":"Freemarker cache","date":"2017-07-21T08:03:26.000Z","path":"2017/07/21/Freemarker-cache/","text":"模板缓存 说明FreeMarker 是会缓存模板的(假设使用 Configuration 对象的方法来创建 Template 对象)。这就是说当调用 getTemplate方法时，FreeMarker不但返回了 Template 对象，而且还会将它存储在缓存中， 当下一次再以相同(或相等)路径调用 getTemplate 方法时， 那么它只返回缓存的 Template 实例， 而不会再次加载和解析模板文件了。 如果更改了模板文件，当下次调用模板时，FreeMarker 将会自动重新载入和解析模板。 然而，要检查模板文件是否改变内容了是需要时间的，有一个 Configuration 级别的设置被称作”更新延迟”，它可以用来配置这个时间。 这个时间就是从上次对某个模板检查更新后，FreeMarker再次检查模板所要间隔的时间。 其默认值是5秒。如果想要看到模板立即更新的效果，那么就要把它设置为0。 要注意某些模板加载器也许在模板更新时可能会有问题。 例如，典型的例子就是在基于类加载器的模板加载器就不会注意到模板文件内容的改变。 当调用了 getTemplate 方法时， 与此同时FreeMarker意识到这个模板文件已经被移除了，所以这个模板也会从缓存中移除。 如果Java虚拟机认为会有内存溢出时，默认情况它会从缓存中移除任意模板。 此外，你还可以使用 Configuration 对象的 clearTemplateCache 方法手动清空缓存。 何时将一个被缓存了的模板清除的实际应用策略是由配置的属性 cache_storage 来确定的，通过这个属性可以配置任何 CacheStorage 的实现。对于大多数用户来说， 使用 freemarker.cache.MruCacheStorage 就足够了。 这个缓存存储实现了二级最近使用的缓存。在第一级缓存中， 组件都被强烈引用到特定的最大数目(引用次数最多的组件不会被Java虚拟机抛弃， 而引用次数很少的组件则相反)。当超过最大数量时， 最近最少使用的组件将被送至二级缓存中，在那里它们被很少引用， 直到达到另一个最大的数目。引用强度的大小可以由构造方法来指定。 例如，设置强烈部分为20，轻微部分为250： cfg.setCacheStorage(new freemarker.cache.MruCacheStorage(20, 250))或者，使用 MruCacheStorage 缓存， 它是默认的缓存存储实现： cfg.setSetting(Configuration.CACHE_STORAGE_KEY, “strong:20, soft:250”);当创建了一个新的 Configuration 对象时， 它使用一个 strongSizeLimit 值为0的 MruCacheStorage 缓存来初始化， softSizeLimit 的值是 Integer.MAX_VALUE (也就是在实际中，是无限大的)。但是使用非0的 strongSizeLimit 对于高负载的服务器来说也许是一个更好的策略，对于少量引用的组件来说， 如果资源消耗已经很高的话，Java虚拟机往往会引发更高的资源消耗， 因为它不断从缓存中抛出经常使用的模板，这些模板还不得不再次加载和解析 spring示例12345&lt;bean id=\"freemarkerMailConfiguration\" class=\"org.springframework.ui.freemarker.FreeMarkerConfigurationFactoryBean\"&gt; &lt;property name=\"templateLoaderPaths\" value=\"classpath:emailtemplates/task,classpath:emailtemplates/user\"/&gt; &lt;!-- Activate the following to disable template caching --&gt; &lt;property name=\"freemarkerSettings\" value=\"cache_storage=freemarker.cache.NullCacheStorage\" /&gt;&lt;/bean&gt; 自定义 freemarkerConfigure 123456&lt;bean id=\"freemarkerConfig\" class=\"com.xxxx.framework.web.EasyFreeMarkerConfigurer\"&gt; &lt;property name=\"freemarkerSettings\"&gt; &lt;props&gt; &lt;prop key=\"cache_storage\"&gt;freemarker.cache.NullCacheStorage&lt;/prop&gt; &lt;/props&gt; &lt;/property&gt; 1234567public class EasyFreeMarkerConfigurer extends FreeMarkerConfigurer &#123; // ... public void setfreemarkerSettings(Properties settings) &#123; // ... user defined super.setFreemarkerSettigs(settings); &#125;&#125;","categories":[{"name":"技术","slug":"技术","permalink":"http://www.sillystone.info/categories/技术/"}],"tags":[{"name":"java","slug":"java","permalink":"http://www.sillystone.info/tags/java/"},{"name":"freemarker","slug":"freemarker","permalink":"http://www.sillystone.info/tags/freemarker/"}]},{"title":"google translate","date":"2017-07-14T01:07:23.000Z","path":"2017/07/14/google-translate/","text":"需求使用Google translate api 批量翻译文件 调研Google translate API官方文档 需要使用google云平台提供的服务 开通云平台（试用1年） 新建google translate 项目 生成key 使用限制： 每天 2,000,000 characters 100 seconds 100,000 characters 100 seconds 1000 request Google会提供每日统计结果。 javascript for google translate api使用github 上Localize 的google-translate 多语言文件处理(csv格式)使用github 上 fast-csv 开发问题一，javascript stream 处理readstream -&gt; pipe( processStream )processStream -&gt; pipe( writeStream) fast-csv 即 processStreamon(“data”, callProcessFunction(){//process;}) 问题二，nodejs 实现 for循环中 同步等待后执行原因： 单条循环调用，差不多500多笔 google开始返回报错 解决思路：使用 定时器，每批调用后 等待3秒， 需要同步等待尝试了 generator co最终： 使用递归调用 1234567891011121314151617181920212223242526272829303132333435363738394041424344let csvdata = []; // array for translatelet ITEM_SIZe = 20; // translate record number every time// for iterator sleep delay sencondsfunction forWithDelay(i, length, array, fn, delay) &#123; setTimeout(function () &#123; fn(i, length, array); i++; if (i * length &lt; array.length) &#123; forWithDelay(i, length, array, fn, delay); &#125; &#125;, delay);&#125;// function call google translate &amp; process data copy from array function callTranslate(i, length, array) &#123; let tranData = []; const arrayLength = array.length; for( let j = 0; j&lt;length; j++) &#123; if (i*length + j &lt; arrayLength)&#123; tranData[j] = array[i*length +j][1]; array[i*length +j][2] =\"AA\"; //console.log(array[i*length +j]); &#125; &#125; googleTranslate.translate(tranData, 'en', function(err, translation) &#123; if (err) &#123; console.log(err.stack()); return; &#125; if (!translation ) &#123; console.log(\"EEE\"); &#125; else &#123; translation.forEach(function(item,index,arr) &#123; console.log(index); console.log(item.translatedText); array[i*length+index][2] = item.translatedText; console.log(array[i*length+index]); csvWriteStream.write(array[i*length+index]); &#125;); &#125; &#125;);&#125;forWithDelay(0, ITEM_SIZE, csvdata, callTranslate, 3000);","categories":[{"name":"技术","slug":"技术","permalink":"http://www.sillystone.info/categories/技术/"}],"tags":[{"name":"javascript","slug":"javascript","permalink":"http://www.sillystone.info/tags/javascript/"}]},{"title":"背影","date":"2017-07-06T15:07:10.000Z","path":"2017/07/06/背影/","text":"我怀念往昔 那纯真， 那失败， 那多情， 那冷漠~~~ 然而， 我总怀念， 不是那时光， 是那背影。","categories":[],"tags":[{"name":"诗","slug":"诗","permalink":"http://www.sillystone.info/tags/诗/"}]},{"title":"mariadb","date":"2017-07-04T07:23:59.000Z","path":"2017/07/04/mariadb/","text":"存储引擎存储引擎介绍 XtraDB is the best choice in the majority of cases. It is a performance-enhanced fork of InnoDB and is MariaDB&apos;s default engine until MariaDB 10.1. InnoDB is a good general transaction storage engine. It is the default MySQL storage engine, and default MariaDB 10.2 storage engine, but in earlier releases XtraDB is a performance enhanced fork of InnoDB, and is usually preferred. Aria, MariaDB&apos;s more modern improvement on MyISAM, has a small footprint and allows for easy copying between systems. MyISAM has a small footprint and allows for easy copying between systems. MyISAM is MySQL&apos;s oldest storage engine. There is usually little reason to use it except for legacy purposes. Aria is MariaDB&apos;s more modern improvement. InnODB引擎支持众多特性：a) 支持ACID，简单地说就是支持事务完整性、一致性；b) 支持行锁，以及类似ORACLE的一致性读，多用户并发；c) 独有的聚集索引主键设计方式，可大幅提升并发读写性能；d) 支持外键；e) 支持崩溃数据自修复；","categories":[{"name":"技术","slug":"技术","permalink":"http://www.sillystone.info/categories/技术/"}],"tags":[{"name":"mariadb","slug":"mariadb","permalink":"http://www.sillystone.info/tags/mariadb/"}]},{"title":"redis","date":"2017-07-04T06:13:42.000Z","path":"2017/07/04/redis-config/","text":"detail info 参考资料redis fans 核心概念Redis 核心概念 概述Redis 与其他 key – value 缓存产品有以下三个特点： 1.Redis支持数据的持久化，可以将内存中的数据保持在磁盘中，重启的时候可以再次加载进行使用2.Redis不仅仅支持简单的key-value类型的数据，同时还提供list，set，zset，hash等数据结构的存储。3.Redis支持数据的备份，即master-slave模式的数据备份。 Redis 优势 性能极高 – Redis能读的速度是110000次/s,写的速度是81000次/s 。 丰富的数据类型 – Redis支持二进制案例的 Strings, Lists, Hashes, Sets 及 Ordered Sets 数据类型操作。 原子 – Redis的所有操作都是原子性的，同时Redis还支持对几个操作全并后的原子性执行。 丰富的特性 – Redis还支持 publish/subscribe, 通知, key 过期等等特性。 Redis与其他key-value存储有什么不同？ Redis有着更为复杂的数据结构并且提供对他们的原子性操作，这是一个不同于其他数据库的进化路径。Redis的数据类型都是基于基本数据结构的同时对程序员透明，无需进行额外的抽象。 Redis运行在内存中但是可以持久化到磁盘，所以在对不同数据集进行高速读写时需要权衡内存，应为数据量不能大于硬件内存。在内存数据库方面的另一个优点是， 相比在磁盘上相同的复杂的数据结构，在内存中操作起来非常简单，这样Redis可以做很多内部复杂性很强的事情。 同时，在磁盘格式方面他们是紧凑的以追加的方式产生的，因为他们并不需要进行随机访问。 数据类型 String（字符串）:string是redis最基本的类型，你可以理解成与Memcached一模一样的类型，一个key对应一个value。string类型是二进制安全的。意思是redis的string可以包含任何数据。比如jpg图片或者序列化的对象 。 string类型是Redis最基本的数据类型，一个键最大能存储512MB。 Hash（哈希）Redis hash 是一个键值对集合。Redis hash是一个string类型的field和value的映射表，hash特别适合用于存储对象。 每个 hash 可以存储 2 *32 – 1键值对（40多亿）。 List（列表）Redis 列表是简单的字符串列表，按照插入顺序排序。你可以添加一个元素导列表的头部（左边）或者尾部（右边）。列表最多可存储 2*32 – 1元素 (4294967295, 每个列表可存储40多亿)。 Set（集合）Redis的Set是string类型的无序集合。集合是通过哈希表实现的，所以添加，删除，查找的复杂度都是O(1)。集合中最大的成员数为 2 32 – 1(4294967295, 每个集合可存储40多亿个成员)。* zset(sorted set：有序集合)Redis zset 和 set 一样也是string类型元素的集合,且不允许重复的成员。不同的是每个元素都会关联一个double类型的分数。redis正是通过分数来为集合中的成员进行从小到大的排序。zset的成员是唯一的,但分数(score)却可以重复。 基本概念 HyperLogLog Redis在 2.8.9 版本添加了 HyperLogLog 结构。Redis HyperLogLog 是用来做基数统计的算法，HyperLogLog 的优点是，在输入元素的数量或者体积非常非常大时，计算基数所需的空间总是固定 的、并且是很小的。 在 Redis 里面，每个 HyperLogLog 键只需要花费 12 KB 内存，就可以计算接近 2^64 个不同元素的基 数。这和计算基数时，元素越多耗费内存就越多的集合形成鲜明对比。 但是，因为 HyperLogLog 只会根据输入元素来计算基数，而不会储存输入元素本身，所以 HyperLogLog 不能像集合那样，返回输入的各个元素。 什么是基数? 比如数据集 {1, 3, 5, 7, 5, 7, 8}， 那么这个数据集的基数集为 {1, 3, 5 ,7, 8}, 基数(不重复元素)为5。 基数估计就是在误差可接受的范围内，快速计算基数。 发布订阅Redis 发布订阅(pub/sub)是一种消息通信模式：发送者(pub)发送消息，订阅者(sub)接收消息。Redis 客户端可以订阅任意数量的频道。 下图展示了频道 channel1 ， 以及订阅这个频道的三个客户端 —— client2 、 client5 和 client1 之间的关系：当有新消息通过 PUBLISH 命令发送给频道 channel1 时， 这个消息就会被发送给订阅它的三个客户端： Redis 事务Redis 事务可以一次执行多个命令， 并且带有以下两个重要的保证： 事务是一个单独的隔离操作：事务中的所有命令都会序列化、按顺序地执行。事务在执行的过程中，不会被其他客户端发送来的命令请求所打断。 事务是一个原子操作：事务中的命令要么全部被执行，要么全部都不执行。 一个事务从开始到执行会经历以下三个阶段： a. 开始事务。 b. 命令入队。 c. 执行事务。 复制（Replication）Redis 支持简单且易用的主从复制（master-slave replication）功能， 该功能可以让从服务器(slave server)成为主服务器(master server)的精确复制品。 以下是关于 Redis 复制功能的几个重要方面： Redis 使用异步复制。 从 Redis 2.8 开始， 从服务器会以每秒一次的频率向主服务器报告复制流（replication stream）的处理进度。 一个主服务器可以有多个从服务器。 不仅主服务器可以有从服务器， 从服务器也可以有自己的从服务器， 多个从服务器之间可以构成一个图状结构。 复制功能不会阻塞主服务器： 即使有一个或多个从服务器正在进行初次同步， 主服务器也可以继续处理命令请求。 复制功能也不会阻塞从服务器： 只要在 redis.conf 文件中进行了相应的设置， 即使从服务器正在进行初次同步， 服务器也可以使用旧版本的数据集来处理命令查询。不过， 在从服务器删除旧版本数据集并载入新版本数据集的那段时间内， 连接请求会被阻塞。你还可以配置从服务器， 让它在与主服务器之间的连接断开时， 向客户端发送一个错误。 复制功能可以单纯地用于数据冗余（data redundancy）， 也可以通过让多个从服务器处理只读命令请求来提升扩展性（scalability）： 比如说， 繁重的 SORT 命令可以交给附属节点去运行。7 .可以通过复制功能来让主服务器免于执行持久化操作： 只要关闭主服务器的持久化功能， 然后由从服务器去执行持久化操作即可。 复制功能的运作原理无论是初次连接还是重新连接， 当建立一个从服务器时， 从服务器都将向主服务器发送一个 SYNC 命令。接到 SYNC 命令的主服务器将开始执行 BGSAVE ， 并在保存操作执行期间， 将所有新执行的写入命令都保存到一个缓冲区里面。 当 BGSAVE 执行完毕后， 主服务器将执行保存操作所得的 .rdb 文件发送给从服务器， 从服务器接收这个 .rdb 文件， 并将文件中的数据载入到内存中。 之后主服务器会以 Redis 命令协议的格式， 将写命令缓冲区中积累的所有内容都发送给从服务器。 你可以通过 telnet 命令来亲自验证这个同步过程： 首先连上一个正在处理命令请求的 Redis 服务器， 然后向它发送 SYNC 命令， 过一阵子， 你将看到 telnet 会话（session）接收到服务器发来的大段数据（.rdb 文件）， 之后还会看到， 所有在服务器执行过的写命令， 都会重新发送到 telnet 会话来。 即使有多个从服务器同时向主服务器发送 SYNC ， 主服务器也只需执行一次 BGSAVE 命令， 就可以处理所有这些从服务器的同步请求。 从服务器可以在主从服务器之间的连接断开时进行自动重连， 在 Redis 2.8 版本之前， 断线之后重连的从服务器总要执行一次完整重同步（full resynchronization）操作， 但是从 Redis 2.8 版本开始， 从服务器可以根据主服务器的情况来选择执行完整重同步还是部分重同步（partial resynchronization）。 部分重同步从 Redis 2.8 开始， 在网络连接短暂性失效之后， 主从服务器可以尝试继续执行原有的复制进程（process）， 而不一定要执行完整重同步操作。这个特性需要主服务器为被发送的复制流创建一个内存缓冲区（in-memory backlog）， 并且主服务器和所有从服务器之间都记录一个复制偏移量（replication offset）和一个主服务器 ID （master run id）， 当出现网络连接断开时， 从服务器会重新连接， 并且向主服务器请求继续执行原来的复制进程： 如果从服务器记录的主服务器 ID 和当前要连接的主服务器的 ID 相同， 并且从服务器记录的偏移量所指定的数据仍然保存在主服务器的复制流缓冲区里面， 那么主服务器会向从服务器发送断线时缺失的那部分数据， 然后复制工作可以继续执行。 否则的话， 从服务器就要执行完整重同步操作。 Redis 2.8 的这个部分重同步特性会用到一个新增的 PSYNC 内部命令， 而 Redis 2.8 以前的旧版本只有 SYNC 命令， 不过， 只要从服务器是 Redis 2.8 或以上的版本， 它就会根据主服务器的版本来决定到底是使用 PSYNC 还是 SYNC ： 如果主服务器是 Redis 2.8 或以上版本，那么从服务器使用 PSYNC 命令来进行同步。 如果主服务器是 Redis 2.8 之前的版本，那么从服务器使用 SYNC 命令来进行同步。 只读从服务器从 Redis 2.6 开始， 从服务器支持只读模式， 并且该模式为从服务器的默认模式。只读模式由 redis.conf 文件中的 slave-read-only 选项控制， 也可以通过 CONFIG SET 命令来开启或关闭这个模式。 只读从服务器会拒绝执行任何写命令， 所以不会出现因为操作失误而将数据不小心写入到了从服务器的情况。 即使从服务器是只读的， DEBUG 和 CONFIG 等管理式命令仍然是可以使用的， 所以我们还是不应该将服务器暴露给互联网或者任何不可信网络。 不过， 使用 redis.conf 中的命令改名选项， 我们可以通过禁止执行某些命令来提升只读从服务器的安全性。 你可能会感到好奇， 既然从服务器上的写数据会被重同步数据覆盖， 也可能在从服务器重启时丢失， 那么为什么要让一个从服务器变得可写呢？ 原因是， 一些不重要的临时数据， 仍然是可以保存在从服务器上面的。 比如说， 客户端可以在从服务器上保存主服务器的可达性（reachability）信息， 从而实现故障转移（failover）策略。 ####主服务器只在有至少 N 个从服务器的情况下，才执行写操作从 Redis 2.8 开始， 为了保证数据的安全性， 可以通过配置， 让主服务器只在有至少 N 个当前已连接从服务器的情况下， 才执行写命令。不过， 因为 Redis 使用异步复制， 所以主服务器发送的写数据并不一定会被从服务器接收到， 因此， 数据丢失的可能性仍然是存在的。 以下是这个特性的运作原理： 1 从服务器以每秒一次的频率 PING 主服务器一次， 并报告复制流的处理情况。 2 主服务器会记录各个从服务器最后一次向它发送 PING 的时间。 3 用户可以通过配置， 指定网络延迟的最大值 ， 以及执行写操作所需的至少从服务器数量如果至少有 min-slaves-to-write 个从服务器， 并且这些服务器的延迟值都少于 min-slaves-max-lag 秒， 那么主服务器就会执行客户端请求的写操作。 你可以将这个特性看作 CAP 理论中的 C 的条件放宽版本： 尽管不能保证写操作的持久性， 但起码丢失数据的窗口会被严格限制在指定的秒数中。 另一方面， 如果条件达不到min-slaves-to-write 和 min-slaves-max-lag 所指定的条件， 那么写操作就不会被执行， 主服务器会向请求执行写操作的客户端返回一个错误。 以下是这个特性的两个选项和它们所需的参数： 1 min-slaves-to-write 2 min-slaves-max-lag 详细的信息可以参考 Redis 源码中附带的 redis.conf 示例文件。 事务（transaction）MULTI 、 EXEC 、 DISCARD 和 WATCH 是 Redis 事务的基础。事务可以一次执行多个命令， 并且带有以下两个重要的保证： 事务是一个单独的隔离操作：事务中的所有命令都会序列化、按顺序地执行。事务在执行的过程中，不会被其他客户端发送来的命令请求所打断。事务是一个原子操作：事务中的命令要么全部被执行，要么全部都不执行。EXEC 命令负责触发并执行事务中的所有命令：如果客户端在使用 MULTI 开启了一个事务之后，却因为断线而没有成功执行 EXEC ，那么事务中的所有命令都不会被执行。另一方面，如果客户端成功在开启事务之后执行 EXEC ，那么事务中的所有命令都会被执行。当使用 AOF 方式做持久化的时候， Redis 会使用单个 write(2) 命令将事务写入到磁盘中。然而，如果 Redis 服务器因为某些原因被管理员杀死，或者遇上某种硬件故障，那么可能只有部分事务命令会被成功写入到磁盘中。如果 Redis 在重新启动时发现 AOF 文件出了这样的问题，那么它会退出，并汇报一个错误。使用 redis-check-aof 程序可以修复这一问题：它会移除 AOF 文件中不完整事务的信息，确保服务器可以顺利启动。从 2.2 版本开始，Redis 还可以通过乐观锁（optimistic lock）实现 CAS （check-and-set）操作，具体信息请参考文档的后半部分。 概念 说明事务中的错误 使用事务时可能会遇上以下两种错误： 事务在执行 EXEC 之前，入队的命令可能会出错。比如说，命令可能会产生语法错误（参数数量错误，参数名错误，等等），或者其他更严重的错误，比如内存不足（如果服务器使用 maxmemory 设置了最大内存限制的话）。 命令可能在 EXEC 调用之后失败。举个例子，事务中的命令可能处理了错误类型的键，比如将列表命令用在了字符串键上面，诸如此类。 对于发生在 EXEC 执行之前的错误，客户端以前的做法是检查命令入队所得的返回值：如果命令入队时返回 QUEUED ，那么入队成功；否则，就是入队失败。如果有命令在入队时失败，那么大部分客户端都会停止并取消这个事务。 不过，从 Redis 2.6.5 开始，服务器会对命令入队失败的情况进行记录，并在客户端调用 EXEC 命令时，拒绝执行并自动放弃这个事务。 在 Redis 2.6.5 以前， Redis 只执行事务中那些入队成功的命令，而忽略那些入队失败的命令。 而新的处理方式则使得在流水线（pipeline）中包含事务变得简单，因为发送事务和读取事务的回复都只需要和服务器进行一次通讯。 至于那些在 EXEC 命令执行之后所产生的错误， 并没有对它们进行特别处理： 即使事务中有某个/某些命令在执行时产生了错误， 事务中的其他命令仍然会继续执行。 最重要的是记住这样一条， 即使事务中有某条/某些命令执行失败了， 事务队列中的其他命令仍然会继续执行 —— Redis 不会停止执行事务中的命令。 Redis 不支持回滚 如果你有使用关系式数据库的经验， 那么 “Redis 在事务失败时不进行回滚，而是继续执行余下的命令”这种做法可能会让你觉得有点奇怪。以下是这种做法的优点： Redis 命令只会因为错误的语法而失败（并且这些问题不能在入队时发现），或是命令用在了错误类型的键上面：这也就是说，从实用性的角度来说，失败的命令是由编程错误造成的，而这些错误应该在开发的过程中被发现，而不应该出现在生产环境中。 因为不需要对回滚进行支持，所以 Redis 的内部可以保持简单且快速。 有种观点认为 Redis 处理事务的做法会产生 bug ， 然而需要注意的是， 在通常情况下， 回滚并不能解决编程错误带来的问题。 举个例子， 如果你本来想通过 INCR 命令将键的值加上 1 ， 却不小心加上了 2 ， 又或者对错误类型的键执行了 INCR ， 回滚是没有办法处理这些情况的。 鉴于没有任何机制能避免程序员自己造成的错误， 并且这类错误通常不会在生产环境中出现， 所以 Redis 选择了更简单、更快速的无回滚方式来处理事务。 乐观锁 WATCH 命令可以为 Redis 事务提供 check-and-set （CAS）行为。被 WATCH 的键会被监视，并会发觉这些键是否被改动过了。 如果有至少一个被监视的键在 EXEC 执行之前被修改了， 那么整个事务都会被取消， EXEC 返回空多条批量回复（null multi-bulk reply）来表示事务已经失败。 举个例子， 假设我们需要原子性地为某个值进行增 1 操作（假设 INCR 不存在）。 首先我们可能会这样做： val = GETmykey val = val + 1 SET mykey $val 上面的这个实现在只有一个客户端的时候可以执行得很好。 但是， 当多个客户端同时对同一个键进行这样的操作时， 就会产生竞争条件。 举个例子， 如果客户端 A 和 B 都读取了键原来的值， 比如 10 ， 那么两个客户端都会将键的值设为 11 ， 但正确的结果应该是 12 才对。 有了 WATCH ， 我们就可以轻松地解决这类问题了： WATCH mykey val = GET mykey val = val + 1 MULTI SET mykey $val EXEC 使用上面的代码， 如果在 WATCH 执行之后， EXEC 执行之前， 有其他客户端修改了 mykey 的值， 那么当前客户端的事务就会失败。 程序需要做的， 就是不断重试这个操作， 直到没有发生碰撞为止。 这种形式的锁被称作乐观锁， 它是一种非常强大的锁机制。 并且因为大多数情况下， 不同的客户端会访问不同的键， 碰撞的情况一般都很少， 所以通常并不需要进行重试。 WATCH WATCH 使得 EXEC 命令需要有条件地执行： 事务只能在所有被监视键都没有被修改的前提下执行， 如果这个前提不能满足的话，事务就不会被执行。如果你使用 WATCH 监视了一个带过期时间的键， 那么即使这个键过期了， 事务仍然可以正常执行， 关于这方面的详细情况，请看这个帖子： http://code.google.com/p/redis/issues/detail?id=270 WATCH 命令可以被调用多次。 对键的监视从 WATCH 执行之后开始生效， 直到调用 EXEC 为止。 用户还可以在单个 WATCH 命令中监视任意多个键， 就像这样： redis&gt; WATCH key1 key2 key3 OK 当 EXEC 被调用时， 不管事务是否成功执行， 对所有键的监视都会被取消。 另外， 当客户端断开连接时， 该客户端对键的监视也会被取消。 使用无参数的 UNWATCH 命令可以手动取消对所有键的监视。 对于一些需要改动多个键的事务， 有时候程序需要同时对多个键进行加锁， 然后检查这些键的当前值是否符合程序的要求。 当值达不到要求时， 就可以使用 UNWATCH 命令来取消目前对键的监视， 中途放弃这个事务， 并等待事务的下次尝试。 WATCH 可以用于创建 Redis 没有内置的原子操作。 Redis 脚本和事务 从定义上来说， Redis 中的脚本本身就是一种事务， 所以任何在事务里可以完成的事， 在脚本里面也能完成。 并且一般来说， 使用脚本要来得更简单，并且速度更快。因为脚本功能是 Redis 2.6 才引入的， 而事务功能则更早之前就存在了， 所以 Redis 才会同时存在两种处理事务的方法。 不过我们并不打算在短时间内就移除事务功能， 因为事务提供了一种即使不使用脚本， 也可以避免竞争条件的方法， 而且事务本身的实现并不复杂。 不过在不远的将来， 可能所有用户都会只使用脚本来实现事务也说不定。 如果真的发生这种情况的话， 那么我们将废弃并最终移除事务功能。 SentinelRedis 的 Sentinel 系统用于管理多个 Redis 服务器（instance）， 该系统执行以下三个任务： 监控（Monitoring）： Sentinel 会不断地检查你的主服务器和从服务器是否运作正常。提醒（Notification）： 当被监控的某个 Redis 服务器出现问题时， Sentinel 可以通过 API 向管理员或者其他应用程序发送通知。自动故障迁移（Automatic failover）： 当一个主服务器不能正常工作时， Sentinel 会开始一次自动故障迁移操作， 它会将失效主服务器的其中一个从服务器升级为新的主服务器， 并让失效主服务器的其他从服务器改为复制新的主服务器； 当客户端试图连接失效的主服务器时， 集群也会向客户端返回新主服务器的地址， 使得集群可以使用新主服务器代替失效服务器。Redis Sentinel 是一个分布式系统， 你可以在一个架构中运行多个 Sentinel 进程（progress）， 这些进程使用流言协议（gossip protocols)来接收关于主服务器是否下线的信息， 并使用投票协议（agreement protocols）来决定是否执行自动故障迁移， 以及选择哪个从服务器作为新的主服务器。虽然 Redis Sentinel 释出为一个单独的可执行文件 redis-sentinel ， 但实际上它只是一个运行在特殊模式下的 Redis 服务器， 你可以在启动一个普通 Redis 服务器时通过给定 –sentinel 选项来启动 Redis Sentinel 。Redis Sentinel 目前仍在开发中， 这个文档的内容可能随着 Sentinel 实现的修改而变更。Redis Sentinel 兼容 Redis 2.4.16 或以上版本， 推荐使用 Redis 2.8.0 或以上的版本。 概念 说明主观下线和客观下线 Redis 的 Sentinel 中关于下线（down）有两个不同的概念： 主观下线（Subjectively Down， 简称 SDOWN）指的是单个 Sentinel 实例对服务器做出的下线判断。 客观下线（Objectively Down， 简称 ODOWN）指的是多个 Sentinel 实例在对同一个服务器做出 SDOWN 判断， 并且通过 SENTINEL is-master-down-by-addr 命令互相交流之后， 得出的服务器下线判断。 （一个 Sentinel 可以通过向另一个 Sentinel 发送 SENTINEL is-master-down-by-addr 命令来询问对方是否认为给定的服务器已下线。） 如果一个服务器没有在 master-down-after-milliseconds 选项所指定的时间内， 对向它发送 PING 命令的 Sentinel 返回一个有效回复（valid reply）， 那么 Sentinel 就会将这个服务器标记为主观下线。 服务器对 PING 命令的有效回复可以是以下三种回复的其中一种： 返回 +PONG 。 返回 -LOADING 错误。 返回 -MASTERDOWN 错误。 如果服务器返回除以上三种回复之外的其他回复， 又或者在指定时间内没有回复 PING 命令， 那么 Sentinel 认为服务器返回的回复无效（non-valid）。 注意， 一个服务器必须在 master-down-after-milliseconds 毫秒内， 一直返回无效回复才会被 Sentinel 标记为主观下线。 举个例子， 如果 master-down-after-milliseconds 选项的值为 30000 毫秒（30 秒）， 那么只要服务器能在每 29 秒之内返回至少一次有效回复， 这个服务器就仍然会被认为是处于正常状态的。 从主观下线状态切换到客观下线状态并没有使用严格的法定人数算法（strong quorum algorithm）， 而是使用了流言协议： 如果 Sentinel 在给定的时间范围内， 从其他 Sentinel 那里接收到了足够数量的主服务器下线报告， 那么 Sentinel 就会将主服务器的状态从主观下线改变为客观下线。 如果之后其他 Sentinel 不再报告主服务器已下线， 那么客观下线状态就会被移除。 客观下线条件只适用于主服务器： 对于任何其他类型的 Redis 实例， Sentinel 在将它们判断为下线前不需要进行协商， 所以从服务器或者其他 Sentinel 永远不会达到客观下线条件。 只要一个 Sentinel 发现某个主服务器进入了客观下线状态， 这个 Sentinel 就可能会被其他 Sentinel 推选出， 并对失效的主服务器执行自动故障迁移操作。 每个 Sentinel 都需要定期执行的任务 1. 每个 Sentinel 以每秒钟一次的频率向它所知的主服务器、从服务器以及其他 Sentinel 实例发送一个 PING 命令。 如果一个实例（instance）距离最后一次有效回复 PING 命令的时间超过 down-after-milliseconds 选项所指定的值， 那么这个实例会被 Sentinel 标记为主观下线。 一个有效回复可以是： +PONG 、 -LOADING 或者 -MASTERDOWN 。 如果一个主服务器被标记为主观下线， 那么正在监视这个主服务器的所有 Sentinel 要以每秒一次的频率确认主服务器的确进入了主观下线状态。 如果一个主服务器被标记为主观下线， 并且有足够数量的 Sentinel （至少要达到配置文件指定的数量）在指定的时间范围内同意这一判断， 那么这个主服务器被标记为客观下线。 在一般情况下， 每个 Sentinel 会以每 10 秒一次的频率向它已知的所有主服务器和从服务器发送 INFO 命令。 当一个主服务器被 Sentinel 标记为客观下线时， Sentinel 向下线主服务器的所有从服务器发送 INFO 命令的频率会从 10 秒一次改为每秒一次。 当没有足够数量的 Sentinel 同意主服务器已经下线， 主服务器的客观下线状态就会被移除。 当主服务器重新向 Sentinel 的 PING命令返回有效回复时， 主服务器的主管下线状态就会被移除。 自动发现 Sentinel 和从服务器 一个 Sentinel 可以与其他多个 Sentinel 进行连接， 各个 Sentinel 之间可以互相检查对方的可用性， 并进行信息交换。你无须为运行的每个 Sentinel 分别设置其他 Sentinel 的地址， 因为 Sentinel 可以通过发布与订阅功能来自动发现正在监视相同主服务器的其他 Sentinel ， 这一功能是通过向频道 sentinel:hello 发送信息来实现的。 与此类似， 你也不必手动列出主服务器属下的所有从服务器， 因为 Sentinel 可以通过询问主服务器来获得所有从服务器的信息。 每个 Sentinel 会以每两秒一次的频率， 通过发布与订阅功能， 向被它监视的所有主服务器和从服务器的 sentinel:hello 频道发送一条信息， 信息中包含了 Sentinel 的 IP 地址、端口号和运行 ID （runid）。 每个 Sentinel 都订阅了被它监视的所有主服务器和从服务器的 sentinel:hello 频道， 查找之前未出现过的 sentinel （looking for unknown sentinels）。 当一个 Sentinel 发现一个新的 Sentinel 时， 它会将新的 Sentinel 添加到一个列表中， 这个列表保存了 Sentinel 已知的， 监视同一个主服务器的所有其他 Sentinel 。 Sentinel 发送的信息中还包括完整的主服务器当前配置（configuration）。 如果一个 Sentinel 包含的主服务器配置比另一个 Sentinel 发送的配置要旧， 那么这个 Sentinel 会立即升级到新配置上。 在将一个新 Sentinel 添加到监视主服务器的列表上面之前， Sentinel 会先检查列表中是否已经包含了和要添加的 Sentinel 拥有相同运行 ID 或者相同地址（包括 IP 地址和端口号）的 Sentinel ， 如果是的话， Sentinel 会先移除列表中已有的那些拥有相同运行 ID 或者相同地址的 Sentinel ， 然后再添加新 Sentinel 。 故障转移 一次故障转移操作由以下步骤组成： 发现主服务器已经进入客观下线状态。 对我们的当前纪元进行自增（详情请参考 Raft leader election ）， 并尝试在这个纪元中当选。 如果当选失败， 那么在设定的故障迁移超时时间的两倍之后， 重新尝试当选。 如果当选成功， 那么执行以下步骤。 选出一个从服务器，并将它升级为主服务器。 向被选中的从服务器发送 SLAVEOF NO ONE 命令，让它转变为主服务器。 通过发布与订阅功能， 将更新后的配置传播给所有其他 Sentinel ， 其他 Sentinel 对它们自己的配置进行更新。 向已下线主服务器的从服务器发送 SLAVEOF 命令， 让它们去复制新的主服务器。 当所有从服务器都已经开始复制新的主服务器时， 领头 Sentinel 终止这次故障迁移操作。 每当一个 Redis 实例被重新配置（reconfigured） —— 无论是被设置成主服务器、从服务器、又或者被设置成其他主服务器的从服务器 —— Sentinel 都会向被重新配置的实例发送一个 CONFIG REWRITE 命令， 从而确保这些配置会持久化在硬盘里。 Sentinel 使用以下规则来选择新的主服务器： 在失效主服务器属下的从服务器当中， 那些被标记为主观下线、已断线、或者最后一次回复 PING 命令的时间大于五秒钟的从服务器都会被淘汰。 在失效主服务器属下的从服务器当中， 那些与失效主服务器连接断开的时长超过 down-after 选项指定的时长十倍的从服务器都会被淘汰。 在经历了以上两轮淘汰之后剩下来的从服务器中， 我们选出复制偏移量（replication offset）最大的那个从服务器作为新的主服务器； 如果复制偏移量不可用， 或者从服务器的复制偏移量相同， 那么带有最小运行 ID 的那个从服务器成为新的主服务器。 Sentinel 自动故障迁移的一致性特质 Sentinel 自动故障迁移使用 Raft 算法来选举领头（leader） Sentinel ， 从而确保在一个给定的纪元（epoch）里， 只有一个领头产生。 这表示在同一个纪元中， 不会有两个 Sentinel 同时被选中为领头， 并且各个 Sentinel 在同一个纪元中只会对一个领头进行投票。 更高的配置纪元总是优于较低的纪元， 因此每个 Sentinel 都会主动使用更新的纪元来代替自己的配置。 简单来说， 我们可以将 Sentinel 配置看作是一个带有版本号的状态。 一个状态会以最后写入者胜出（last-write-wins）的方式（也即是，最新的配置总是胜出）传播至所有其他 Sentinel 。 举个例子， 当出现网络分割（network partitions）时， 一个 Sentinel 可能会包含了较旧的配置， 而当这个 Sentinel 接到其他 Sentinel 发来的版本更新的配置时， Sentinel 就会对自己的配置进行更新。 如果要在网络分割出现的情况下仍然保持一致性， 那么应该使用 min-slaves-to-write 选项， 让主服务器在连接的从实例少于给定数量时停止执行写操作， 与此同时， 应该在每个运行 Redis 主服务器或从服务器的机器上运行 Redis Sentinel 进程。 Sentinel 状态的持久化 Sentinel 的状态会被持久化在 Sentinel 配置文件里面。 每当 Sentinel 接收到一个新的配置， 或者当领头 Sentinel 为主服务器创建一个新的配置时， 这个配置会与配置纪元一起被保存到磁盘里面。 这意味着停止和重启 Sentinel 进程都是安全的。 Sentinel 在非故障迁移的情况下对实例进行重新配置 即使没有自动故障迁移操作在进行， Sentinel 总会尝试将当前的配置设置到被监视的实例上面。 特别是： 根据当前的配置， 如果一个从服务器被宣告为主服务器， 那么它会代替原有的主服务器， 成为新的主服务器， 并且成为原有主服务器的所有从服务器的复制对象。 那些连接了错误主服务器的从服务器会被重新配置， 使得这些从服务器会去复制正确的主服务器。 不过， 在以上这些条件满足之后， Sentinel 在对实例进行重新配置之前仍然会等待一段足够长的时间， 确保可以接收到其他 Sentinel 发来的配置更新， 从而避免自身因为保存了过期的配置而对实例进行了不必要的重新配置。 TILT 模式 Redis Sentinel 严重依赖计算机的时间功能： 比如说， 为了判断一个实例是否可用， Sentinel 会记录这个实例最后一次相应 PING 命令的时间， 并将这个时间和当前时间进行对比， 从而知道这个实例有多长时间没有和 Sentinel 进行任何成功通讯。不过， 一旦计算机的时间功能出现故障， 或者计算机非常忙碌， 又或者进程因为某些原因而被阻塞时， Sentinel 可能也会跟着出现故障。 TILT 模式是一种特殊的保护模式： 当 Sentinel 发现系统有些不对劲时， Sentinel 就会进入 TILT 模式。 因为 Sentinel 的时间中断器默认每秒执行 10 次， 所以我们预期时间中断器的两次执行之间的间隔为 100 毫秒左右。 Sentinel 的做法是， 记录上一次时间中断器执行时的时间， 并将它和这一次时间中断器执行的时间进行对比： 如果两次调用时间之间的差距为负值， 或者非常大（超过 2 秒钟）， 那么 Sentinel 进入 TILT 模式。 如果 Sentinel 已经进入 TILT 模式， 那么 Sentinel 延迟退出 TILT 模式的时间。 当 Sentinel 进入 TILT 模式时， 它仍然会继续监视所有目标， 但是： 它不再执行任何操作，比如故障转移。 当有实例向这个 Sentinel 发送 SENTINEL is-master-down-by-addr 命令时， Sentinel 返回负值： 因为这个 Sentinel 所进行的下线判断已经不再准确。 如果 TILT 可以正常维持 30 秒钟， 那么 Sentinel 退出 TILT 模式。 clusterredis cluster 官方介绍特点： 节点间数据自动同步 节点间数据自动分配 故障隔离 所有节点彼此互联，使用二进制协议传输 客户端可以连接任意结点（不区分master slave） 集群实现： ex. server port is 6379; another tcp port 16379(adding 10000) used as cluster bus(故障检查，配置更新 etc) hash slot， 0-16383，集群负责维护node和slot和value的映射， Consistency guarantees：无法保证strong guarantee, Basically there is a trade-off to take between performance and consistency. 集群配置：1.依赖软件： ruby-2.3.1.tar.gz rubygem-2.6.6.zip redis-3.3.1.gem redis-3.2.3 高可用： 集群包含多个组， 每个组由一个master和至少1个slave组成； 同组内的结点的数据一致 集群不可用: 任意master不可用&amp;&amp;无slave， 此时集群的slot[0-16383]不完全覆盖参数：cluster-require-full-coverage 默认配置为yes，部分宕机 其他节点不对外服务 使用 集群是一个整体，数据按key的slot计算方法 分配到不同node的不同slot， 当client访问任意一个集群node，get某个key时，如果此key不在此node，则返回 该key所属的redirect信息：MOVED xxx ip:port client如果随机访问集群的某个node，很大概率需要通过redirect信息 再次访问正确的node这样处理的效率很低，正确的处理方式是client记录集群的node slot分配信息，每次访问时按照key计算的slot 访问具体的某个node。参考：spring-data-redis中的实现机制ClusterTopology类中 getKeyServingMasterNode 可以获取key对应的nodeClusterSlotHashUtil类中 calculateSlot实现了redis的slot分配策略 jedis模块实现了java连接redis的具体实现，redis的接口命令在此模块中都有实现 piple大量数据加载，通过数据文件形式执行cat data.txt | redis-cli –pipe partitionredis partition 和数据库分库类似， 将数据分布在多个实体上 需要解决的问题是： 键值分配规则 一般的规则包括： 按范围分段 键值 取模（字符键值可以使用crc32等方法转换为数字） 实现方式： 客户端分part 代理负责： TwemProxy 轮询 Disadvantage： 多key操作不适用 多key事物不适用 持久化工作复杂 扩容策略 用于数据存储or cache If Redis is used as a cache scaling up and down using consistent hashing is easy. If Redis is used as a store, a fixed keys-to-nodes map is used, so the number of nodes must be fixed and cannot vary. Otherwise, a system is needed that is able to rebalance keys between nodes when nodes are added or removed, and currently only Redis Cluster is able to do this - Redis Cluster is generally available and production-ready as of April 1st, 2015. 实践策略： config123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468469470471472473474475476477478479480481482483484485486487488489490491492493494495496497498499500501502503504505506507508509510511512513514515516517518519520521522523524525526527528529530531532533534535536537538539540541542543544545546547548549550551552553554555556557558559560561562563564565566567568569570571572573574575576577578579580581582583584585586587588589590591592593594595596597598599600601602603604605606607608609610611612613614615616617618619620621622623624625626627628629630631632633634635636637638639640641642643644645646647648649650651652653654655656657658659660661662663664665666667668669670671672673674675676677678679680681682683684685686687688689690691692693694695696697698699700701702703704705706707708709710711712713714715716717718719720721722723724725726727728729730731732733734735736737738739740741742743744745746747748749750751752753754755756757758759760761762763764765766767768769770771772773774775776777778779780781782783784785786787788789790791792793794795796797798799800801802803804805806807808809810811812813814815816817818819820821822823824825826827828829830831832833834835836837838839840841842843844845846847848849850851852853854855856857858859860861862863864865866867868869870871872873874875876877878879880881882883884885886887888889890891892893894895896897898899900901902903904905906907908909910911912913914915916917918919920921922923924925926927928929930931932933934935936937938939940941942943944945946947948949950951952953954955956957958959960961962963964965966967968969970971972973974975976977978979980981982983984985986987988989990991992993994995996997998999100010011002100310041005100610071008100910101011101210131014101510161017101810191020102110221023102410251026102710281029103010311032103310341035103610371038103910401041104210431044104510461047104810491050105110521053105410551056105710581059106010611062106310641065106610671068106910701071107210731074107510761077107810791080108110821083108410851086108710881089109010911092109310941095109610971098109911001101110211031104110511061107##redis配置详解# Redis configuration file example.## Note that in order to read the configuration file, Redis must be# started with the file path as first argument:## ./redis-server /path/to/redis.conf# Note on units: when memory size is needed, it is possible to specify# it in the usual form of 1k 5GB 4M and so forth:## 1k =&gt; 1000 bytes# 1kb =&gt; 1024 bytes# 1m =&gt; 1000000 bytes# 1mb =&gt; 1024*1024 bytes# 1g =&gt; 1000000000 bytes# 1gb =&gt; 1024*1024*1024 bytes## units are case insensitive so 1GB 1Gb 1gB are all the same.################################## INCLUDES ##################################################################### 包含 #################################### Include one or more other config files here. This is useful if you# have a standard template that goes to all Redis servers but also need# to customize a few per-server settings. Include files can include# other files, so use this wisely.## Notice option \"include\" won't be rewritten by command \"CONFIG REWRITE\"# from admin or Redis Sentinel. Since Redis always uses the last processed# line as value of a configuration directive, you'd better put includes# at the beginning of this file to avoid overwriting config change at runtime.## If instead you are interested in using includes to override configuration# options, it is better to use include as the last line.## 假如说你有一个可用于所有的 redis server 的标准配置模板，# 但针对某些 server 又需要一些个性化的设置，# 你可以使用 include 来包含一些其他的配置文件，这对你来说是非常有用的。## 但是要注意哦，include 是不能被 config rewrite 命令改写的# 由于 redis 总是以最后的加工线作为一个配置指令值，所以你最好是把 include 放在这个文件的最前面，# 以避免在运行时覆盖配置的改变，相反，你就把它放在后面# include /path/to/local.conf# include /path/to/other.conf################################ GENERAL ##################################################################### 常用 ###################################### By default Redis does not run as a daemon. Use 'yes' if you need it.# Note that Redis will write a pid file in /var/run/redis.pid when daemonized.# 默认情况下 redis 不是作为守护进程运行的，如果你想让它在后台运行，你就把它改成 yes。# 当redis作为守护进程运行的时候，它会写一个 pid 到 /var/run/redis.pid 文件里面。daemonize yes# When running daemonized, Redis writes a pid file in /var/run/redis.pid by# default. You can specify a custom pid file location here.# 当 Redis 以守护进程的方式运行的时候，Redis 默认会把 pid 文件放在/var/run/redis.pid# 可配置到其他地址，当运行多个 redis 服务时，需要指定不同的 pid 文件和端口# 指定存储Redis进程号的文件路径pidfile /var/run/redis.pid# Accept connections on the specified port, default is 6379.# If port 0 is specified Redis will not listen on a TCP socket.# 端口，默认端口是6379，生产环境中建议更改端口号，安全性更高# 如果你设为 0 ，redis 将不在 socket 上监听任何客户端连接。port 9966# TCP listen() backlog.## In high requests-per-second environments you need an high backlog in order# to avoid slow clients connections issues. Note that the Linux kernel# will silently truncate it to the value of /proc/sys/net/core/somaxconn so# make sure to raise both the value of somaxconn and tcp_max_syn_backlog# in order to get the desired effect.# TCP 监听的最大容纳数量# 此参数确定了TCP连接中已完成队列(完成三次握手之后)的长度，# 当系统并发量大并且客户端速度缓慢的时候，你需要把这个值调高以避免客户端连接缓慢的问题。# Linux 内核会一声不响的把这个值缩小成 /proc/sys/net/core/somaxconn 对应的值，默认是511，而Linux的默认参数值是128。# 所以可以将这二个参数一起参考设定，你以便达到你的预期。# tcp-backlog 511# By default Redis listens for connections from all the network interfaces# available on the server. It is possible to listen to just one or multiple# interfaces using the \"bind\" configuration directive, followed by one or# more IP addresses.## Examples:## bind 192.168.1.100 10.0.0.1# 有时候为了安全起见，redis一般都是监听127.0.0.1 但是有时候又有同网段能连接的需求，当然可以绑定0.0.0.0 用iptables来控制访问权限，或者设置redis访问密码来保证数据安全# 不设置将处理所有请求,建议生产环境中设置，有个误区：bind是用来限制外网IP访问的，其实不是，限制外网ip访问可以通过iptables；如：-A INPUT -s 10.10.1.0/24 -p tcp -m state --state NEW -m tcp --dport 9966 -j ACCEPT ；# 实际上，bind ip 绑定的是redis所在服务器网卡的ip，当然127.0.0.1也是可以的#如果绑定一个外网ip，就会报错：Creating Server TCP listening socket xxx.xxx.xxx.xxx:9966: bind: Cannot assign requested address# bind 127.0.0.1bind 127.0.0.1 10.10.1.3# 假设绑定是以上ip，使用 netstat -anp|grep 9966 会发现，这两个ip被bind，其中10.10.1.3是服务器网卡的ip# tcp 0 0 10.10.1.3:9966 0.0.0.0:* LISTEN 11188/redis-server # tcp 0 0 127.0.0.1:9966 0.0.0.0:* LISTEN 11188/redis-server # Specify the path for the Unix socket that will be used to listen for# incoming connections. There is no default, so Redis will not listen# on a unix socket when not specified.## unixsocket /tmp/redis.sock# unixsocketperm 700# Close the connection after a client is idle for N seconds (0 to disable)# 客户端和Redis服务端的连接超时时间，默认是0，表示永不超时。timeout 0# TCP keepalive.## If non-zero, use SO_KEEPALIVE to send TCP ACKs to clients in absence# of communication. This is useful for two reasons:## 1) Detect dead peers.# 2) Take the connection alive from the point of view of network# equipment in the middle.## On Linux, the specified value (in seconds) is the period used to send ACKs.# Note that to close the connection the double of the time is needed.# On other kernels the period depends on the kernel configuration.## A reasonable value for this option is 60 seconds.# tcp 心跳包。## 如果设置为非零，则在与客户端缺乏通讯的时候使用 SO_KEEPALIVE 发送 tcp acks 给客户端。# 这个之所有有用，主要由两个原因：## 1) 防止死的 peers# 2) Take the connection alive from the point of view of network# equipment in the middle.## 推荐一个合理的值就是60秒tcp-keepalive 0# Specify the server verbosity level.# This can be one of:# debug (a lot of information, useful for development/testing)# verbose (many rarely useful info, but not a mess like the debug level)# notice (moderately verbose, what you want in production probably)# warning (only very important / critical messages are logged)# 日志记录等级，4个可选值debug,verbose,notice,warning# 可以是下面的这些值：# debug (适用于开发或测试阶段)# verbose (many rarely useful info, but not a mess like the debug level)# notice (适用于生产环境)# warning (仅仅一些重要的消息被记录)loglevel notice# Specify the log file name. Also the empty string can be used to force# Redis to log on the standard output. Note that if you use standard# output for logging but daemonize, logs will be sent to /dev/null#配置 log 文件地址,默认打印在命令行终端的窗口上，也可设为/dev/null屏蔽日志、logfile \"/data/logs/redis/redis.log\"# To enable logging to the system logger, just set 'syslog-enabled' to yes,# and optionally update the other syslog parameters to suit your needs.# 要想把日志记录到系统日志，就把它改成 yes，# 也可以可选择性的更新其他的syslog 参数以达到你的要求# syslog-enabled no# Specify the syslog identity.# 设置 syslog 的 identity。# syslog-ident redis# Specify the syslog facility. Must be USER or between LOCAL0-LOCAL7.# syslog-facility local0# Set the number of databases. The default database is DB 0, you can select# a different one on a per-connection basis using SELECT &lt;dbid&gt; where# dbid is a number between 0 and 'databases'-1# 可用的数据库数，默认值为16，默认数据库为0，数据库范围在0-（database-1）之间databases 16################################ SNAPSHOTTING ################################################################ 快照 ################################## Save the DB on disk:## save &lt;seconds&gt; &lt;changes&gt;## Will save the DB if both the given number of seconds and the given# number of write operations against the DB occurred.## In the example below the behaviour will be to save:# after 900 sec (15 min) if at least 1 key changed# after 300 sec (5 min) if at least 10 keys changed# after 60 sec if at least 10000 keys changed## Note: you can disable saving completely by commenting out all \"save\" lines.## It is also possible to remove all the previously configured save# points by adding a save directive with a single empty string argument# like in the following example:## save \"\"# 在 900 秒内最少有 1 个 key 被改动，或者 300 秒内最少有 10 个 key 被改动，又或者 60 秒内最少有 1000 个 key 被改动，以上三个条件随便满足一个，就触发一次保存操作。# if(在60秒之内有10000个keys发生变化时)&#123;# 进行镜像备份# &#125;else if(在300秒之内有10个keys发生了变化)&#123;# 进行镜像备份# &#125;else if(在900秒之内有1个keys发生了变化)&#123;# 进行镜像备份# &#125;save 900 1save 300 10save 60 10000# By default Redis will stop accepting writes if RDB snapshots are enabled# (at least one save point) and the latest background save failed.# This will make the user aware (in a hard way) that data is not persisting# on disk properly, otherwise chances are that no one will notice and some#:/ disaster will happen.## If the background saving process will start working again Redis will# automatically allow writes again.## However if you have setup your proper monitoring of the Redis server# and persistence, you may want to disable this feature so that Redis will# continue to work as usual even if there are problems with disk,# permissions, and so forth.# 默认情况下，如果 redis 最后一次的后台保存失败，redis 将停止接受写操作，# 这样以一种强硬的方式让用户知道数据不能正确的持久化到磁盘，# 否则就会没人注意到灾难的发生。## 如果后台保存进程重新启动工作了，redis 也将自动的允许写操作。## 然而你要是安装了靠谱的监控，你可能不希望 redis 这样做，那你就改成 no 好stop-writes-on-bgsave-error yes# Compress string objects using LZF when dump .rdb databases?# For default that's set to 'yes' as it's almost always a win.# If you want to save some CPU in the saving child set it to 'no' but# the dataset will likely be bigger if you have compressible values or keys.# 在进行备份时,是否进行压缩# 是否在 dump .rdb 数据库的时候使用 LZF 压缩字符串# 默认都设为 yes# 如果你希望保存子进程节省点 cpu ，你就设置它为 no ，# 不过这个数据集可能就会比较大rdbcompression yes# Since version 5 of RDB a CRC64 checksum is placed at the end of the file.# This makes the format more resistant to corruption but there is a performance# hit to pay (around 10%) when saving and loading RDB files, so you can disable it# for maximum performances.## RDB files created with checksum disabled have a checksum of zero that will# tell the loading code to skip the check. # 读取和写入的时候是否支持CRC64校验，默认是开启的rdbchecksum yes# The filename where to dump the DB# 备份文件的文件名dbfilename dump.rdb# The working directory.## The DB will be written inside this directory, with the filename specified# above using the 'dbfilename' configuration directive.## The Append Only File will also be created inside this directory.## Note that you must specify a directory here, not a file name.# 数据库备份的文件放置的路径# 路径跟文件名分开配置是因为 Redis 备份时，先会将当前数据库的状态写入到一个临时文件# 等备份完成时，再把该临时文件替换为上面所指定的文件# 而临时文件和上面所配置的备份文件都会放在这个指定的路径当中# 默认值为 ./dir /data/data/redis/################################# REPLICATION ################################################################## 主从复制 ################################## Master-Slave replication. Use slaveof to make a Redis instance a copy of# another Redis server. A few things to understand ASAP about Redis replication.## 1) Redis replication is asynchronous, but you can configure a master to# stop accepting writes if it appears to be not connected with at least# a given number of slaves.# 2) Redis slaves are able to perform a partial resynchronization with the# master if the replication link is lost for a relatively small amount of# time. You may want to configure the replication backlog size (see the next# sections of this file) with a sensible value depending on your needs.# 3) Replication is automatic and does not need user intervention. After a# network partition slaves automatically try to reconnect to masters# and resynchronize with them.## 设置该数据库为其他数据库的从数据库# slaveof &lt;masterip&gt; &lt;masterport&gt; 当本机为从服务时，设置主服务的IP及端口# slaveof &lt;masterip&gt; &lt;masterport&gt;# If the master is password protected (using the \"requirepass\" configuration# directive below) it is possible to tell the slave to authenticate before# starting the replication synchronization process, otherwise the master will# refuse the slave request.## 指定与主数据库连接时需要的密码验证# masterauth &lt;master-password&gt; 当本机为从服务时，设置访问master服务器的密码# masterauth &lt;master-password&gt;# When a slave loses its connection with the master, or when the replication# is still in progress, the slave can act in two different ways:## 1) if slave-serve-stale-data is set to 'yes' (the default) the slave will# still reply to client requests, possibly with out of date data, or the# data set may just be empty if this is the first synchronization.## 2) if slave-serve-stale-data is set to 'no' the slave will reply with# an error \"SYNC with master in progress\" to all the kind of commands# but to INFO and SLAVEOF.## 当slave服务器和master服务器失去连接后，或者当数据正在复制传输的时候，如果此参数值设置“yes”，slave服务器可以继续接受客户端的请求，否则，会返回给请求的客户端如下信息“SYNC with master in progress”,除了INFO，SLAVEOF这两个命令slave-serve-stale-data yes# You can configure a slave instance to accept writes or not. Writing against# a slave instance may be useful to store some ephemeral data (because data# written on a slave will be easily deleted after resync with the master) but# may also cause problems if clients are writing to it because of a# misconfiguration.## Since Redis 2.6 by default slaves are read-only.## Note: read only slaves are not designed to be exposed to untrusted clients# on the internet. It's just a protection layer against misuse of the instance.# Still a read only slave exports by default all the administrative commands# such as CONFIG, DEBUG, and so forth. To a limited extent you can improve# security of read only slaves using 'rename-command' to shadow all the# administrative / dangerous commands.# 是否允许slave服务器节点只提供读服务slave-read-only yes# Replication SYNC strategy: disk or socket.## -------------------------------------------------------# WARNING: DISKLESS REPLICATION IS EXPERIMENTAL CURRENTLY# -------------------------------------------------------## New slaves and reconnecting slaves that are not able to continue the replication# process just receiving differences, need to do what is called a \"full# synchronization\". An RDB file is transmitted from the master to the slaves.# The transmission can happen in two different ways:## 1) Disk-backed: The Redis master creates a new process that writes the RDB# file on disk. Later the file is transferred by the parent# process to the slaves incrementally.# 2) Diskless: The Redis master creates a new process that directly writes the# RDB file to slave sockets, without touching the disk at all.## With disk-backed replication, while the RDB file is generated, more slaves# can be queued and served with the RDB file as soon as the current child producing# the RDB file finishes its work. With diskless replication instead once# the transfer starts, new slaves arriving will be queued and a new transfer# will start when the current one terminates.## When diskless replication is used, the master waits a configurable amount of# time (in seconds) before starting the transfer in the hope that multiple slaves# will arrive and the transfer can be parallelized.## With slow disks and fast (large bandwidth) networks, diskless replication# works better.repl-diskless-sync no# When diskless replication is enabled, it is possible to configure the delay# the server waits in order to spawn the child that transfers the RDB via socket# to the slaves.## This is important since once the transfer starts, it is not possible to serve# new slaves arriving, that will be queued for the next RDB transfer, so the server# waits a delay in order to let more slaves arrive.## The delay is specified in seconds, and by default is 5 seconds. To disable# it entirely just set it to 0 seconds and the transfer will start ASAP.repl-diskless-sync-delay 5# Slaves send PINGs to server in a predefined interval. It's possible to change# this interval with the repl_ping_slave_period option. The default value is 10# seconds.## Slaves 在一个预定义的时间间隔内发送 ping 命令到 server 。# 你可以改变这个时间间隔。默认为 10 秒。# repl-ping-slave-period 10# The following option sets the replication timeout for:## 1) Bulk transfer I/O during SYNC, from the point of view of slave.# 2) Master timeout from the point of view of slaves (data, pings).# 3) Slave timeout from the point of view of masters (REPLCONF ACK pings).## It is important to make sure that this value is greater than the value# specified for repl-ping-slave-period otherwise a timeout will be detected# every time there is low traffic between the master and the slave.## 设置主从复制过期时间# 这个值一定要比 repl-ping-slave-period 大# repl-timeout 60# Disable TCP_NODELAY on the slave socket after SYNC?## If you select \"yes\" Redis will use a smaller number of TCP packets and# less bandwidth to send data to slaves. But this can add a delay for# the data to appear on the slave side, up to 40 milliseconds with# Linux kernels using a default configuration.## If you select \"no\" the delay for data to appear on the slave side will# be reduced but more bandwidth will be used for replication.## By default we optimize for low latency, but in very high traffic conditions# or when the master and slaves are many hops away, turning this to \"yes\" may# be a good idea.# 指定向slave同步数据时，是否禁用socket的NO_DELAY选 项。若配置为“yes”，则禁用NO_DELAY，则TCP协议栈会合并小包统一发送，这样可以减少主从节点间的包数量并节省带宽，但会增加数据同步到 slave的时间。若配置为“no”，表明启用NO_DELAY，则TCP协议栈不会延迟小包的发送时机，这样数据同步的延时会减少，但需要更大的带宽。 通常情况下，应该配置为no以降低同步延时，但在主从节点间网络负载已经很高的情况下，可以配置为yes。repl-disable-tcp-nodelay no# Set the replication backlog size. The backlog is a buffer that accumulates# slave data when slaves are disconnected for some time, so that when a slave# wants to reconnect again, often a full resync is not needed, but a partial# resync is enough, just passing the portion of data the slave missed while# disconnected.## The bigger the replication backlog, the longer the time the slave can be# disconnected and later be able to perform a partial resynchronization.## The backlog is only allocated once there is at least a slave connected.## 设置主从复制容量大小。这个 backlog 是一个用来在 slaves 被断开连接时# 存放 slave 数据的 buffer，所以当一个 slave 想要重新连接，通常不希望全部重新同步，# 只是部分同步就够了，仅仅传递 slave 在断开连接时丢失的这部分数据。## The biggest the replication backlog, the longer the time the slave can be# disconnected and later be able to perform a partial resynchronization.# 这个值越大，salve 可以断开连接的时间就越长。# repl-backlog-size 1mb# After a master has no longer connected slaves for some time, the backlog# will be freed. The following option configures the amount of seconds that# need to elapse, starting from the time the last slave disconnected, for# the backlog buffer to be freed.## A value of 0 means to never release the backlog.## 在某些时候，master 不再连接 slaves，backlog 将被释放。# 如果设置为 0 ，意味着绝不释放 backlog 。# repl-backlog-ttl 3600# The slave priority is an integer number published by Redis in the INFO output.# It is used by Redis Sentinel in order to select a slave to promote into a# master if the master is no longer working correctly.## A slave with a low priority number is considered better for promotion, so# for instance if there are three slaves with priority 10, 100, 25 Sentinel will# pick the one with priority 10, that is the lowest.## However a special priority of 0 marks the slave as not able to perform the# role of master, so a slave with priority of 0 will never be selected by# Redis Sentinel for promotion.## By default the priority is 100.# 指定slave的优先级。在不只1个slave存在的部署环境下，当master宕机时，Redis# Sentinel会将priority值最小的slave提升为master。# 这个值越小，就越会被优先选中，需要注意的是，# 若该配置项为0，则对应的slave永远不会自动提升为master。slave-priority 100# It is possible for a master to stop accepting writes if there are less than# N slaves connected, having a lag less or equal than M seconds.## The N slaves need to be in \"online\" state.## The lag in seconds, that must be &lt;= the specified value, is calculated from# the last ping received from the slave, that is usually sent every second.## This option does not GUARANTEE that N replicas will accept the write, but# will limit the window of exposure for lost writes in case not enough slaves# are available, to the specified number of seconds## For example to require at least 3 slaves with a lag &lt;= 10 seconds use:## min-slaves-to-write 3# min-slaves-max-lag 10## Setting one or the other to 0 disables the feature.## By default min-slaves-to-write is set to 0 (feature disabled) and# min-slaves-max-lag is set to 10.################################## SECURITY ##################################################################### 安全 #################################### Require clients to issue AUTH &lt;PASSWORD&gt; before processing any other# commands. This might be useful in environments in which you do not trust# others with access to the host running redis-server.## This should stay commented out for backward compatibility and because most# people do not need auth (e.g. they run their own servers).## Warning: since Redis is pretty fast an outside user can try up to# 150k passwords per second against a good box. This means that you should# use a very strong password otherwise it will be very easy to break.## 设置连接redis的密码# redis速度相当快，一个外部用户在一秒钟进行150K次密码尝试，需指定强大的密码来防止暴力破解requirepass set_enough_strong_passwd# Command renaming.## It is possible to change the name of dangerous commands in a shared# environment. For instance the CONFIG command may be renamed into something# hard to guess so that it will still be available for internal-use tools# but not available for general clients.## Example:## rename-command CONFIG b840fc02d524045429941cc15f59e41cb7be6c52## It is also possible to completely kill a command by renaming it into# an empty string:## rename-command CONFIG \"\"## Please note that changing the name of commands that are logged into the# AOF file or transmitted to slaves may cause problems.# 重命名一些高危命令，用来禁止高危命令rename-command FLUSHALL ZYzv6FOBdwflW2nXrename-command CONFIG aI7zwm1GDzMMrEirename-command EVAL S9UHPKEpSvUJMMrename-command FLUSHDB D60FPVDJuip7gy6l################################### LIMITS ####################################################################### 限制 ##################################### Set the max number of connected clients at the same time. By default# this limit is set to 10000 clients, however if the Redis server is not# able to configure the process file limit to allow for the specified limit# the max number of allowed clients is set to the current file limit# minus 32 (as Redis reserves a few file descriptors for internal uses).## Once the limit is reached Redis will close all the new connections sending# an error 'max number of clients reached'.## 限制同时连接的客户数量,默认是10000# 当连接数超过这个值时，redis 将不再接收其他连接请求，客户端尝试连接时将收到 error 信息# maxclients 10000# Don't use more memory than the specified amount of bytes.# When the memory limit is reached Redis will try to remove keys# according to the eviction policy selected (see maxmemory-policy).## If Redis can't remove keys according to the policy, or if the policy is# set to 'noeviction', Redis will start to reply with errors to commands# that would use more memory, like SET, LPUSH, and so on, and will continue# to reply to read-only commands like GET.## This option is usually useful when using Redis as an LRU cache, or to set# a hard memory limit for an instance (using the 'noeviction' policy).## WARNING: If you have slaves attached to an instance with maxmemory on,# the size of the output buffers needed to feed the slaves are subtracted# from the used memory count, so that network problems / resyncs will# not trigger a loop where keys are evicted, and in turn the output# buffer of slaves is full with DELs of keys evicted triggering the deletion# of more keys, and so forth until the database is completely emptied.## In short... if you have slaves attached it is suggested that you set a lower# limit for maxmemory so that there is some free RAM on the system for slave# output buffers (but this is not needed if the policy is 'noeviction').## 设置redis能够使用的最大内存。# 达到最大内存设置后，Redis会先尝试清除已到期或即将到期的Key（设置过expire信息的key）# 在删除时,按照过期时间进行删除，最早将要被过期的key将最先被删除# 如果已到期或即将到期的key删光，仍进行set操作，那么将返回错误# 此时redis将不再接收写请求,只接收get请求。# maxmemory的设置比较适合于把redis当作于类似memcached 的缓存来使用# maxmemory &lt;bytes&gt;# MAXMEMORY POLICY: how Redis will select what to remove when maxmemory# is reached. You can select among five behaviors:## volatile-lru -&gt; remove the key with an expire set using an LRU algorithm# allkeys-lru -&gt; remove any key according to the LRU algorithm# volatile-random -&gt; remove a random key with an expire set# allkeys-random -&gt; remove a random key, any key# volatile-ttl -&gt; remove the key with the nearest expire time (minor TTL)# noeviction -&gt; don't expire at all, just return an error on write operations## Note: with any of the above policies, Redis will return an error on write# operations, when there are no suitable keys for eviction.## At the date of writing these commands are: set setnx setex append# incr decr rpush lpush rpushx lpushx linsert lset rpoplpush sadd# sinter sinterstore sunion sunionstore sdiff sdiffstore zadd zincrby# zunionstore zinterstore hset hsetnx hmset hincrby incrby decrby# getset mset msetnx exec sort## The default is:## maxmemory-policy noeviction# LRU and minimal TTL algorithms are not precise algorithms but approximated# algorithms (in order to save memory), so you can tune it for speed or# accuracy. For default Redis will check five keys and pick the one that was# used less recently, you can change the sample size using the following# configuration directive.## The default of 5 produces good enough results. 10 Approximates very closely# true LRU but costs a bit more CPU. 3 is very fast but not very accurate.## maxmemory-samples 5############################## APPEND ONLY MODE ################################ By default Redis asynchronously dumps the dataset on disk. This mode is# good enough in many applications, but an issue with the Redis process or# a power outage may result into a few minutes of writes lost (depending on# the configured save points).## The Append Only File is an alternative persistence mode that provides# much better durability. For instance using the default data fsync policy# (see later in the config file) Redis can lose just one second of writes in a# dramatic event like a server power outage, or a single write if something# wrong with the Redis process itself happens, but the operating system is# still running correctly.## AOF and RDB persistence can be enabled at the same time without problems.# If the AOF is enabled on startup Redis will load the AOF, that is the file# with the better durability guarantees.## Please check http://redis.io/topics/persistence for more information.# redis 默认每次更新操作后会在后台异步的把数据库镜像备份到磁盘，但该备份非常耗时，且备份不宜太频繁# redis 同步数据文件是按上面save条件来同步的# 如果发生诸如拉闸限电、拔插头等状况,那么将造成比较大范围的数据丢失# 所以redis提供了另外一种更加高效的数据库备份及灾难恢复方式# 开启append only 模式后,redis 将每一次写操作请求都追加到appendonly.aof 文件中# redis重新启动时,会从该文件恢复出之前的状态。# 但可能会造成 appendonly.aof 文件过大，所以redis支持BGREWRITEAOF 指令，对appendonly.aof重新整理,默认是不开启的。appendonly no# The name of the append only file (default: \"appendonly.aof\")# 默认为appendonly.aof。appendfilename \"appendonly.aof\"# The fsync() call tells the Operating System to actually write data on disk# instead of waiting for more data in the output buffer. Some OS will really flush# data on disk, some other OS will just try to do it ASAP.## Redis supports three different modes:## no: don't fsync, just let the OS flush the data when it wants. Faster.# always: fsync after every write to the append only log. Slow, Safest.# everysec: fsync only one time every second. Compromise.## The default is \"everysec\", as that's usually the right compromise between# speed and data safety. It's up to you to understand if you can relax this to# \"no\" that will let the operating system flush the output buffer when# it wants, for better performances (but if you can live with the idea of# some data loss consider the default persistence mode that's snapshotting),# or on the contrary, use \"always\" that's very slow but a bit safer than# everysec.## More details please check the following article:# http://antirez.com/post/redis-persistence-demystified.html## If unsure, use \"everysec\".# 设置对 appendonly.aof 文件进行同步的频率,有三种选择always、everysec、no，默认是everysec表示每秒同步一次。# always 表示每次有写操作都进行同步,everysec 表示对写操作进行累积,每秒同步一次。# no表示等操作系统进行数据缓存同步到磁盘，都进行同步,everysec 表示对写操作进行累积,每秒同步一次# appendfsync always# appendfsync everysec# appendfsync no# When the AOF fsync policy is set to always or everysec, and a background# saving process (a background save or AOF log background rewriting) is# performing a lot of I/O against the disk, in some Linux configurations# Redis may block too long on the fsync() call. Note that there is no fix for# this currently, as even performing fsync in a different thread will block# our synchronous write(2) call.## In order to mitigate this problem it's possible to use the following option# that will prevent fsync() from being called in the main process while a# BGSAVE or BGREWRITEAOF is in progress.## This means that while another child is saving, the durability of Redis is# the same as \"appendfsync none\". In practical terms, this means that it is# possible to lose up to 30 seconds of log in the worst scenario (with the# default Linux settings).## If you have latency problems turn this to \"yes\". Otherwise leave it as# \"no\" that is the safest pick from the point of view of durability.# 指定是否在后台aof文件rewrite期间调用fsync，默认为no，表示要调用fsync（无论后台是否有子进程在刷盘）。Redis在后台写RDB文件或重写afo文件期间会存在大量磁盘IO，此时，在某些linux系统中，调用fsync可能会阻塞。no-appendfsync-on-rewrite yes# Automatic rewrite of the append only file.# Redis is able to automatically rewrite the log file implicitly calling# BGREWRITEAOF when the AOF log size grows by the specified percentage.## This is how it works: Redis remembers the size of the AOF file after the# latest rewrite (if no rewrite has happened since the restart, the size of# the AOF at startup is used).## This base size is compared to the current size. If the current size is# bigger than the specified percentage, the rewrite is triggered. Also# you need to specify a minimal size for the AOF file to be rewritten, this# is useful to avoid rewriting the AOF file even if the percentage increase# is reached but it is still pretty small.## Specify a percentage of zero in order to disable the automatic AOF# rewrite feature.# 指定Redis重写aof文件的条件，默认为100，表示与上次rewrite的aof文件大小相比，当前aof文件增长量超过上次afo文件大小的100%时，就会触发background rewrite。若配置为0，则会禁用自动rewriteauto-aof-rewrite-percentage 100# 指定触发rewrite的aof文件大小。若aof文件小于该值，即使当前文件的增量比例达到auto-aof-rewrite-percentage的配置值，也不会触发自动rewrite。即这两个配置项同时满足时，才会触发rewrite。auto-aof-rewrite-min-size 64mb# An AOF file may be found to be truncated at the end during the Redis# startup process, when the AOF data gets loaded back into memory.# This may happen when the system where Redis is running# crashes, especially when an ext4 filesystem is mounted without the# data=ordered option (however this can't happen when Redis itself# crashes or aborts but the operating system still works correctly).## Redis can either exit with an error when this happens, or load as much# data as possible (the default now) and start if the AOF file is found# to be truncated at the end. The following option controls this behavior.## If aof-load-truncated is set to yes, a truncated AOF file is loaded and# the Redis server starts emitting a log to inform the user of the event.# Otherwise if the option is set to no, the server aborts with an error# and refuses to start. When the option is set to no, the user requires# to fix the AOF file using the \"redis-check-aof\" utility before to restart# the server.## Note that if the AOF file will be found to be corrupted in the middle# the server will still exit with an error. This option only applies when# Redis will try to read more data from the AOF file but not enough bytes# will be found.aof-load-truncated yes################################ LUA SCRIPTING ################################ Max execution time of a Lua script in milliseconds.## If the maximum execution time is reached Redis will log that a script is# still in execution after the maximum allowed time and will start to# reply to queries with an error.## When a long running script exceeds the maximum execution time only the# SCRIPT KILL and SHUTDOWN NOSAVE commands are available. The first can be# used to stop a script that did not yet called write commands. The second# is the only way to shut down the server in the case a write command was# already issued by the script but the user doesn't want to wait for the natural# termination of the script.## Set it to 0 or a negative value for unlimited execution without warnings.# 一个Lua脚本最长的执行时间，单位为毫秒，如果为0或负数表示无限执行时间，默认为5000lua-time-limit 5000################################ REDIS CLUSTER ################################# ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++# WARNING EXPERIMENTAL: Redis Cluster is considered to be stable code, however# in order to mark it as \"mature\" we need to wait for a non trivial percentage# of users to deploy it in production.# ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++## Normal Redis instances can't be part of a Redis Cluster; only nodes that are# started as cluster nodes can. In order to start a Redis instance as a# cluster node enable the cluster support uncommenting the following:## cluster-enabled yes# Every cluster node has a cluster configuration file. This file is not# intended to be edited by hand. It is created and updated by Redis nodes.# Every Redis Cluster node requires a different cluster configuration file.# Make sure that instances running in the same system do not have# overlapping cluster configuration file names.## cluster-config-file nodes-6379.conf# Cluster node timeout is the amount of milliseconds a node must be unreachable# for it to be considered in failure state.# Most other internal time limits are multiple of the node timeout.## cluster-node-timeout 15000# A slave of a failing master will avoid to start a failover if its data# looks too old.## There is no simple way for a slave to actually have a exact measure of# its \"data age\", so the following two checks are performed:## 1) If there are multiple slaves able to failover, they exchange messages# in order to try to give an advantage to the slave with the best# replication offset (more data from the master processed).# Slaves will try to get their rank by offset, and apply to the start# of the failover a delay proportional to their rank.## 2) Every single slave computes the time of the last interaction with# its master. This can be the last ping or command received (if the master# is still in the \"connected\" state), or the time that elapsed since the# disconnection with the master (if the replication link is currently down).# If the last interaction is too old, the slave will not try to failover# at all.## The point \"2\" can be tuned by user. Specifically a slave will not perform# the failover if, since the last interaction with the master, the time# elapsed is greater than:## (node-timeout * slave-validity-factor) + repl-ping-slave-period## So for example if node-timeout is 30 seconds, and the slave-validity-factor# is 10, and assuming a default repl-ping-slave-period of 10 seconds, the# slave will not try to failover if it was not able to talk with the master# for longer than 310 seconds.## A large slave-validity-factor may allow slaves with too old data to failover# a master, while a too small value may prevent the cluster from being able to# elect a slave at all.## For maximum availability, it is possible to set the slave-validity-factor# to a value of 0, which means, that slaves will always try to failover the# master regardless of the last time they interacted with the master.# (However they'll always try to apply a delay proportional to their# offset rank).## Zero is the only value able to guarantee that when all the partitions heal# the cluster will always be able to continue.## cluster-slave-validity-factor 10# Cluster slaves are able to migrate to orphaned masters, that are masters# that are left without working slaves. This improves the cluster ability# to resist to failures as otherwise an orphaned master can't be failed over# in case of failure if it has no working slaves.## Slaves migrate to orphaned masters only if there are still at least a# given number of other working slaves for their old master. This number# is the \"migration barrier\". A migration barrier of 1 means that a slave# will migrate only if there is at least 1 other working slave for its master# and so forth. It usually reflects the number of slaves you want for every# master in your cluster.## Default is 1 (slaves migrate only if their masters remain with at least# one slave). To disable migration just set it to a very large value.# A value of 0 can be set but is useful only for debugging and dangerous# in production.## cluster-migration-barrier 1# By default Redis Cluster nodes stop accepting queries if they detect there# is at least an hash slot uncovered (no available node is serving it).# This way if the cluster is partially down (for example a range of hash slots# are no longer covered) all the cluster becomes, eventually, unavailable.# It automatically returns available as soon as all the slots are covered again.## However sometimes you want the subset of the cluster which is working,# to continue to accept queries for the part of the key space that is still# covered. In order to do so, just set the cluster-require-full-coverage# option to no.## cluster-require-full-coverage yes# In order to setup your cluster make sure to read the documentation# available at http://redis.io web site.################################## SLOW LOG #################################### The Redis Slow Log is a system to log queries that exceeded a specified# execution time. The execution time does not include the I/O operations# like talking with the client, sending the reply and so forth,# but just the time needed to actually execute the command (this is the only# stage of command execution where the thread is blocked and can not serve# other requests in the meantime).## You can configure the slow log with two parameters: one tells Redis# what is the execution time, in microseconds, to exceed in order for the# command to get logged, and the other parameter is the length of the# slow log. When a new command is logged the oldest one is removed from the# queue of logged commands.# The following time is expressed in microseconds, so 1000000 is equivalent# to one second. Note that a negative number disables the slow log, while# a value of zero forces the logging of every command.slowlog-log-slower-than 10000# There is no limit to this length. Just be aware that it will consume memory.# You can reclaim memory used by the slow log with SLOWLOG RESET.slowlog-max-len 128################################ LATENCY MONITOR ############################### The Redis latency monitoring subsystem samples different operations# at runtime in order to collect data related to possible sources of# latency of a Redis instance.## Via the LATENCY command this information is available to the user that can# print graphs and obtain reports.## The system only logs operations that were performed in a time equal or# greater than the amount of milliseconds specified via the# latency-monitor-threshold configuration directive. When its value is set# to zero, the latency monitor is turned off.## By default latency monitoring is disabled since it is mostly not needed# if you don't have latency issues, and collecting data has a performance# impact, that while very small, can be measured under big load. Latency# monitoring can easily be enabled at runtime using the command# \"CONFIG SET latency-monitor-threshold &lt;milliseconds&gt;\" if needed.latency-monitor-threshold 0############################# EVENT NOTIFICATION ############################### Redis can notify Pub/Sub clients about events happening in the key space.# This feature is documented at http://redis.io/topics/notifications## For instance if keyspace events notification is enabled, and a client# performs a DEL operation on key \"foo\" stored in the Database 0, two# messages will be published via Pub/Sub:## PUBLISH __keyspace@0__:foo del# PUBLISH __keyevent@0__:del foo## It is possible to select the events that Redis will notify among a set# of classes. Every class is identified by a single character:## K Keyspace events, published with __keyspace@&lt;db&gt;__ prefix.# E Keyevent events, published with __keyevent@&lt;db&gt;__ prefix.# g Generic commands (non-type specific) like DEL, EXPIRE, RENAME, ...# $ String commands# l List commands# s Set commands# h Hash commands# z Sorted set commands# x Expired events (events generated every time a key expires)# e Evicted events (events generated when a key is evicted for maxmemory)# A Alias for g$lshzxe, so that the \"AKE\" string means all the events.## The \"notify-keyspace-events\" takes as argument a string that is composed# of zero or multiple characters. The empty string means that notifications# are disabled.## Example: to enable list and generic events, from the point of view of the# event name, use:## notify-keyspace-events Elg## Example 2: to get the stream of the expired keys subscribing to channel# name __keyevent@0__:expired use:## notify-keyspace-events Ex## By default all notifications are disabled because most users don't need# this feature and the feature has some overhead. Note that if you don't# specify at least one of K or E, no events will be delivered.notify-keyspace-events \"\"############################### ADVANCED CONFIG ################################ Hashes are encoded using a memory efficient data structure when they have a# small number of entries, and the biggest entry does not exceed a given# threshold. These thresholds can be configured using the following directives.# 当hash中包含超过指定元素个数并且最大的元素没有超过临界时，# hash将以一种特殊的编码方式（大大减少内存使用）来存储，这里可以设置这两个临界值hash-max-ziplist-entries 512hash-max-ziplist-value 64# Similarly to hashes, small lists are also encoded in a special way in order# to save a lot of space. The special representation is only used when# you are under the following limits:# list数据类型多少节点以下会采用去指针的紧凑存储格式。# list数据类型节点值大小小于多少字节会采用紧凑存储格式。list-max-ziplist-entries 512list-max-ziplist-value 64# Sets have a special encoding in just one case: when a set is composed# of just strings that happen to be integers in radix 10 in the range# of 64 bit signed integers.# The following configuration setting sets the limit in the size of the# set in order to use this special memory saving encoding.# set数据类型内部数据如果全部是数值型，且包含多少节点以下会采用紧凑格式存储。set-max-intset-entries 512# Similarly to hashes and lists, sorted sets are also specially encoded in# order to save a lot of space. This encoding is only used when the length and# elements of a sorted set are below the following limits:# zsort数据类型多少节点以下会采用去指针的紧凑存储格式。# zsort数据类型节点值大小小于多少字节会采用紧凑存储格式。zset-max-ziplist-entries 128zset-max-ziplist-value 64# HyperLogLog sparse representation bytes limit. The limit includes the# 16 bytes header. When an HyperLogLog using the sparse representation crosses# this limit, it is converted into the dense representation.## A value greater than 16000 is totally useless, since at that point the# dense representation is more memory efficient.## The suggested value is ~ 3000 in order to have the benefits of# the space efficient encoding without slowing down too much PFADD,# which is O(N) with the sparse encoding. The value can be raised to# ~ 10000 when CPU is not a concern, but space is, and the data set is# composed of many HyperLogLogs with cardinality in the 0 - 15000 range.hll-sparse-max-bytes 3000# Active rehashing uses 1 millisecond every 100 milliseconds of CPU time in# order to help rehashing the main Redis hash table (the one mapping top-level# keys to values). The hash table implementation Redis uses (see dict.c)# performs a lazy rehashing: the more operation you run into a hash table# that is rehashing, the more rehashing \"steps\" are performed, so if the# server is idle the rehashing is never complete and some more memory is used# by the hash table.## The default is to use this millisecond 10 times every second in order to# actively rehash the main dictionaries, freeing memory when possible.## If unsure:# use \"activerehashing no\" if you have hard latency requirements and it is# not a good thing in your environment that Redis can reply from time to time# to queries with 2 milliseconds delay.## use \"activerehashing yes\" if you don't have such hard requirements but# want to free memory asap when possible.# Redis将在每100毫秒时使用1毫秒的CPU时间来对redis的hash表进行重新hash，可以降低内存的使用# 当你的使用场景中，有非常严格的实时性需要，不能够接受Redis时不时的对请求有2毫秒的延迟的话，把这项配置为no。# 如果没有这么严格的实时性要求，可以设置为yes，以便能够尽可能快的释放内存activerehashing yes# The client output buffer limits can be used to force disconnection of clients# that are not reading data from the server fast enough for some reason (a# common reason is that a Pub/Sub client can't consume messages as fast as the# publisher can produce them).## The limit can be set differently for the three different classes of clients:## normal -&gt; normal clients including MONITOR clients# slave -&gt; slave clients# pubsub -&gt; clients subscribed to at least one pubsub channel or pattern## The syntax of every client-output-buffer-limit directive is the following:## client-output-buffer-limit &lt;class&gt; &lt;hard limit&gt; &lt;soft limit&gt; &lt;soft seconds&gt;## A client is immediately disconnected once the hard limit is reached, or if# the soft limit is reached and remains reached for the specified number of# seconds (continuously).# So for instance if the hard limit is 32 megabytes and the soft limit is# 16 megabytes / 10 seconds, the client will get disconnected immediately# if the size of the output buffers reach 32 megabytes, but will also get# disconnected if the client reaches 16 megabytes and continuously overcomes# the limit for 10 seconds.## By default normal clients are not limited because they don't receive data# without asking (in a push way), but just after a request, so only# asynchronous clients may create a scenario where data is requested faster# than it can read.## Instead there is a default limit for pubsub and slave clients, since# subscribers and slaves receive data in a push fashion.## Both the hard or the soft limit can be disabled by setting them to zero.client-output-buffer-limit normal 0 0 0client-output-buffer-limit slave 256mb 64mb 60client-output-buffer-limit pubsub 32mb 8mb 60# Redis calls an internal function to perform many background tasks, like# closing connections of clients in timeout, purging expired keys that are# never requested, and so forth.## Not all tasks are performed with the same frequency, but Redis checks for# tasks to perform according to the specified \"hz\" value.## By default \"hz\" is set to 10. Raising the value will use more CPU when# Redis is idle, but at the same time will make Redis more responsive when# there are many keys expiring at the same time, and timeouts may be# handled with more precision.## The range is between 1 and 500, however a value over 100 is usually not# a good idea. Most users should use the default of 10 and raise this up to# 100 only in environments where very low latency is required.hz 10# When a child rewrites the AOF file, if the following option is enabled# the file will be fsync-ed every 32 MB of data generated. This is useful# in order to commit the file to the disk more incrementally and avoid# big latency spikes.# aof rewrite过程中,是否采取增量文件同步策略,默认为“yes”。 rewrite过程中,每32M数据进行一次文件同步,这样可以减少aof大文件写入对磁盘的操作次数aof-rewrite-incremental-fsync yes# redis数据存储redis的存储分为内存存储、磁盘存储和log文件三部分，配置文件中有三个参数对其进行配置。save seconds updates，save配置，指出在多长时间内，有多少次更新操作，就将数据同步到数据文件。可多个条件配合，默认配置了三个条件。appendonly yes/no ，appendonly配置，指出是否在每次更新操作后进行日志记录，如果不开启，可能会在断电时导致一段时间内的数据丢失。因为redis本身同步数据文件是按上面的save条件来同步的，所以有的数据会在一段时间内只存在于内存中。appendfsync no/always/everysec ，appendfsync配置，no表示等操作系统进行数据缓存同步到磁盘，always表示每次更新操作后手动调用fsync()将数据写到磁盘，everysec表示每秒同步一次。","categories":[{"name":"技术","slug":"技术","permalink":"http://www.sillystone.info/categories/技术/"}],"tags":[{"name":"redis","slug":"redis","permalink":"http://www.sillystone.info/tags/redis/"}]},{"title":"阿里RocketMQ开发者见面会","date":"2017-07-03T04:21:17.000Z","path":"2017/07/03/阿里RocketMQ开发者见面会/","text":"故事自从上次被阿里面试虐过一次后，最近研究了一下流行的分布式系统技术架构。 阿里的rocketMQ最近加入了apache基金会阵营，也一下变得火了。 35度的北京， 会场满满的都是人（估计这么一屋子IT合起来的估值也不小） 会议组织的一般，节奏，内容，互动都没有很好。案例分享也没有含金量。 Flink Spark standalone架构 总结apache 开源项目 开源协议介绍（单位里也介绍过，了解更多了） 社区，相关参与角色的介绍 社区贡献决定了在项目中的地位 产品总结 消息处理：kafka VS RocketMQ 流式 实时/批量处理：flink/storm/spark stream VS spark/hadoopflink 已试用 框架： beam 分布式日志收集，处理：Flume 主题内容1、分布式消息引擎最佳实践主要分享分布式消息引擎的功能特性(顺序消息、SQL Filtering、 Batch、 LogAppender), 使用场景（金融交易、大数据等），以及生产实践的常用问题 2、分布式消息引擎性能优化及大数据生态主要分享百万吞吐与低延迟的奥秘，RocketMQ与Kafka的对比，阿里云上Kafka的优化与实施 周新宇：Apache RocketMQ PMC/Committer，2015年阿里巴巴性能挑战大赛冠军。目前主要负责消息引擎RocketMQ的性能优化，规范演进以及社区输出 3、基于分布式消息引擎的流计算本主题主要分享对流处理和消息系统的理解，以及在项目实践过程中流处理和消息系统集成的经验等。 王鑫：Apache Storm PMC/Committer，流处理技术专家，开源爱好者。5年高性能分布式系统研发经验。负责过分布式网络爬虫、内容聚合、用户行为分析、个性化推荐等大数据项目。目前主要兴趣在于分布式流处理引擎、分布式消息引擎等。对分布式系统的架构及调优有丰富经验。 storm作为流式计算的案例分享 4、RocketMQ-MySQL-Connector项目介绍主要分享RocketMQ-MySQL-Connector项目的应用场景，目前的进展情况以及未来的规划。 赵群：Apache RocketMQ Contributor，开源爱好者，多年高并发系统架构经验，目前从事通信平台建设工作，主要关注分布式系统、网络通信等领域。 可以用于 数据库复制/数据在线迁移的工具， 介绍了实践案例：是基于数据库日志的事物读取 并通过RocketMQ 发送给下游的应用 Apache Way：如何打造世界级软件产品主要分享对Apache Way的理解，建设Apache社区的经验，以及如何打造一款能在世界范围内被认可的软件产品","categories":[{"name":"技术","slug":"技术","permalink":"http://www.sillystone.info/categories/技术/"}],"tags":[{"name":"大数据","slug":"大数据","permalink":"http://www.sillystone.info/tags/大数据/"},{"name":"分布式","slug":"分布式","permalink":"http://www.sillystone.info/tags/分布式/"},{"name":"消息服务","slug":"消息服务","permalink":"http://www.sillystone.info/tags/消息服务/"}]},{"title":"奇葩说","date":"2017-06-24T15:58:55.000Z","path":"2017/06/24/奇葩说/","text":"朋友介绍，看了《奇葩说》 第四季的最后一场 辩论本身题目我们终将变成我们讨厌的人； 成为讨厌的人是坏事吗？ 辩论要点 讨厌的定义 讨厌不是憎恨，讨厌的事不是大家所共识的堕落的事， 讨厌是个人在特定时段的感情 讨厌有轻重，我认为：讨厌的事就是做了超过自己底线的事，而底线，每个人不同，每个时间段也不同 我们 我们，意指所有的人，不是个人的个别特例；这点将所有的极端举例都驳倒 （老罗） 终将 代表着时间跨度 夹杂着感情，无奈，悲观感情 变 观念的变化 对于变化的接纳 命题:这种变化是否是坏事 变化是否有黑白之分 变化的定义决定了褒贬的成分。 （老罗把这种变化定义为成长，提出勇敢面对变化） 坏的界定我认为：坏是个人感情表达，好坏本身是黑白分明的，没有灰度的；对于自己是否可以容忍自己跨越底线这件事情本身，是不喜欢的，是坏的，这点大家应该是没有疑问的。 老罗回避了这点，而是给大家讲述了 对于你面对的这个坏事情 你要选择怎么处理，提出能够接纳变化，能够适应成长，对于不同的差异更能提高自己的容忍度，提高自己的适应力；但对于很重要的底线 我认为我们不应该随意修改，但重要不重要只有你知道 辩手观点总结黄执中： 强化了讨厌的程度，提供了强力的实例；跳出轮回，摆脱人性束缚的人才是伟大的人，不要自我和解马薇薇： 强调了个性受社会和现实的约束，好的社会尊重个人喜好，提供发展空间；社会是无情的命运是无情的，人成长就是坏事 蔡康永：讨厌是青年不成熟的想法，接纳变化是成熟的表现马东：事与愿违的事往往是正确的，而变成你讨厌的人这件事，也是事与愿违的事讨厌有很多场景，也有轻重之分，很难用这个词界定好坏；世事洞明 却不以事故待人老罗：成长是主观不断重建的过程，这个过程你需要不断地接纳变化，接受挑战 感思想的对抗比思想的陈述更值得思考奇袭之所以可行，在于观点之间没有强弱之分 摘万物皆裂痕，那又怎样，裂痕，那是光照进来的地方 成长， 就是你主观世界遇到 客观世界的那条沟。 掉进去了，叫挫折； 爬出来了，叫成长","categories":[{"name":"随笔","slug":"随笔","permalink":"http://www.sillystone.info/categories/随笔/"}],"tags":[{"name":"日记","slug":"日记","permalink":"http://www.sillystone.info/tags/日记/"}]},{"title":"需求分析培训","date":"2017-06-17T01:30:04.000Z","path":"2017/06/17/需求分析培训/","text":"价值需求宏观需求 功能需求流程-&gt;场景-&gt;功能 流程确定： 端到端业务需求分析： 起始端-接入系统开始（业务模型分析： 起始端-最终） 四类流程： 主业务流程（主业务） ：入住流程 变体业务流程（辅助业务）：换房，续房 支撑流程（服务，辅助）： 客房服务，查询，投诉 管理流程（控制）：押金不足 业务流程是分层的： 组织级流程： 展现部门间协助，部门维度（同级别组织） 部门级流程： 展现岗位间协作，岗位/系统 个人级流程 业务流程八个要素： 分工（规模，风险，专业） # 协作 活动 异常 规则 描述业务流程： 工具 跨职能流程图：商业建模标准，复用性强，用户接受，并行，异步支持差 活动图：UML标准，语义分析，强调行为流，强调活动内容 时序图：UML标准，强调行为流，强调协作，交互，技术常用 数据流图（上下文关系）：IDEF建模标准，强调数据流，未标识谁执行，计费类系统适合 现场出流程图 客户代表陈述，不打断，绘出脉络 具体岗位，数据规则，分支与异常，管控 绘图复述，客户代表验证，达成共识 流程派生场景观察： 典型一天， 关键时点竞品拆解头脑风暴： 意图 时间 地点 周边 功能生成： 场景-挑战-方案：场景和挑战稳定， 方案开发和需求一起讨论使用场景：事件流 UI要求 交互过程： 非必需，别忽略； 可用POP等工具； 可用界面流转图 静态快照： 直观，易于理解；可使用AxureRP；别过于追求细节 设计说明：界面元素的用途；界面的数据要求；界面的操作需求 第四节课： 其他需求管理需求明确管理需求-&gt;拆解为指标-&gt; 报表 指标完整度 数据需求数据构成；关系，范围；推演 领域模型适用场景： 1&gt;不熟悉的领域， 2&gt;大量数据复杂关系领域建模：使用母语领域建模：使用类图 类图相关说明：聚合：空心， 可独立存在组合：实心 关联存在 类图业务解读： 四色建模法 质量需求逆向思考： 危险导向的非功能需求识别关键质量需求易用性的挑战：和开发不一样的用户 POINTS 术语 的规范定义 关键业务：业务角度定义：一个流程/ 一个场景 迭代手段，增量是目标 图：是简洁表达的方式， 不简洁的图不是合格的图 人/岗位/系统/人工智能 协同办理 敏捷不是消灭分工，敏捷是专业化分工后的主动补位 实线代表工作流 虚线代表数据流 规则：容易执行 活动取代数据 大师都不用计算机工具 需求文档，架构文档，业务测试文档 对方思维流程未结束前不打断 场景： 面向大批量用户，用户态描述。独立，停止，有价值，可汇报。同比 工作职责说明书 高净值用户不care每日收益 《用户故事地图》 流程活动对应两方参与者，主/从； 一般保留服务人员的活动，用户操作手册体现用户的活动 风控；常态 时态 异态 《设计心理学》4本 体验设计 UE， UX：用户体验工程师 探索型购物需求，必须品购物需求 指标体系是数据运营的 peter coad 成就：color UML四色建模法， FDD 特征驱动开发过程 数据架构的稳定性，接受场景的挑战 春秋航空自己的订票系统，中航信 298033@qq.com OTH POINTS 需求来源： 7宗罪， 欲望 存储需求：喜欢的or不喜欢的 or 不care","categories":[{"name":"技术","slug":"技术","permalink":"http://www.sillystone.info/categories/技术/"}],"tags":[{"name":"项目","slug":"项目","permalink":"http://www.sillystone.info/tags/项目/"},{"name":"需求","slug":"需求","permalink":"http://www.sillystone.info/tags/需求/"}]},{"title":"一道考题","date":"2017-06-11T14:34:13.000Z","path":"2017/06/11/一道考题/","text":"beginning单位组织编程比赛，在线编写代码，评比指标：性能题目包括： 大量数据 文件 数据高效处理 实时界面交互 环境： 百度云，centos prepareday 1主流大数据 框架以上内容都基于hadoop， storm还依赖zookeeper 暂时忽略。 storm example spark start netty java 并发[java 并发介绍] (http://www.importnew.com/14506.html) oracle example示例程序 java并行框架 akka introduce 要点介绍 nodejs 框架适合IO高并发， 对于CPU 并行计算。。。 erlang待了解 addsbenchmark toolwrk - a HTTP benchmarking tool","categories":[{"name":"技术","slug":"技术","permalink":"http://www.sillystone.info/categories/技术/"}],"tags":[{"name":"java","slug":"java","permalink":"http://www.sillystone.info/tags/java/"},{"name":"大数据","slug":"大数据","permalink":"http://www.sillystone.info/tags/大数据/"},{"name":"分布式","slug":"分布式","permalink":"http://www.sillystone.info/tags/分布式/"},{"name":"并行计算","slug":"并行计算","permalink":"http://www.sillystone.info/tags/并行计算/"}]},{"title":"db2 工具使用总结","date":"2017-05-13T01:45:30.000Z","path":"2017/05/13/db2-工具使用总结/","text":"常用工具包括：db2top db2pd, db2load db2import以下详细说明每个工具使用总结 性能工具备份/恢复import包含自增列的数据导入 数据中不包含自增列 12db2 import from import.del of del modified by identitymissing replace into table1 数据中包含自增列 12db2 import from import.del of del modified by identityignore replace into table1 loadload 后导致表空间状态为BackupPending， 以下为解释。 Normal The Normal state is the initial state of a table space after it is created, indicating that no (abnormal) states currently affect it. Load in Progress The Load in Progress state indicates that there is a load in progress on the table space. This state prevents the backup of dependent tables during the load. The table space state is distinct from the Load in Progress table state (which is used in all load operations) because the load utility places table spaces in the Load in Progress state only when you specify the COPY NO parameter for a recoverable database. The table spaces remain in this state for the duration of the load operation. * Backup Pending * If you perform a load operation for a recoverable database and specify the COPY NO parameter, table spaces are placed in the Backup Pending table space state after the first commit. You cannot update a table space in the Backup Pending state. You can remove the table space from the Backup Pending state only by backing up the table space. Even if you cancel the load operation, the table space remains in the Backup Pending state because the table space state is changed at the beginning of the load operation and cannot be rolled back. * Restore Pending * If you perform a successful load operation with the COPY NO option, restore the database, and then rollforward through that operation, the associated table spaces are placed in the Restore Pending state. To remove the table spaces from the Restore Pending state, you must perform a restore operation. 解决方法： norecoverable or copy yes12--db2 load from staff.del of del insert into staff nonrecoverable db2 load from staff.del of del insert into staff copy yes to . --推荐使用yes 123456db2set DB2_LOAD_COPY_NO_OVERRIDE=\"COPY YES TO E:\\TEST\" --db2set DB2_LOAD_COPY_NO_OVERRIDE=NONRECOVERABLE db2 terminatedb2set --显示配置结果db2 load from staff.del of del insert into staff load的 copy参数相关说明如下： COPY NO Specifies that the table space in which the table resides will be placed in backup pending state if forward recovery is enabled (that is, if either logarchmeth1 or logarchmeth2 is set to a value other than OFF). The COPY NO option will also put the table space state into the Load in Progress table space state. This is a transient state that will disappear when the load completes or aborts. The data in any table in the table space cannot be updated or deleted until a table space backup or a full database backup is made. However, it is possible to access the data in any table by using the SELECT statement. LOAD with COPY NO on a recoverable database leaves the table spaces in a backup pending state. For example, performing a LOAD with COPY NO and INDEXING MODE DEFERRED will leave indexes needing a refresh. Certain queries on the table might require an index scan and will not succeed until the indexes are refreshed. The index cannot be refreshed if it resides in a table space which is in the backup pending state. In that case, access to the table will not be allowed until a backup is taken. Index refresh is done automatically by the database when the index is accessed by a query. If one of COPY NO, COPY YES, or NONRECOVERABLE is not specified, and the database is recoverable (logarchmeth1 or logarchmeth2 is set to value other than OFF), then COPY NO is the default. COPY YES Saves a copy of the loaded data. This parameter is invalid if forward recovery is disabled. USE TSM Specifies that the copy will be stored using IBM® Tivoli® Storage Manager. OPEN num-sess SESSIONS The number of I/O sessions to be used with TSM or the vendor product. The default value is 1. TO device/directory Specifies the device or directory on which the copy image will be created. LOAD lib-name The name of the shared library (DLL on Windows operating systems) containing the vendor backup and restore I/O functions to be used. It can contain the full path. If the full path is not given, it will default to the path where the user exit programs reside. NONRECOVERABLE Specifies that the load transaction is to be marked as unrecoverable and that it will not be possible to recover it by a subsequent roll forward action. The roll forward utility will skip the transaction and will mark the table into which data was being loaded as &quot;invalid&quot;. The utility will also ignore any subsequent transactions against that table. After the roll forward operation is completed, such a table can only be dropped or restored from a backup (full or table space) taken after a commit point following the completion of the nonrecoverable load operation. With this option, table spaces are not put in backup pending state following the load operation, and a copy of the loaded data does not have to be made during the load operation. If one of COPY NO, COPY YES, or NONRECOVERABLE is not specified, and the database is not recoverable (logarchmeth1 and logarchmeth2 are both set to OFF), then NONRECOVERABLE is the default. db2look 导出表结构db2look -d db_name -e -o output 导出数据表，权限，表空间和缓冲，db2look -d db_name -e -a -l -x -o output","categories":[{"name":"技术","slug":"技术","permalink":"http://www.sillystone.info/categories/技术/"}],"tags":[{"name":"db2","slug":"db2","permalink":"http://www.sillystone.info/tags/db2/"}]},{"title":"在路上-台湾","date":"2017-05-12T14:15:00.000Z","path":"2017/05/12/宝岛点滴/","text":"台湾记忆街道台北的早上很安静， 干净的街道没什么人，商场，西餐店，咖啡店都不营业。 走了很久才找到一个早餐店，店里主要是卖蛋饼，往来的都是早起的大叔，或是出门买早餐的小孩子，吃早餐的人不少但不合我的口味。 台铁月台，传说中的月台， 可以标识出车厢，好神奇，为什么国内的站台不行花莲-瑞芳，倒换了三张票，也是醉了台铁好便宜。。。 地铁 - 捷运可能是周末的原因，地铁里人很少，座位都是空的，相比北京的人挤人，舒适多了。 我搭乘最多的是绿线（松山-新店）和红线（淡水-象山），从南京复兴到七分，大约40分钟，一路没什么人，大家都很安静，周末早上出行的人都为生活奔波着，没什么生气。 爱心座经常是空着的，我只好站着 公交最让我感到新奇的交通工具，上车要招手，否则可能飞驰而过，下车要提前按铃，公交上到处都可以很方便的找到下车按钮，车上人也不多，最好坐在座位上，座位上有安全带，可能因为车开的快有些路段又有山路的原因吧。 最后就是车上的刷卡指示牌， 我估计公交是分段计价的，一段路程是上车刷卡，一段路程下车刷卡，路程长的话可能上下都要刷卡，总之按车上的指示牌刷卡就好台北的司机 下车都要说声谢谢，感觉好客气 摩托台北的摩托车开的好快，绿灯刚一亮就飞了出去，路上总能听到呼啸而过的摩托车，面对飞车，我只好规规矩矩的等红绿灯有机会还是希望骑一下摩托车，感受一下风声。 电动车那辆 hello kitty电动车，追风的少年，迷人的海景 台湾人公交司机下车会说谢谢火车站的服务人员耐心的解说一日游巴士司机热心的拍照美术馆服务人员详细的解说宾馆，民宿周到的服务 显示出台湾人的服务； 国父纪念馆外练习街舞的学生 零碎浦发AE白，你值得拥有，谁用谁知道","categories":[{"name":"随笔","slug":"随笔","permalink":"http://www.sillystone.info/categories/随笔/"}],"tags":[{"name":"随笔","slug":"随笔","permalink":"http://www.sillystone.info/tags/随笔/"}]},{"title":"台湾","date":"2017-05-05T11:55:47.000Z","path":"2017/05/05/台湾/","text":"宝岛9日游, 多图预警 台北 故宫里的宝贝 高雄 中山大学 垦丁","categories":[{"name":"摄影","slug":"摄影","permalink":"http://www.sillystone.info/categories/摄影/"}],"tags":[{"name":"日记，摄影","slug":"日记，摄影","permalink":"http://www.sillystone.info/tags/日记，摄影/"}]},{"title":"山本耀司-文摘","date":"2017-04-09T09:47:11.000Z","path":"2017/04/09/山本耀司-文摘/","text":"山本耀司 日文名Yohji Yamamoto 走上旅程，我兜里有钱 买梦，我兜里有钱 我也能为她买一段生活 但为什么，我的背脊感到一丝凉意 奇，奇怪 奔跑的一生，不停歇 到达的终点，总会有 没什么能让我悲伤 只是背脊上那一丝凉意 * 过分认真的为那一天而活 我不能为那一天而活 好，我要出发。时间已到。 窗外司空见惯的风景 却好久不曾见到 玻璃窗外，布满污点和灰尘，同我一样 喜爱的绿色被黑色覆盖 新发的嫩芽，散发黄绿的亮丽色彩 好像我有点太过慵懒 好像我有点过于担忧 别发牢骚，会被人耻笑 要挺直腰杆做人 为那一天而活的意义在于 没办法为那一天而活 好，我要出发。时间已到 对你来说，贫困潦倒时用最后几个硬币买来的啤酒的味道，与，在半岛酒店的房间里穿着柔软 的浴袍喝着的冰香槟的味道，并无差别 今天，太阳依旧升起 当然，我无意揭露你明知故犯，违背自己原则的那一面 你，就是你 而我，就是喜欢你。 “自己”这个东西是看不见的，撞上一些别的什么,反弹回来，才会了解“自己”。 所以，跟很强的东西、可怕的东西、水准很高的东西相碰撞，然后才知道“自己”是什么，这才是自我 “时尚”不会让你变的性感，你的“经历”和“想象力”才能让你变得性感。 而要得到这些性感没有捷径，唯一的方法就是你得好好生活。 而我的内心总有一小部分，保留了一个顽皮捣蛋的孩童的内心。他只会突然转过身来， 对整个世界放肆地吐吐舌头。这样的我，面对他人的赞许，会不自在起来","categories":[{"name":"随笔","slug":"随笔","permalink":"http://www.sillystone.info/categories/随笔/"}],"tags":[{"name":"诗","slug":"诗","permalink":"http://www.sillystone.info/tags/诗/"},{"name":"文摘","slug":"文摘","permalink":"http://www.sillystone.info/tags/文摘/"}]},{"title":"养鱼记-大鱼吃小鱼","date":"2017-04-08T12:48:46.000Z","path":"2017/04/08/养鱼记-大鱼吃小鱼/","text":"早上突然发现鱼缸里有一条小鱼 黑色的，小小的 蝌蚪一样 他 应该刚出生不久 从草丛中游了出来 然后 一只燕鱼出现了 他，消失了 短暂的生命 多彩的世界 瞬间变成黑暗 后记：只发现两条小鱼，发现的瞬间，就被吃了，估计其他的小鱼也是如此","categories":[{"name":"随笔","slug":"随笔","permalink":"http://www.sillystone.info/categories/随笔/"}],"tags":[{"name":"日记","slug":"日记","permalink":"http://www.sillystone.info/tags/日记/"}]},{"title":"前端之CSS","date":"2017-03-30T14:29:49.000Z","path":"2017/03/30/前端之CSS/","text":"前端组件1. Dialogbootstrap-dialog满足所有Dialog的需求 修订需求： 全屏对话框：用来实现大量内容加载和录入 问题：对话框加载的页面如果是个组合页面（即:页面套页面），对话框大小无法自适应高度 修订：对于dialog的message内容定制 高度属性/css 类 参见：bootstrap-dialog 2. Table待补充","categories":[{"name":"技术","slug":"技术","permalink":"http://www.sillystone.info/categories/技术/"}],"tags":[{"name":"javascript","slug":"javascript","permalink":"http://www.sillystone.info/tags/javascript/"},{"name":"css","slug":"css","permalink":"http://www.sillystone.info/tags/css/"}]},{"title":"Linux相关","date":"2017-03-29T09:14:32.000Z","path":"2017/03/29/Linux相关/","text":"Linux 相关总结 系统管理系统资源进程资源目录：/proc/进程ID/可查看某个进程的相关信息， 其中limits文件中包含该进程相关信息，示例如下：12345678Limit Soft Limit ... Max cpu time unlimited Max file size unlimited Max data size unlimited Max stack size 10485760 Max core file size unlimited Max processes unlimited Max open files 8192 工具sed12# 从建表ddl中筛选所有表名，转大写grep -i \"create table\" create_table.sql|sed 's/.*\\.\\(.*\\)(/\\1/' |tr a-z A-Z awkcrontab11 23 * * 2,5 /home/user1/reorg.sh &gt;&gt; /home/user1/reorg.log 2&gt;&amp;1 jar用法: jar {ctxui}[vfm0Me] [jar-file] [manifest-file] [entry-point] [-C dir] files …选项包括： -c 创建新的归档文件 -t 列出归档目录 -x 解压缩已归档的指定（或所有）文件 -u 更新现有的归档文件 -v 在标准输出中生成详细输出 -f 指定归档文件名 -m 包含指定清单文件中的清单信息 -e 为捆绑到可执行 jar 文件的独立应用程序 指定应用程序入口点 -0 仅存储；不使用任何 ZIP 压缩 -M 不创建条目的清单文件 -i 为指定的 jar 文件生成索引信息 -C 更改为指定的目录并包含其中的文件如果有任何目录文件，则对其进行递归处理。清单文件名、归档文件名和入口点名的指定顺序与 “m”、”f” 和 “e” 标志的指定顺序相同。 12345678# 将两个类文件归档到一个名为 classes.jar 的归档文件中jar cvf classes.jar Foo.class Bar.class# 使用现有的清单文件 \"mymanifest\" 并将 foo/ 目录中的所有文件归档到 \"classes.jar\" 中jar cvfm classes.jar mymanifest -C foo/ .# 将wbe目录下所有文件 归档到 “classes.jar\"中jar cvf classes.jar -C web/ . 可以使用 vi直接编辑 jar包 * grep在Linux中要正确匹配tab（退格）符有两种方式 1：用 grep $’\\t’ 你的文件2：用 grep ‘按CTRL+V 键，再按TAB键’ 你的文件 性能监控 top第一行后面的三个值是系统在之前 1、5、15 的平均负载，也可以看出系统负载是上升、平稳、下降的趋势，当这个值超过 CPU 可执行单元的数目，则表示 CPU 的性能已经饱和成为瓶颈了。 第二行统计了系统的任务状态信息。running 很自然不必多说，包括正在 CPU 上运行的和将要被调度运行的；sleeping 通常是等待事件(比如 IO 操作)完成的任务，细分可以包括 interruptible 和 uninterruptible 的类型；stopped 是一些被暂停的任务，通常发送 SIGSTOP 或者对一个前台任务操作 Ctrl-Z 可以将其暂停；zombie 僵尸任务，虽然进程终止资源会被自动回收，但是含有退出任务的 task descriptor 需要父进程访问后才能释放，这种进程显示为 defunct 状态，无论是因为父进程提前退出还是未 wait 调用，出现这种进程都应该格外注意程序是否设计有误。 第三行 CPU 占用率根据类型有以下几种情况： (us) user：CPU 在低 nice 值(高优先级)用户态所占用的时间(nice&lt;=0)。正常情况下只要服务器不是很闲，那么大部分的 CPU 时间应该都在此执行这类程序(sy) system：CPU 处于内核态所占用的时间，操作系统通过系统调用(system call)从用户态陷入内核态，以执行特定的服务；通常情况下该值会比较小，但是当服务器执行的 IO 比较密集的时候，该值会比较大(ni) nice：CPU 在高 nice 值(低优先级)用户态以低优先级运行占用的时间(nice&gt;0)。默认新启动的进程 nice=0，是不会计入这里的，除非手动通过 renice 或者 setpriority() 的方式修改程序的nice值(id) idle：CPU 在空闲状态(执行 kernel idle handler )所占用的时间(wa) iowait：等待 IO 完成做占用的时间(hi) irq：系统处理硬件中断所消耗的时间(si) softirq：系统处理软中断所消耗的时间，记住软中断分为 softirqs、tasklets (其实是前者的特例)、work queues，不知道这里是统计的是哪些的时间，毕竟 work queues 的执行已经不是中断上下文了(st) steal：在虚拟机情况下才有意义，因为虚拟机下 CPU 也是共享物理 CPU 的，所以这段时间表明虚拟机等待 hypervisor 调度 CPU 的时间，也意味着这段时间 hypervisor 将 CPU 调度给别的 CPU 执行，这个时段的 CPU 资源被“stolen”了。这个值在我 KVM 的 VPS 机器上是不为 0 的，但也只有 0.1 这个数量级，是不是可以用来判断 VPS 超售的情况？ CPU 占用率高很多情况下意味着一些东西，这也给服务器 CPU 使用率过高情况下指明了相应地排查思路： 当 user 占用率过高的时候，通常是某些个别的进程占用了大量的 CPU，这时候很容易通过 top 找到该程序；此时如果怀疑程序异常，可以通过 perf 等思路找出热点调用函数来进一步排查；当 system 占用率过高的时候，如果 IO 操作(包括终端 IO)比较多，可能会造成这部分的 CPU 占用率高，比如在 file server、database server 等类型的服务器上，否则(比如&gt;20%)很可能有些部分的内核、驱动模块有问题；当 nice 占用率过高的时候，通常是有意行为，当进程的发起者知道某些进程占用较高的 CPU，会设置其 nice 值确保不会淹没其他进程对 CPU 的使用请求；当 iowait 占用率过高的时候，通常意味着某些程序的 IO 操作效率很低，或者 IO 对应设备的性能很低以至于读写操作需要很长的时间来完成；当 irq/softirq 占用率过高的时候，很可能某些外设出现问题，导致产生大量的irq请求，这时候通过检查 /proc/interrupts 文件来深究问题所在；当 steal 占用率过高的时候，黑心厂商虚拟机超售了吧！ 第四行和第五行是物理内存和虚拟内存(交换分区)的信息： total = free + used + buff/cache，现在buffers和cached Mem信息总和到一起了，但是buffers和cached Mem 的关系很多地方都没说清楚。其实通过对比数据，这两个值就是 /proc/meminfo 中的 Buffers 和 Cached 字段：Buffers 是针对 raw disk 的块缓存，主要是以 raw block 的方式缓存文件系统的元数据(比如超级块信息等)，这个值一般比较小(20M左右)；而 Cached 是针对于某些具体的文件进行读缓存，以增加文件的访问效率而使用的，可以说是用于文件系统中文件缓存使用。 而 avail Mem 是一个新的参数值，用于指示在不进行交换的情况下，可以给新开启的程序多少内存空间，大致和 free + buff/cached 相当，而这也印证了上面的说法，free + buffers + cached Mem才是真正可用的物理内存。并且，使用交换分区不见得是坏事情，所以交换分区使用率不是什么严重的参数，但是频繁的 swap in/out 就不是好事情了，这种情况需要注意，通常表示物理内存紧缺的情况。 最后是每个程序的资源占用列表，其中 CPU 的使用率是所有 CPU core 占用率的总和。通常执行 top 的时候，本身该程序会大量的读取 /proc 操作，所以基本该 top 程序本身也会是名列前茅的。 top 虽然非常强大，但是通常用于控制台实时监测系统信息，不适合长时间(几天、几个月)监测系统的负载信息，同时对于短命的进程也会遗漏无法给出统计信息 vmstatr 表示可运行进程数目，数据大致相符；而b表示的是 uninterruptible 睡眠的进程数目；swpd 表示使用到的虚拟内存数量，跟 top-Swap-used 的数值是一个含义，而如手册所说，通常情况下 buffers 数目要比 cached Mem 小的多，buffers 一般20M这么个数量级；io 域的 bi、bo 表明每秒钟向磁盘接收和发送的块数目(blocks/s)；system 域的 in 表明每秒钟的系统中断数(包括时钟中断)，cs表明因为进程切换导致上下文切换的数目。 说到这里，想到以前很多人纠结编译 linux kernel 的时候 -j 参数究竟是 CPU Core 还是 CPU Core+1？通过上面修改 -j 参数值编译 boost 和 linux kernel 的同时开启 vmstat 监控，发现两种情况下 context switch 基本没有变化，且也只有显著增加 -j 值后 context switch 才会有显著的增加，看来不必过于纠结这个参数了，虽然具体编译时间长度我还没有测试。资料说如果不是在系统启动或者 benchmark 的状态，参数 context switch&gt;100000 程序肯定有问题 pidstat如果想对某个进程进行全面具体的追踪，没有什么比 pidstat 更合适的了——栈空间、缺页情况、主被动切换等信息尽收眼底。这个命令最有用的参数是-t，可以将进程中各个线程的详细信息罗列出来。 -r： 显示缺页错误和内存使用状况，缺页错误是程序需要访问映射在虚拟内存空间中但是还尚未被加载到物理内存中的一个分页，缺页错误两个主要类型是 minflt/s 指的 minor faults，当需要访问的物理页面因为某些原因(比如共享页面、缓存机制等)已经存在于物理内存中了，只是在当前进程的页表中没有引用，MMU 只需要设置对应的 entry 就可以了，这个代价是相当小的majflt/s 指的 major faults，MMU 需要在当前可用物理内存中申请一块空闲的物理页面(如果没有可用的空闲页面，则需要将别的物理页面切换到交换空间去以释放得到空闲物理页面)，然后从外部加载数据到该物理页面中，并设置好对应的 entry，这个代价是相当高的，和前者有几个数据级的差异 -s：栈使用状况，包括 StkSize 为线程保留的栈空间，以及 StkRef 实际使用的栈空间。使用ulimit -s发现CentOS 6.x上面默认栈空间是10240K，而 CentOS 7.x、Ubuntu系列默认栈空间大小为8196K -u：CPU使用率情况，参数同前面类似 -w：线程上下文切换的数目，还细分为cswch/s因为等待资源等因素导致的主动切换，以及nvcswch/s线程CPU时间导致的被动切换的统计 如果每次都先ps得到程序的pid后再操作pidstat会显得很麻烦，所以这个杀手锏的-C可以指定某个字符串，然后Command中如果包含这个字符串，那么该程序的信息就会被打印统计出来，-l可以显示完整的程序名和参数 ➜ ~ pidstat -w -t -C “ailaw” -l 其他➜ ~ mpstat -P ALL 1➜ ~ ps axjf IOiotop 可以直观的显示各个进程、线程的磁盘读取实时速率；lsof 不仅可以显示普通文件的打开信息(使用者)，还可以操作 /dev/sda1 这类设备文件的打开信息，那么比如当分区无法 umount 的时候，就可以通过 lsof 找出磁盘该分区的使用状态了，而且添加 +fg 参数还可以额外显示文件打开 flag 标记 iostat➜ ~ iostat -xz 1 其实无论使用 iostat -xz 1 还是使用 sar -d 1，对于磁盘重要的参数是： avgqu-s：发送给设备 I/O 请求的等待队列平均长度，对于单个磁盘如果值&gt;1表明设备饱和，对于多个磁盘阵列的逻辑磁盘情况除外 await(r_await、w_await)：平均每次设备 I/O 请求操作的等待时间(ms)，包含请求排列在队列中和被服务的时间之和； svctm：发送给设备 I/O 请求的平均服务时间(ms)，如果 svctm 与 await 很接近，表示几乎没有 I/O 等待，磁盘性能很好，否则磁盘队列等待时间较长，磁盘响应较差； %util：设备的使用率，表明每秒中用于 I/O 工作时间的占比，单个磁盘当 %util&gt;60% 的时候性能就会下降(体现在 await 也会增加)，当接近100%时候就设备饱和了，但对于有多个磁盘阵列的逻辑磁盘情况除外； 还有，虽然监测到的磁盘性能比较差，但是不一定会对应用程序的响应造成影响，内核通常使用 I/O asynchronously 技术，使用读写缓存技术来改善性能，不过这又跟上面的物理内存的限制相制约了。 上面的这些参数，对网络文件系统也是受用的。 netstat➜ ~ netstat -s 显示自从系统启动以来，各个协议的总体数据信息。虽然参数信息比较丰富有用，但是累计值，除非两次运行做差才能得出当前系统的网络状态信息，亦或者使用 watch 眼睛直观其数值变化趋势。所以netstat通常用来检测端口和连接信息的： netstat –all(a) –numeric(n) –tcp(t) –udp(u) –timers(o) –listening(l) –program(p) –timers可以取消域名反向查询，加快显示速度；比较常用的有 ➜ ~ netstat -antp #列出所有TCP的连接➜ ~ netstat -nltp #列出本地所有TCP侦听套接字，不要加-a参数 sarsar 这个工具太强大了，什么 CPU、磁盘、页面交换啥都管，这里使用 -n 主要用来分析网络活动，虽然网络中它还给细分了 NFS、IP、ICMP、SOCK 等各种层次各种协议的数据信息，我们只关心 TCP 和 UDP。下面的命令除了显示常规情况下段、数据报的收发情况，还包括 TCP ➜ ~ sudo sar -n TCP,ETCP 1 active/s：本地发起的 TCP 连接，比如通过 connect()，TCP 的状态从CLOSED -&gt; SYN-SENT passive/s：由远程发起的 TCP 连接，比如通过 accept()，TCP 的状态从LISTEN -&gt; SYN-RCVD retrans/s(tcpRetransSegs)：每秒钟 TCP 重传数目，通常在网络质量差，或者服务器过载后丢包的情况下，根据 TCP 的确认重传机制会发生重传操作 isegerr/s(tcpInErrs)：每秒钟接收到出错的数据包(比如 checksum 失败) UDP ➜ ~ sudo sar -n UDP 1 noport/s(udpNoPorts)：每秒钟接收到的但是却没有应用程序在指定目的端口的数据报个数 idgmerr/s(udpInErrors)：除了上面原因之外的本机接收到但却无法派发的数据报个数 当然，这些数据一定程度上可以说明网络可靠性，但也只有同具体的业务需求场景结合起来才具有意义。 tcpdump这么看来，如果查看单个尤其是多线程的任务时候，pidstat比常用的ps更好使","categories":[{"name":"技术","slug":"技术","permalink":"http://www.sillystone.info/categories/技术/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://www.sillystone.info/tags/Linux/"}]},{"title":"批量设计","date":"2017-03-28T02:04:14.000Z","path":"2017/03/28/批量设计/","text":"概述批量作业相对于联机交易而言，主要用于实现数据加工（计算，统计） 一般批量作业的特点 大量数据筛选，加工。消耗数据库资源：CPU/IO 利用数据库存储过程，数据处理在数据库上执行数据加工过程使用临时表大量数据处理，使用游标分批加工，减少日志空间的消耗，和错误引起执行效率底下问题数据导入导出使用数据库工具（DB2：load/import） 数据库上执行，存在单点问题 加工过程不易输出异常信息 特定需求： 7*24小时服务，系统不停机 （数据库资源不能消耗太高）全球服务：业务数据隔离， 批处理调度作业按时区划分并行处理设计（基于应用服务器） 解决思路 批量需求新技术和新技术方案越来越多，可以满足各类业务需求，对于批量需求首要考虑其必要性应当尽量减少批量作业数量，联机方案替代批量作业 应用服务器并行作业处理","categories":[{"name":"技术","slug":"技术","permalink":"http://www.sillystone.info/categories/技术/"}],"tags":[{"name":"批量","slug":"批量","permalink":"http://www.sillystone.info/tags/批量/"}]},{"title":"新职业-视频剪辑师","date":"2017-03-25T04:31:20.000Z","path":"2017/03/25/新职业-视频剪辑师/","text":"最近负责制作一段demo演示视频，用来给业务展示新建系统的UI界面和功能。视频剪辑是个体力活—-脖子疼 录屏软件google后，试用了几个 camstudio 历史悠久，广泛使用，大约13M window系统需要安装 对应版本的 visual c++ redistributable package（5M）功能简单 shareX 开源软件 大约5M 录屏需要安装ffmpeg（32位或者64位）功能简单，界面友好 screenpresso 大约13M 录屏也需要ffmpeg 可能需安装.net framework work 对应版本 ActivePresenter 35M 可录屏，可编辑制作视频 最终录屏使用的 shareX（ffmpeg) 安装文件小开源软件使用简单UI很好 视频编辑制作列表如下： 国内软件：会声会影 名气很大，安装文件太大 没有安装 国内软件：爱剪辑 283M avidemux： 20M 没有找到视频剪辑功能 ActivePresenter： 最终使用 ActivePresenter： 可以剪切视频 放大/缩小 添加备注 增加：图片，PPT等 制作的demo","categories":[{"name":"随笔","slug":"随笔","permalink":"http://www.sillystone.info/categories/随笔/"}],"tags":[{"name":"日记","slug":"日记","permalink":"http://www.sillystone.info/tags/日记/"}]},{"title":"贷前调查","date":"2017-03-23T14:45:42.000Z","path":"2017/03/23/贷前调查/","text":"来源：微信公众号 信贷共学 一、行业1、什么行业？2、行业所处阶段？（新兴、成熟、衰退）3、行业是否受以经济周期影响？4、行业的整体盈利情况？与企业盈利状况比较。5、企业规模及市场占有率状况，是否为龙头企业？6、行业产能是否过剩？7、行业经营资质是否需有关部门审批？是否受法律政策限制或影响？ 二、股东和经营者8、企业性质是什么？（民营、国有、股份、合资、独资、合伙、个体）9、股权结构是什么？谁控股？企业实际控制人是谁？10、股东以什么方式投资？是否到位？是否抽逃？11、是否有经营团队？经营团队是否有足够的经验？12、企业的组织构架是什么？管理是否有深度和广度？管理是否规范？企业的激励机制和用人机制是什么？企业文化是什么？13、是否有董事会？是否有独立董事？董事会是否在行使职权？董事会对管理层是否有足够的制约？14、企业的历史沿革，近三年经营班子的目标是什么？是否完成？（年终总结）15、企业的母公司、子公司、兄弟公司及其他关联企业有多少？股东的关联企业有多少？关联企业在社会的信誉如何？在我行和他行的融资情况如何？16、企业的关联企业与企业采购合同和购销合同的价格、数量、结算是否真实？是否符合市场行情？ 三、生产经营17、生产什么产品或提供什么服务？18、产品或服务的特点是什么？竞争力是什么？（差异优势、技术优势、成本优势、关系优势）19、是否有替代品将影响企业经营？20、产品的市场供求状况分析，是供大于求，还是供不应求？21、客户对企业产品的依赖度如何？（单一产品）22、原材料价格波动趋势和供给情况如何，对公司产品销售的影响是什么？23、原材料质量、保存有什么特殊要求？24、生产是否符合环保要求？（环保批文）25、生产技术是否落后？是否具有自主知识产权？与同行业比较？26、产品的销售渠道是什么？27、是否有销售团队？销售手段是什么？28、产品的销售政策是什么？是否赊销？是否有现金折扣？ 四、财务29、企业近三年的销售收入是多少？是增长、下降还是波动？原因是什么？30、企业近三年的利润总额和销售利润率是多少？是增长、下降还是波动？原因是什么？31、企业近三年的资产、负债、所有者权益是多少？资产负负债率是否符合行业特征？32、企业近三年的经营性现金净流量是多少？现金净流量与利润总额之间的差额是多少？现金净流量小于利润总额的原因是什么？33、企业流动资产和流动负债是多少？流动负债与流动资产的差额是多少？流动负债过高是否有短贷长用的现象？34、货币资金中保证金存款和已冻结的定期存单存款有多少？货币资金与抽查的现金日记账、银行日记账、银行对账单是否相符？35、应收账款明细是什么？一年以上账龄的应收账款有多少？应收账款坏账有多少？是否按财务制度规定计提准备？36、应收账款客户是否集中、单一？单一客户是否可能违约或取消合作？37、应收账款周转速度是否符合同业标准？38、应收账款增长额是多少？应收账款增长额与销售收入增长额之间的关系？与利润总额之间的关系？39、存货明细是什么？存货结构是什么？40、一年以上产成品、半成品有多少？41、原材料的采购成本与市场价格之间的差额是多少？是否计提存货跌价损失？42、存货周转速度是否符合同业标准？43、存货增长额是多少？存货增长额与销售收入增长额之间的关系？与固定资产增长额之间的关系？与利润总额之间的关系？44、存货的结转方法是什么？对当期成本和利润的影响是什么？45、存货存放在场内还是场外？存货是否已在他行或第三人质押？46、预付账款明细？采购价格与市场价格比较？是否符合采购合同约定？47、其他应收款明细是什么？在同业中占比是否过高？有无与实收资本金额相近的大额其他应收账款？有无注册资本抽逃现象？有无大额资产转移现象？48、固定资产明细是什么？产权是否明晰？49、固定资产入账依据是什么？固定资产账面价值与实际购买价值是否相符？固定资产评估入账的依据是否充分？评估价值是否过高？50、固定资产是否已在他行或第三人抵押？51、固定资产折旧方法是否符合财务制度规定？对当期的利润影响是什么？52、设备是否为专业设备？是否已被淘汰？变现能力如何？53、在建工程的总投资多少？已投资多少？竣工验收还需投资多少？在建工程投入使用对未来销售收入、利润、融资需求的影响？在建工程是否已抵押？54、土地性质是什么？是否已缴纳全额土地出让金？是否先征后返？地方是否有禁止转让或补交土地出让金后转让的要求？土地是否已抵押？55、固定资产是否已出租？出租合同的期限和付款方式是什么？出租价格是否合理？承租人是否同意租赁人违约时解除租赁合同或将租金缴纳给银行？56、短期借款、长期借款、应付票据明细？各银行授信金额多少？授信余额多少？到期日？利率水平？是否逾期？五级分类？担保方式？是否有短贷长用现象？57、应付账款明细？应付账款期限是多少？一年以上应付账款有多少？是否已违约？是否有纠纷？58、应付账款增长额是多少？是否高于往年增长额？是否高于平时增长额？是否有调整经营性现金净流量的嫌疑？59、预收账款明细？预收账款金额与合同约定生产进度是否相符？是否已开出预收账款保函？60、企业营业税缴纳多少？企业进项增值税多少？销项增值税多少？是否与税单相符？与报表销售收入是否匹配？61、企业是否享受各种税费减免政策？是否享受各种补贴？62、企业实收资本多少？注资方式是什么？是否抽逃？63、企业资本公积计账是否合理？固定资产评估增值是否符合市场价格？64、企业经营性现金流入量占销售收入比是多少？65、销售成本占比是否异常？是否存在少结转成本增加利润现象？66、投资收益率是否符合同业水平？投资收益中获得现金的比率是否正常？长期投资是否存在不良资产？ 五、用途、期限和还款来源67、企业的贷款用途是什么？68、是否有订单？69、项目贷款是否符合手续？如立项、可研、环评？70、自有资金有多少？占资金需求比例是多少？是否已到位？71、贷款的还款来源是什么？测算还款来源是否扣除铺底流动资金？72、何时还款？流动资金贷款测算企业的经营周期，项目贷款测算企业的每年净现金流量。 六、风险控制手段73、如何控制企业信贷资金流出和销售资金回笼？74、如何监管企业生产或项目进度？75、担保方式是什么？76、抵押物评估价值是否偏高？抵押物是否有瑕疵？77、保证人还款能力如何？78、仓单如何监管？79、是否同意签订个人无限责任担保和远期拍卖协议？ 七、收益测算80、授信产品如何设计？81、是否在我行开立基本账户？82、贷款利率是否符合企业信用等级标准？83、是否有中间业务收入？84、企业是否在我行代发工资？85、法定代表人是否办理贵宾卡？86、员工是否办理信用卡？87、关联企业是否办理网银？88、关联企业和上下游企业是否在我行开户？下游企业是否办理保理？上游企业可否办理保兑仓业务？89、授信余额是否超我行集中度要求？90、信用等级是否在AA级以上？91、抵押率是否在50%以下？92、授信业务种类和行业收取的资本占用费率是否最低？ 八、企业的社会信誉93、是否到工商局查询企业年检状况、公司章程和股东变更记录？94、是否到房交所查询企业固定资产是否已抵押或查封？95、是否到房交所查询企业法定代表人个人财产状况？96、是否到其他融资银行了解企业的信誉状况？97、是否到同业或行业协会了解企业在同业间的口碑？ 九、法律要件98、是否有董事会决议？99、借款合同、担保合同是否当面签章？100、个人无限责任夫妻双方是否当面签字？","categories":[{"name":"金融","slug":"金融","permalink":"http://www.sillystone.info/categories/金融/"}],"tags":[{"name":"银行","slug":"银行","permalink":"http://www.sillystone.info/tags/银行/"},{"name":"信贷","slug":"信贷","permalink":"http://www.sillystone.info/tags/信贷/"}]},{"title":"第一次","date":"2017-03-21T14:00:17.000Z","path":"2017/03/21/第一次/","text":"看了一眼央视的 《朗读者》喜欢读书，思想的沉淀，喜欢这期节目开头的 《第一次》 当你呱呱落地的那一瞬间, 你开始了在这个人世间第一次的神奇之旅， 第一次拉开了你人生的帷幕， 随后， 你开始经历各种各样形形色色的第一次： 第一次哭，第一次笑，第一次走路，第一次成功，第一次失败， 它是生命的体验， 它是成长的过程， 因为不会再重来， 所以难忘， 所以让人珍惜 第一次往往需要勇气， 但是第一次也往往会有意想不到的收获， 因为它是探索， 是挑战， 是机遇。 如果人生拥有越多的第一次， 也意味着人生越丰富 生活是个过程","categories":[{"name":"随笔","slug":"随笔","permalink":"http://www.sillystone.info/categories/随笔/"}],"tags":[{"name":"日记","slug":"日记","permalink":"http://www.sillystone.info/tags/日记/"}]},{"title":"架构决策","date":"2017-03-21T13:59:52.000Z","path":"2017/03/21/架构决策/","text":"架构决策 面向未来，明确目标架构 分析现状，确定实施线路 解决问题，解决必要需求，放弃次要功能 避免频繁修订，妥协，偏离目标。","categories":[{"name":"技术","slug":"技术","permalink":"http://www.sillystone.info/categories/技术/"}],"tags":[]},{"title":"web服务器 调试","date":"2017-03-21T13:59:36.000Z","path":"2017/03/21/jetty-调试/","text":"项目实践过的各种服务器调试总结，包括：IBM WAS， jetty 场景 远程实时调试web server：一般用于分析某个事件出发的系统处理异常，需单步跟踪 分析java web server运行状态：包括内存溢出，cpu 100% 实践远程实时调试服务器IBM websphere 服务器设置： 开启服务器调试端口重启web server 本地设置 Run-&gt;Debug configuration新建 Remote jetty 本地设置（基于IntelliJ IDEA）： Run-&gt;Debug configuration新建 Remote配置服务器 HOST 和 PORT ; 端口可设置1000以上非常用端口复制服务器命令行参数： Command line arguments for running remote JVM 1agentlib:jdwp=transport=dt_socket,server=y,suspend=n,address=5005 服务器设置： jetty启动时增加 命令参数（上文复制的内容）示例如下： 1java -agentlib:jdwp=transport=dt_socket,server=y,suspend=n,address=5005 -jar &#123;jetty path&#125; &#123;jetty port&#125; --path &#123;your war&#125; 1&gt;/dev/null 2&gt;&amp;1 &amp; 设置本地代码断点，启动remote server 触发服务器事件，在IDE中跟踪断点 分析java web server运行状态java自带工具jpsjps主要用来输出JVM中运行的进程状态信息 jstack用来查看某个Java进程内的线程堆栈信息1234567jstack [option] pidjstack [option] executable corejstack [option] [server-id@]remote-hostname-or-ip# option-l long listings，会打印出额外的锁信息，在发生死锁时可以用jstack -l pid来观察锁持有情况-m mixed mode，不仅会输出Java堆栈信息，还会输出C/C++堆栈信息（比如Native方法） 使用示例123456789# 获取进程PIDps -ef | grep JavaServiceName # 查看线程 ps -Lfp pid or ps -mp pid -o THREAD,tid,time# time列 是线程运行时间， 获取线程idtop -Hp pid# 线程id转为 16进制echo &quot;obase=16;ibase=10;23187&quot; |bc # 使用jstack&#123;java home&#125;jstack pid | grep 43A1 #16进制结果 jmap jhatjmap用于查看堆内存，结合jhat使用123456789# 查看堆&#123;java home&#125;/jmap -heap pid# 使用jmap -histo[:live] pid查看堆内存中的对象数目、大小统计直方图 jmap -histo:live pid | more# 输出到dump文件&#123;java home&#125;/jmap -dump:format=b,file=/tmp/dump.dat 5961# dump 信息使用jhat查看&#123;java home&#125;/jhat -J-Xmx512m /tmp/dump.data visualVm可用于远程分析 jstat123jstat [ generalOption | outputOptions vmid [interval[s|ms] [count]] ]# GC信息，采样时间间隔为250ms，采样数为4jstat -gc 21711 250 4 hprof展现CPU使用率，统计堆内存123456789101112java -agentlib:hprof[=options] ToBeProfiledClassjava -Xrunprof[:options] ToBeProfiledClassjavac -J-agentlib:hprof[=options] ToBeProfiledClass# 每隔20毫秒采样CPU消耗信息，堆栈深度为3，生成的profile文件名称是java.hprof.txtjava -agentlib:hprof=cpu=samples,interval=20,depth=3 Hellojavac -J-agentlib:hprof=cpu=times Hello.javajavac -J-agentlib:hprof=heap=sites Hello.javajavac -J-agentlib:hprof=heap=dump Hello.java IBM websphere 生成分析日志 was运行异常默认在profile目录生成javacore snapshot heapdump 信息linux下 使用 kill命令 触发was server 生成javacore 1kill -3 PID 使用工具分析日志IBM官网提供了工具jcaNNN.jar (备注: NNN版本号) 1&lt;Java Runtime Environment path&gt;java -Xmx500m -jar jca457.jar 需要根据heapdump大小 调整Xmx参数值，实操过程中2G heapdump，可能需要&gt;4G内存。远程服务器可以通过xshell工具（支持远程UI，需远程服务器支持图形相关库）调试。 jetty 9 服务器设置jetty官网说明 启用JMX 命令示例如下，执行后 会在jetty.base目录的start.ini中添加 jmx相关参数。启动服务 $ java -jar {$jetty.home}/start.jar 1java -jar /usr/local/jett9/bin/start.jar --add-to-start=jmx-remote jmx相关参数：123456--module=jmxjetty.jmxrmihost=localhostjetty.jmxrmiport=1099-Dcom.sun.management.jmxremote-Dcom.sun.management.jmxremote.ssl=false-Dcom.sun.management.jmxremote.authenticate=false jmx配置： {jetty home}/etc/jetty-jmx.xml 工具使用使用jconsoleoracle说明1jconsole -J-DsocksProxyHost=localhost -J-DsocksProxyPort=1099 RemoteServer:1099 visualVm 执行 visualVm新建remote ，配置远程服务器的地址 后注问题一：was dump问题 heap空间不足 导致dump，可以用IBM工具分析 系统资源不足报错信息：java.lang.OutOfMemoryError: Failed to create a thread: retVal -1073741830, errno 11系统资源不足，无法创建线程。 javacore：122CIUSERLIMIT RLIMIT_NOFILE 1024 655362CIUSERLIMIT RLIMIT_NPROC 1024 20480 解决：修改 /etc/security/limits.d/90-nproc.conf1* soft nproc 10240 需要重新启动server nodeagent 可以参考查看Linux进程资源来确定进程的limits参数是否修改成功 3.","categories":[{"name":"技术","slug":"技术","permalink":"http://www.sillystone.info/categories/技术/"}],"tags":[{"name":"jetty","slug":"jetty","permalink":"http://www.sillystone.info/tags/jetty/"},{"name":"WAS","slug":"WAS","permalink":"http://www.sillystone.info/tags/WAS/"},{"name":"java","slug":"java","permalink":"http://www.sillystone.info/tags/java/"}]},{"title":"db2 实施总结","date":"2017-03-19T01:53:26.000Z","path":"2017/03/19/db2-实施总结/","text":"针对参与实施的两个项目的数据库部分，总结如下本文示例基于db2 10.5.0 物理设计表分区（Partition）表分区主要为了数据隔离，按分区操作效率高，按分区运维方便 建表分区按分区字段键值区间设置1234567891011121314CREATE TABLE \"SCMNAME\".\"T_TABNAME\" ( \"PART_COL\" VARCHAR(12 OCTETS) , \"TAB_COL\" VARCHAR(32 OCTETS) , \"TAB_COL2\" DECIMAL(24,6) , \"REMARKS\" VARCHAR(240 OCTETS)) IN \"TBS_DATA_8K\" PARTITION BY RANGE(PART_COL) ( STARTING '001' ENDING '002', STARTING '003' ENDING '200', STARTING '201' ENDING '400', ENDING MAXVALUE ) 每个分区可以指定表空间和索引空间，上述sql db2look导出后1234567 PARTITION BY RANGE(PART_COL) ( STARTING '001' ENDING '002' IN \"TBS_DATA_8K\", STARTING '003' ENDING '200' IN \"TBS_DATA_8K\", STARTING '201' ENDING '400' IN \"TBS_DATA_8K\", ENDING MAXVALUE IN \"TBS_DATA_8K\") 索引默认为分区索引1234```主键/唯一索引 是全局索引``` sql 运维清除某分区（比如：按日期分区）的数据12 日志日志模式db2 默认为循环日志，开发和测试环境一般设置为循环日志，不可前滚恢复 不需要运维归档日志，生产环境一般为此模式，模式选项包括：RETAIN， DISK 需指定日志路径 123456db2 update db cfg for USER_DB_NAME using LOGARCHMETH1 DISK:/db2arclog-- 修改后需要备份和重启数据库db2stop forcedb2startdb2 backup db USER_DB_NAME to /disk 日志路径缺省日志路径：/home/dbuser/dbinst/NODE0000/SQL00001/LOGSTREAM0000修改：1db2 update db cfg for USER_DB_NAME using NEWLOGPATH /db2actlog 日志大小db2 操作时，可以认为一个事物内的所有数据库记录都在日志中记录， 如果某操作（特别是批量操作）处理了大量数据，那么将使用大量的数据库日志存储。 日志总大小=单个日志大小 (主日志个数 + 辅日志个数)LOGFILSZ (LOGPRIMARY + LOGSECOND) 数据库启动时 LOGPRIMARY的空间已分配，如果磁盘空间不足，将导致数据库无法启动123db2 update db cfg for USER_DB_NAME using LOGFILSZ 4096;db2 update db cfg for USER_DB_NAME using LOGPRIMARY 20;db2 update db cfg for USER_DB_NAME using LOGSECOND 30; 缓冲区应用设计问题解决db2diag 查看数据库运行日志(1) A timestamp for the message.(2) The name of the instance generating the message.(3) For DB2 Extended Enterprise Edition systems with a db2nodes.cfg file, the node generating the message. (If the db2nodes.cfg file is not used, the value is “000”.)(4) Identification of the process was generating the message. In this example, the message came from the process identified as 44829. The name of this process is db2agent and it is connected to the database named SAMPLE. Note: If the application is operating in a DUOW environment, the ID shown is the DUOW correlation token.(5) Identification of the application for which the process is working. In this example, the process generating the message is working on behalf of an application with the ID *LOCAL.payroll.970317140834. To identify more about a particular application ID, either: Use the db2 list applications command to view a list of application IDs. From this list, you can determine information about the client experiencing the error, such as its node name and its TCP/IP address. Use the db2 get snapshot for application command to view a list of application IDs.(6) The DB2 component that is writing the message.(7) The name of the function that is providing the message. This function operates within the DB2 subcomponent that is writing the message. To find out more about the type of activity performed by a function, look at the fourth letter of its name. In this example, the letter “p” in the function “sqlplrq” indicates a data protection problem. (Logs could be damaged, for example.) The following list shows some of the letters used in the fourth position of the function name, and the type of activity they identify: b Buffer poolsc Communication between clients and serversd Data managemente Engine processeso Operating system calls (such as opening and closing files)p Data protection (such as locking and logging)r Relational database servicess Sortingx Indexing (8) Identification of the internal error that was reported.(9) The database on which the error occurred.(10) Diagnostic message indicating that an internal error occurred.(11) Hexadecimal representation of an internal return code (see “Interpreting Hexadecimal Codes”). db2 “?” sql0912运维管理备份/恢复123db2 connect to SAMPLEdb2 -x \"select 'REBIND PACKAGE ' || rtrim(pkgschema) || '.' || rtrim(pkgname) || ';' as command from syscat.packages\" &gt; rebind.sqldb2 -tvf rebind.sql","categories":[{"name":"技术","slug":"技术","permalink":"http://www.sillystone.info/categories/技术/"}],"tags":[{"name":"db2","slug":"db2","permalink":"http://www.sillystone.info/tags/db2/"},{"name":"数据库","slug":"数据库","permalink":"http://www.sillystone.info/tags/数据库/"}]},{"title":"mybatis 汇总","date":"2017-03-17T02:45:21.000Z","path":"2017/03/17/mybatis-汇总/","text":"CDATA的使用在XML文档中的所有文本都会被解析器解析，只有在CDATA部件之内的文本会被解析器忽略。术语 CDATA 指的是不应由 XML 解析器进行解析的文本数据（Unparsed Character Data）。 在 XML 元素中，”&lt;” 和 “&amp;” 是非法的。“&lt;” 会产生错误，因为解析器会把该字符解释为新元素的开始。“&amp;” 也会产生错误，因为解析器会把该字符解释为字符实体的开始 某些文本，比如 JavaScript 代码，包含大量 “&lt;” 或 “&amp;” 字符。为了避免错误，可以将脚本代码定义为 CDATA。 CDATA 部分中的所有内容都会被解析器忽略。CDATA 部分由 “&lt;![CDATA[“ 开始，由 “]]&gt;” 结束CDATA 部分不能包含字符串 “]]&gt;”。也不允许嵌套的 CDATA 部分。标记 CDATA 部分结尾的 “]]&gt;” 不能包含空格或折行。&lt;![CDATA[ ]]&gt; 标记避免Sql中与xml规范相冲突的字符对xml映射文件的合法性造成影响","categories":[{"name":"技术","slug":"技术","permalink":"http://www.sillystone.info/categories/技术/"}],"tags":[{"name":"mybatis","slug":"mybatis","permalink":"http://www.sillystone.info/tags/mybatis/"}]},{"title":"db2 权限管理","date":"2017-03-15T12:39:19.000Z","path":"2017/03/15/db2-权限管理/","text":"背景1.用户分类设置权限：查询用户，数据库管理用户，数据库maintain用户2.数据库使用restrictive模式创建 参考资料restrictive模式对数据库权限的影响参照IBM Securing the system catalog viewPUBLIC无任何权限，非restrictive模式会默认包含以下权限 CREATETAB BINDADD CONNECT IMPLICIT_SCHEMA EXECUTE with GRANT on all procedures in schema SQLJ EXECUTE with GRANT on all functions and procedures in schema SYSPROC BIND on all packages created in the NULLID schema EXECUTE on all packages created in the NULLID schema CREATEIN on schema SQLJ CREATEIN on schema NULLID USE on table space USERSPACE1 SELECT access to the SYSIBM catalog tables SELECT access to the SYSCAT catalog views SELECT access to the SYSIBMADM administrative views SELECT access to the SYSSTAT catalog views UPDATE access to the SYSSTAT catalog views dbadm用户数据库对象（表，试图，索引等常规对象）维护权限 12345678db2 connect to $DBNAMEdb2 drop role $ADMROLEdb2 create role $ADMROLEdb2 grant dbadm on database to role $ADMROLEdb2 grant role $ADMROLE to $TARGET_USER## another userdb2 grant role $ADMROLE to $ANOTHER_USER query用户 最小权限的查询用户， 无法看到系统视图（schema，数据库对象列表信息） 123456789101112131415161718db2 connect to $DBNAMEdb2 drop role $QRYROLEdb2 create role $QRYROLEdb2 grant connect on database to role $QRYROLEdb2 grant usage on workload sysdefaultuserworkload to role $QRYROLEdb2 grant execute on package NULLID.SQLC2K26 to role $QRYROLEdb2 grant execute on package NULLID.SYSSH200 to role $QRYROLEdb2 grant select on table SYSCAT.SCHEMATA to role $QRYROLEdb2 grant select on table SYSIBM.SYSDUMMY1 to role $QRYROLE# your tablefor TAB_NAME in `db2 -x \"select trim(TABSCHEMA)||'.'||TABNAME from SYSCAT.TABLES where TABSCHEMA = 'YOUR_SCHEMA'\"`do echo \"$TAB_NAME\" db2 \"grant select on table $TAB_NAME to role $QRYROLE\"donedb2 grant role $QRYROLE to user $TARGET_USER 查询用户，可以查看数据库系统视图（使用DbVisualizer工具）1234567891011121314db2 connect to $DBNAMEdb2 drop role $QRYROLEdb2 create role $QRYROLEdb2 grant dbadm without dataaccess on database to role $QRYROLEdb2 grant execute on package NULLID.SYSSH200 to role $QRYROLE# your tablefor TAB_NAME in `db2 -x \"select trim(TABSCHEMA)||'.'||TABNAME from SYSCAT.TABLES where TABSCHEMA = 'YOUR_SCHEMA'\"`do echo \"$TAB_NAME\" db2 \"grant select on table $TAB_NAME to role $QRYROLE\"donedb2 grant role $QRYROLE to user $TARGET_USER 问题和解决方法 查询用户的权限赋值过程 对于NULLID package的权限根据错误提示执行 DbVisualizer工具报错问题 : 设置Tools-&gt;DebugWindow log Destination查看错误输出 错误提示： SQLCODE=-551, SQLSTATE=42501, SQLERRMC=DB2USER;EXECUTE;SYSIBM.SQLTABLES （未能通过赋权解决） DB2工具： db2top watch功能 导出dynamic sqlDB2 Diaglog: db2 update dbm cfg using DIAGLEVEL 4; check $DIAGPATH/db2diag.log 原因： call SYSIBM.SQLTABLES() 无 execute权限grant execute on procedure SYSIBM.SQLTABLES to user TarGETUSER系统catelog package/procedure无法赋值给普通用户， 报错sqlcode: -607 sqlstate: 42832参考IBM 错误说明 网上的权限分配示例12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394#--创建角色 bsb_write_role：具有DML操作权限 bsb_read_role：只读权限db2 create role bsb_write_roledb2 create role bsb_read_role#-----------------------------------------------##--给角色 bsb_write_role 授权db2 grant usage on workload sysdefaultuserworkload to role bsb_write_roledb2 grant connect on database to role bsb_write_roledb2 grant bindadd on database to role bsb_write_roledb2 grant load on database to role bsb_write_roledb2 grant create_external_routine on database to role bsb_write_roledb2 grant createtab on database to role bsb_write_roledb2 grant use of tablespace userspace1 to role bsb_write_roledb2 grant implicit_schema on database to role bsb_write_role#db2 grant dataaccess on database to role bsb_write_role#问题：如何确定应用用户需要哪些package的执行权限？db2 grant execute on package nullid.sqlc2j25 to role bsb_write_roledb2 grant execute on package nullid.syssh200 to role bsb_write_roledb2 grant execute on package nullid.sqlubj05 to role bsb_write_roledb2 grant execute on package nullid.sqlukj0b to role bsb_write_roledb2 grant execute on package nullid.sqlupj00 to role bsb_write_roledb2 grant execute on package nullid.sqlucj05 to role bsb_write_roledb2 grant execute on package nullid.sqluaj20 to role bsb_write_roledb2 grant execute on package nullid.sqlufj14 to role bsb_write_roledb2 grant execute on package nullid.sqluoj01 to role bsb_write_roledb2 grant execute on function sysproc.base_table to role bsb_write_roledb2 grant select on table syscat.colidentattributes to role bsb_write_roledb2 grant select on table sysibmadm.dbcfg to role bsb_write_roledb2 grant select on table sysibm.systables to role bsb_write_roledb2 grant select on table sysibm.sysindexes to role bsb_write_roledb2 grant select on table sysibm.syscolumns to role bsb_write_roledb2 grant select on table sysibm.dual to role bsb_write_roledb2 grant select on table syscat.packages to role bsb_write_roledb2 grant select on table syscat.columns to role bsb_write_roledb2 grant select on table syscat.indexcoluse to role bsb_write_roledb2 grant select on table syscat.sequences to role bsb_write_roledb2 grant select on table syscat.functions to role bsb_write_roledb2 grant select on table syscat.tables to role bsb_write_roledb2 grant select on table syscat.tabauth to role bsb_write_roledb2 grant select on table syscat.tbspaceauth to role bsb_write_roledb2 grant select on table syscat.views to role bsb_write_roledb2 grant select on table syscat.schemaauth to role bsb_write_roledb2 grant select on table syscat.sequences to role bsb_write_roledb2 grant select on table syscat.sequenceauth to role bsb_write_roledb2 grant select on table syscat.roles to role bsb_write_roledb2 grant select on table syscat.roleauth to role bsb_write_roledb2 grant select on table syscat.procedures to role bsb_write_roledb2 grant select on table syscat.references to role bsb_write_roledb2 grant select on table syscat.packages to role bsb_write_roledb2 grant select on table syscat.packageauth to role bsb_write_role#-----------------------------------------------##--给角色 bsb_read_role 授权db2 grant connect on database to role bsb_read_roledb2 grant select on table syscat.tables to role bsb_read_roledb2 grant select on table syscat.tabauth to role bsb_read_roledb2 grant select on table syscat.tbspaceauth to role bsb_read_roledb2 grant select on table syscat.views to role bsb_read_roledb2 grant select on table syscat.schemaauth to role bsb_read_roledb2 grant select on table syscat.sequences to role bsb_read_roledb2 grant select on table syscat.sequenceauth to role bsb_read_roledb2 grant select on table syscat.roles to role bsb_read_roledb2 grant select on table syscat.roleauth to role bsb_read_roledb2 grant select on table syscat.procedures to role bsb_read_roledb2 grant select on table syscat.references to role bsb_read_roledb2 grant select on table syscat.packages to role bsb_read_roledb2 grant select on table syscat.packageauth to role bsb_read_roledb2 grant select on table sysibm.dual to role bsb_read_role#-----------------------------------------------##--创建模式# 1）没有隐式模式权限（IMPLICIT_SCHEMA）的用户必须显示创建模式 # 2）没有DBADM权限的应用用户bsbview可以创建与用户名同名的模式bsbviewbsbview@sles11:~&gt; db2 \"create schema bsbview\"DB20000I The SQL command completed successfully.#--授权模式bsbview的权限给角色bsb_write_roledb2 grant createin,alterin,dropin on schema bsbview to role bsb_write_role#--理解以下两个概念很重要！# 1）对象的创建者自动拥有了该对象的所有权限。# 2）用户拥有模式的DML权限后，在该模式上就拥有了创建对象的权限。# 3）对象包含：表，视图，索引，序列，触发器，存储过程，函数#--给应用用户授权角色bsb_write_roledb2 grant role bsb_write_role to user bsbview#-----------------------------------------------##回收创建表的权限后，使用表空间的权限也将默认回收：db2 revoke CREATETAB on DATABASE from bsbview #———————————————-# 设置应用要连接的实例的环境变量#———————————————-#1）DB2实例查看方法cd /opt/IBM/db2/V10.1/instance./db2ilistdb2inst1 #DB2的实例名其实是操作系统的一个用户名2）查看实例 db2inst1 家目录cat /etc/passwd|grep db2inst1db2inst1:x:1001:1000::/home/db2inst1:/bin/bash3）修改应用用户的 .profilebsbview@sles11:~&gt; cat &gt;&gt; ~/.profile &lt; if [ -f /home/db2inst2/sqllib/db2profile ]; then . /home/db2inst2/sqllib/db2profilefiEOF #———————————————-# END 设置应用要连接的实例的环境变量#———————————————-# #———————————————————————————-# 最小化权限管理实验#———————————————————————————-# #–建库语句，必须用 RESTRICTIVE 参数db2 “create database test2 on /db2data1,/db2data2,/db2data3 using codeset UTF-8 territory cn RESTRICTIVE” #–DB2数据库rest为restrict模式db2inst2@sles11:~&gt; db2 get db cfg |grep -i restrictRestrict access = YES 对于没有任何权限的OS用户bsbview，执行如下操作报错的解决方法： 1)没有connect权限bsbview@sles11:~&gt; db2 connect to restSQL1060N User “BSBVIEW “ does not have the CONNECT privilege. SQLSTATE=08004 解决方法：db2 grant connect on database to bsbview bsbview@sles11:~&gt; db2 connect to rest Database Connection Information Database server = DB2/LINUXX8664 10.1.3SQL authorization ID = BSBVIEWLocal database alias = REST 2)列出模式bsbview的表，没有workload权限bsbview@sles11:~&gt; db2 list tablesSQL5193N The current session user does not have usage privilege on anyenabled workloads. SQLSTATE=42524 解决方法：db2 grant usage on workload sysdefaultuserworkload to user bsbview 3)没有执行包NULLID.SQLC2J25权限bsbview@sles11:~&gt; db2 list tablesSQL0551N “BSBVIEW” does not have the required authorization or privilege toperform operation “EXECUTE” on object “NULLID.SQLC2J25”. SQLSTATE=42501 解决方法：db2 GRANT EXECUTE ON PACKAGE NULLID.SQLC2J25 TO bsbview 4)没有视图syscat.tables的查询权限bsbview@sles11:~&gt; db2 list tablesSQL0551N “BSBVIEW” does not have the required authorization or privilege toperform operation “SELECT” on object “SYSCAT.TABLES”. SQLSTATE=42501 解决方法：db2 grant select on table syscat.tables to user bsbview 通过以上4种权限：用户bsbview可以正常连接上rest，并可以列出模式bsbview下表：bsbview@sles11:~&gt; db2 list tables for schema bsbview Table/View Schema Type Creation time 0 record(s) selected. 5）没有create table权限bsbview@sles11:~&gt; db2 “create table t1(id int)”DB21034E The command was processed as an SQL statement because it was not avalid Command Line Processor command. During SQL processing it returned:SQL0552N “BSBVIEW” does not have the privilege to perform operation “CREATETABLE”. SQLSTATE=42502 解决方法：db2 grant CREATETAB ON DATABASE to bsbview 6）没有隐式的创建模式权限：IMPLICIT CREATE SCHEMAbsbview@sles11:~&gt; db2 “create table t1(id int)”DB21034E The command was processed as an SQL statement because it was not avalid Command Line Processor command. During SQL processing it returned:SQL0552N “BSBVIEW” does not have the privilege to perform operation “IMPLICITCREATE SCHEMA”. SQLSTATE=42502 解决方法：对于没有IMPLICIT_SCHEMA权限的用户，有两种解决办法：1）直接授予IMPLICIT_SCHEMA权限：db2 grant IMPLICIT_SCHEMA ON DATABASE to user bsbview2）使用DBADM的用户创建bsbview所需要的模式，然后授权db2 create schema s1db2 grant createin,alterin,dropin on schema s1 to user bsbview 7）没有表空间权限，若不指定表空间名字，默认使用表空间USERSPACE1bsbview@sles11:~&gt; db2 “create table s1.t1(id int) in userspace1”DB21034E The command was processed as an SQL statement because it was not avalid Command Line Processor command. During SQL processing it returned:SQL0551N “BSBVIEW” does not have the required authorization or privilege toperform operation “CREATE TABLE” on object “USERSPACE1”. SQLSTATE=42501 解决方法： db2 grant use of TABLESPACE USERSPACE1 to bsbview bsbview@sles11:~&gt; db2 “create table s1.t1(id int) in userspace1”DB20000I The SQL command completed successfully. 8）没有存储过程执行的权限bsbview@sles11:~&gt; db2 “call s1.sleep(10)”SQL0551N “BSBVIEW” does not have the required authorization or privilege toperform operation “EXECUTE” on object “NULLID.SYSSH200”. SQLSTATE=42501 解决方法： db2 grant execute on package NULLID.SYSSH200 to user bsbview bsbview@sles11:~&gt; db2 “call s1.sleep(2)” Return Status = 0 9）没有export权限bsbview@sles11:~&gt; db2 “export to s1.t1.ixf of ixf messages s1.t1.msg select * from s1.t1”SQL3020N The user does not have the authority to run the specified EXPORTcommand.bsbview@sles11:~&gt; lltotal 8drwxr-xr-x 2 bsbview users 4096 Feb 1 17:04 bin-rw-r–r– 1 bsbview users 719 Feb 4 12:24 s1.t1.msgbsbview@sles11:~&gt; cat s1.t1.msgSQL3015N An SQL error “-551” occurred during processing. SQL0551N “BSBVIEW” does not have the required authorization or privilege toperform operation “EXECUTE” on object “NULLID.SQLUBJ05”. SQLSTATE=42501 SQL3015N An SQL error “-551” occurred during processing. SQL0551N “BSBVIEW” does not have the required authorization or privilege toperform operation “EXECUTE” on object “NULLID.SQLUKJ0B”. SQLSTATE=42501 SQL3015N An SQL error “-551” occurred during processing. SQL0551N “BSBVIEW” does not have the required authorization or privilege toperform operation “EXECUTE” on object “NULLID.SQLUPJ00”. SQLSTATE=42501 SQL3020N The user does not have the authority to run the specified EXPORTcommand. 解决方法：db2 grant execute on package nullid.sqlubj05 to user BSBVIEWdb2 grant execute on package nullid.sqlukj0b to user BSBVIEWdb2 grant execute on package nullid.sqlupj00 to user BSBVIEWdb2 grant execute on package nullid.sqlucj05 to user BSBVIEWdb2 grant execute on package nullid.sqluaj20 to user BSBVIEWdb2 grant execute on function sysproc.base_table to user BSBVIEWdb2 grant select on table SYSCAT.COLIDENTATTRIBUTES to user BSBVIEWdb2 grant select on table SYSCAT.INDEXCOLUSE to user BSBVIEWdb2 grant select on table SYSCAT.SEQUENCES to user BSBVIEWdb2 grant select on table SYSIBM.SYSTABLES to user BSBVIEWdb2 grant select on table SYSIBM.SYSINDEXES to user BSBVIEWdb2 grant select on table syscat.functions to user BSBVIEWdb2 grant select on table sysibm.syscolumns to user BSBVIEW –授予上面的权限后，最终报错：bsbview@sles11:~&gt; cat s1.t1.msgSQL3104N The Export utility is beginning to export data to file “s1.t1.ixf”. SQL27981W The utility could not verify presence of attached or detached datapartitions in the target table or the source table. SQL0551N “” does not have the required authorization or privilege to performoperation “” on object “”. SQL3105N The Export utility has finished exporting “1” rows. 10）没有import权限bsbview@sles11:~&gt; db2 “import from s1.t1.ixf of ixf insert into s1.t1”SQL0551N “BSBVIEW” does not have the required authorization or privilege toperform operation “EXECUTE” on object “NULLID.SQLUFJ14”. SQLSTATE=42501 bsbview@sles11:~&gt; db2 “import from s1.t1.ixf of ixf insert into s1.t1”SQL0551N “BSBVIEW” does not have the required authorization or privilege toperform operation “SELECT” on object “SYSIBMADM.DBCFG”. SQLSTATE=42501 bsbview@sles11:~&gt; db2 “import from s1.t1.ixf of ixf insert into s1.t1”SQL3015N An SQL error “-551” occurred during processing. SQL0551N “BSBVIEW” does not have the required authorization or privilege toperform operation “EXECUTE” on object “NULLID.SQLUOJ01”. SQLSTATE=42501 bsbview@sles11:~&gt; db2 “import from s1.t1.ixf of ixf insert into s1.t1”SQL3015N An SQL error “-551” occurred during processing. SQL0551N “BSBVIEW” does not have the required authorization or privilege toperform operation “SELECT” on object “SYSCAT.PACKAGES”. SQLSTATE=42501 SQL3015N An SQL error “” occurred during processing. 解决方法：db2 grant execute on package nullid.SQLUFJ14 to user BSBVIEWdb2 grant select on table SYSIBMADM.DBCFG to user BSBVIEWdb2 grant execute on package NULLID.SQLUOJ01 to user BSBVIEWdb2 grant select on table SYSCAT.PACKAGES to user BSBVIEWdb2 grant select on table SYSCAT.COLUMNS to user BSBVIEW bsbview@sles11:~&gt; db2 “import from s1.t1.ixf of ixf insert into s1.t1”SQL27981W The utility could not verify presence of attached or detached datapartitions in the target table or the source table. SQL3150N The H record in the PC/IXF file has product “DB2 02.00”, date“20150204”, and time “124100”. SQL3153N The T record in the PC/IXF file has name “s1.t1.ixf”, qualifier “”,and source “ “. SQL3015N An SQL error “-551” occurred during processing. SQL0551N “BSBVIEW” does not have the required authorization or privilege toperform operation “SELECT” on object “SYSCAT.COLUMNS”. SQLSTATE=42501 SQL3110N The utility has completed processing. “0” rows were read from theinput file. #———————————————————————————-# END 最小化权限管理实验#———————————————————————————-#","categories":[{"name":"技术","slug":"技术","permalink":"http://www.sillystone.info/categories/技术/"}],"tags":[{"name":"db2","slug":"db2","permalink":"http://www.sillystone.info/tags/db2/"}]},{"title":"db2数据库物理设计要点","date":"2017-03-14T08:59:52.000Z","path":"2017/03/14/db2数据库设计要点/","text":"整体架构单分区SMP集群数据库Purescale多分区MPP：数据量大于2TB 数据库设计建库 库名：XXXXDB数据文件存储目录： 独立挂载，便于运维和扩展数据库主目录：独立挂载，空间需求：小于10g活动日志目录：独立挂载，容量设计（压测大小的1.5倍）归档日志目录：独立挂载，容量设计（至少3天日志量，循环日志不需要配置）代码页： UTF-8（1208）RESTRICTIVE：如果未声明 则默认 restrictive 为no，默认赋值PUBLIC权限（下列数据库特权被自动授予 PUBLIC：对系统目录视图的 CREATETAB、BINDADD、CONNECT、IMPLICIT_SCHEMA 和 SELECT）。但是，如果有 RESTRICTIVE 选项，那么不会自动对 PUBLIC 授予任何特权.在此情况下对于应用服务器访问用户建议授权admin权限，对于其他用户单独授权，授权示例见下文PAGESIZE：单位为k，此选项设置默认的buffer pool，影响table spaces (SYSCATSPACE, TEMPSPACE1, USERSPACE1)，同时也是默认的buffer pool，table spaces属性 12db2 create database &lt;dbname&gt; on ‘/db2fs1’,’/db2fs2’dbpath on‘/dbpath’using codeset UTF-8 territory CN pagesize 8192 restrictive 12345db2 \"grant dbadm on database to user APPUSERNAME\"db2 \"grant connect on database to user $TARGET_USER\"db2 \"grant usage on workload sysdefaultuserworkload to user $TARGET_USER\"db2 \"grant select,insert,update,delete on table $TAB_NAME to user $TARGET_USER\" 缓冲池 大小不应该超过数据库可用内存50%与表空间设计同时考虑缓冲池个数尽量少缺省缓冲 调整为固定大小 12create bufferpool &lt;bpname&gt; size &lt;n&gt; pagesize 8k;alter bufferpool ibmdefaultbp size 25600; 表空间设计日志设计索引设计设计专题容量设计示例语句12","categories":[{"name":"技术","slug":"技术","permalink":"http://www.sillystone.info/categories/技术/"}],"tags":[{"name":"db2","slug":"db2","permalink":"http://www.sillystone.info/tags/db2/"},{"name":"数据库","slug":"数据库","permalink":"http://www.sillystone.info/tags/数据库/"}]},{"title":"db2分区特性","date":"2017-03-13T08:09:56.000Z","path":"2017/03/13/db2分区特性/","text":"概述数据分区技术主要用于大容量数据的物理设计，主要特性包括：访问速度，数据隔离，数据扩展和数据运维几个方面。 架构上可以分为：共享内存， 共享存储， 无共享。 DPF 数据分区Data Partitioning feature， 采用share-nothing体系结构。数据库在非共享环境下分为独立的分区，每个分区有独立的硬件资源，数据，索引和日志，每个数据分区可以称为节点；每个节点有独立处理能力，节点间通过高速网路连接。 扩展性好，可增加节点。一库拆分为多库的思路。并行策略，节点之间，节点内分区并行，查询语句并行DPF还根据负载动态分流，同时支持异步I/O和平行I/O MDCIBM MDC 介绍MDC是在DB2 Version 8中引入的，通过它可以在物理上将在多维上具有类似值的行聚合在一起放在磁盘上。这种聚合能为常见分析性查询提供高效的I/O，提高检索数据的效率一个块的大小等于表空间的扩展数据块（extent）大小，扩展数据块是磁盘上的一组连续页，所以将这些具有类似值的行在物理上是存放在连续的数据页上在 MDC 表中，块映射（block map）会跟踪属于这个表的所有扩展数据块，并且指示哪些块或扩展数据块上包含数据以及哪些块或扩展数据块上没有包含数据。包含数据的块标记为“正在使用”(“IN USE”)。每当发生删除或转出时，相应的块条目不再标记为“正在使用”，而是被释放以供 MDC 表复用。但是表空间中的其他对象无法使用这些扩展数据块。可以通过重组 MDC 表来从 MDC 表释放这些可用数据扩展数据块 特点 由于与基于记录的索引相比，由于块索引的大小是很小的，所以探测和扫描块索引要快 块索引和相应的数据组织允许更精细的“数据库分区忽略”或者有选择性地进行表访问 利用块索引的查询因为减小了索引大小、优化了对块的预取并且可以保证相应数据的集群而受益 对于某些查询，可以减少锁定和谓词求值 块索引用于日志记录和维护方面的开销很少，因为仅当将第一条记录添加至块或从块中除去最后一条记录时才需要更新它们 转入的数据可以复用先前转出的数据留下的连续空间。 适用场景数据量大，经常按某一条件删除或者增加数据，经常使用相异值小的列（这样的列不适合常规索引）进行数据范围筛选 维度筛选 用于范围、等于或 IN 列表谓词用于转入、转出或其他大规模的行删除被 GROUP BY 或 ORDER by 子句引用外键列星型数据库的事实表中 join 子句中的列粗粒度，也就是说不同的值很少的列典型的设计是用一个表示日期的列作为一个 MDC 维，再加上 0 到 3 个其他列作为其他维，例如 region 和 product_type。绝对不能使用主键或唯一索引列做维度 索引设计MDC表支持创建常规索引，对于一个n维的MDC表自动会创建n+1个索引，即：每个维度一个索引，加上所有维度的组合索引 TP表分区TP是在DB2 9中引入的，与MDC类似，它也可以将具有近似值的行存储在一起。TP 不同于其他特性的优势在于为表添加或删除大量数据这个方面，即转入和转出。分区表的索引全部建成分区索引，要求尽量不要建立主键和唯一索引 分区表的索引默认是分区索引, 如下所示：12345678CREATE TABLE A (columns) PARTITION BY RANGE (column expression) (PARTITION PART0 STARTING FROM constant ENDING constant IN ts1 INDEX IN ts2, PARTITION PART1 STARTING FROM constant ENDING constant IN ts3 INDEX IN ts4, PARTITION PART2 STARTING FROM constant ENDING constant IN ts3,INDEX IN ts5) CREATE INDEX x1 ON A (...); CREATE INDEX x2 ON A (...); 分区表建立非分区索引，下例x1; 存储空间参见示例图21234567891011CREATE TABLE t1 (columns) in ts1 INDEX IN ts2 1 PARTITION BY RANGE (column expression) (PARTITION PART0 STARTING FROM constant ENDING constant IN ts3, 2 PARTITION PART1 STARTING FROM constant ENDING constant INDEX IN ts5, PARTITION PART2 STARTING FROM constant ENDING constant INDEX IN ts4, PARTITION PART3 STARTING FROM constant ENDING constant INDEX IN ts4, PARTITION PART4 STARTING FROM constant ENDING constant)CREATE INDEX x1 ON t1 (...) NOT PARTITIONED; CREATE INDEX x2 ON t1 (...) PARTITIONED;CREATE INDEX x3 ON t1 (...) PARTITIONED; 空间存储示例如下： 比较DDL 分区方式 Create table语句 DPF DISTRIBUTE BY HASH MDC ORGANIZE BY DIMENSION TP PARTITION BY RANGE 设计特性 分区方式 实现思路 优点 DPF 将行均匀地分布在多个数据库分区上 可伸缩性随着数据库的增长增加计算资源（也就是数据库分区） MDC 将在多维上具有近似值的行放在表中相同的物理位置，即所谓的块 查询性能 —— 组织数据的方式有利于获得更快的检索速度，对于由多个谓词指定范围的查询尤其有效 TP 将所有行放在同一个数据分区的一个指定范围的维中 数据移动 —— 通过添加和删除整个数据分区，可以增加和删除大量数据 事实表特征 分区方式 适合 事实 DPF 大型表 —— 大到无法仅依靠单独一组 CPU 和 I/O 通道来处理 事实表是最大的数据库表。它们常常包含数亿行数据，有时候甚至包含数千亿行数据 MDC 结果集返回在多个维上具有近似值的行的查询 事实表（以及通常所说的数据仓库）是为支持这种类型的查询而设计的 TP 这种类型的表：周期性地添加大量数据，然后在数据到期后又删除大量数据 在事实表中，常常是每天都添加新数据。通常每月或每个季度删除过时的数据 经验法则总结 分区方式 分区特性设计决定 经验法则 DPF 用作分布键的列 首选是具有很多不同值的列 MDC 用作 MDC 维的列 一种典型的设计是选择一个表示日期的列，再加上 0 到 3 个其他列 TP 用作表分区键的列和分区的数量 选择一个基于时间的列。定义与每次转出的数据量相符的分区 DB2 &amp; Oracle Oracle分区 DB2分区 Oracle 10g语法 DB2 V9语法 区间分区（Range Partitioning） 表分区（Table Partitioning） PARTITION BY RANGE PARTITION BY RANGE 哈希分区（Hash Partitioning） 数据库分区（Database Partitioning） PARTITION BY HASH DISTRIBUTE BY HASH 列表分区（List Partitioning） 带生成列表分区（Table Partitioning With Generated Column） PARTITION BY LIST PARTITION BY RANGE 不支持 多维集群（Multidimensional clustering） 无 ORGANIZE BY DIMENSION DB2的数据库分区特性采用Share-nothing架构，这种架构允许多个数据库分区在一起并行工作来处理工作负载。在Oracle中，使用Share-disk架构 代码示例1234567891011 CREATE TABLE partition_table (partition_date date NOT NULL, partition_data VARCHAR(20) NOT NULL ) IN tbsp_parts DISTRIBUTE BY HASH (partition_date); 参考IBM DB2关键特性解析：DB2分区特性IBM官网： 表分区和多维集群表","categories":[{"name":"技术","slug":"技术","permalink":"http://www.sillystone.info/categories/技术/"}],"tags":[{"name":"db2","slug":"db2","permalink":"http://www.sillystone.info/tags/db2/"},{"name":"数据库","slug":"数据库","permalink":"http://www.sillystone.info/tags/数据库/"}]},{"title":"思维","date":"2017-03-12T14:13:34.000Z","path":"2017/03/12/思维/","text":"回归理性Learn the rules like a pro, so you can break them like an artist 已知观点 专注 时间观 写下你的想法 分享也是学习， 乐于奉献 把握重点 不打”价格战“ 内部”压力测试“ 投资自己， 包括”眼界“ 先调整”状态“ 再做”事“ 最不在乎输赢的，往往是赢家 创造属于自己的细分领域 有待理解不要高估失败 （重视结果）从失败中，你可能学不到任何东西；失败除了是悲剧，什么也不是Pivot 意味着已经走错了 反对谈趋势趋势意味着竞争， 不如 使命感 少一些竞争力我在学校里成绩非常好，个人竞争力极强。但回头看，我不希望自己眼中只有竞争，也不想把精力全部放在竞争对手身上；那样我会错过其他很多东西，忽略了创造更有价值的事情。我希望自己少一些竞争力，从而变得更加成功 向对立面学习除了学习硅谷的同行，我会花很多时间学习价值投资者，比如沃伦·巴菲特、塞思·卡拉曼等。我们与价值投资是两种截然相反的投资类型：我们是押注“变化”，价值投资是押注“不变”。如果他们犯错，则意味着某些变化他们没有意识到；如果我们犯错，则意味着我们预测的变化还没有出现。但两者的共同之处在于：我们都倡导原创性思考，去挖掘别人看不到、甚至持相反观点的机会 不对称的风险与回报“风险越大，回报越高”几乎是所有投资者的共识。但最伟大的投资人都在挖空心思以最小的风险（甚至无风险），获得最高的回报。","categories":[{"name":"随笔","slug":"随笔","permalink":"http://www.sillystone.info/categories/随笔/"}],"tags":[{"name":"文摘","slug":"文摘","permalink":"http://www.sillystone.info/tags/文摘/"},{"name":"鸡汤","slug":"鸡汤","permalink":"http://www.sillystone.info/tags/鸡汤/"}]},{"title":"严歌苓的文字","date":"2017-03-11T15:26:31.000Z","path":"2017/03/11/严歌苓的文字/","text":"述简洁的文字，不玩弄词藻，表达清晰而直接，具有冲击性心理/思想描述很到位，也是她作品最吸引人的地方故事叙述的切入也是其文字特点，快速切入，却不影响连贯性很佩服她可以把心理和性格表达的如此流畅作品把人物的丰富情感和现实的生活间的冲突和结合展示的很到位 作品已读：《小姨多鹤》 人物性格到位，多鹤，小环，张检，张钢的刻画栩栩如生，折射出时代背景和民族性格 结尾感觉有些局促和拖拉，对于张铁的刻画不够清晰，结局似乎无亮点无冲击。《寄居者》 喜欢她的文字始于这本书，民族性格的展现以及人物道德底线的冲击是本书的精华《霜降》 和上边作品相比算是短篇，小环境，小人物，故事完整性很好。《天浴》 尾好的作品不多，好的作者更少，珍惜佳作","categories":[{"name":"随笔","slug":"随笔","permalink":"http://www.sillystone.info/categories/随笔/"}],"tags":[{"name":"日记","slug":"日记","permalink":"http://www.sillystone.info/tags/日记/"}]},{"title":"浅谈银行系统-渠道类系统","date":"2017-03-11T01:18:00.000Z","path":"2017/03/11/浅谈银行系统-渠道类系统/","text":"概述银行的渠道类系统按照先后发展有以下几类： 传统渠道：柜面 电话 ATM 网银 银企直连新兴渠道：手机 微信（企业号，小程序） 自助银行 智能终端设备 对客接入点先后经历了：实体网点，自助设备，电话银行，网银，手机等智能设备伴随着智能设备的普及和安全技术以及大众的认知改变，客户接入渠道逐渐转向智能设备对客服务方式也逐渐转变。 银行的渠道不仅是服务客户的接入点，同时也是银行营销的途径，随着零售业务的发展，各银行都很重视各种渠道的客户获取和产品营销，获客渠道也逐渐成为各家银行的一个重要渠道系统；这也成就了目前互联网公司和银行的合作，同时银行的产品也通过第三方互联网公司开展营销，这其中包含：渠道与信誉的整合，利益分割，资源积累，公司发展策略 直销银行：主要通过互联网渠道提供高效，便捷，有特色的服务。主要营收可以依赖于：贷款， 金融产品收益。贷款产品主要是信用贷，和阿里等公司的产品同质，如无特色很难超越金融产品创新，主要包括金融超市直营方式销售金融产品，需要有特色的金融产品扩展用户 渠道类系统(待完善)柜面网银手机银行微信银行渠道整合渠道技术主题安全","categories":[{"name":"金融","slug":"金融","permalink":"http://www.sillystone.info/categories/金融/"}],"tags":[{"name":"金融","slug":"金融","permalink":"http://www.sillystone.info/tags/金融/"},{"name":"银行","slug":"银行","permalink":"http://www.sillystone.info/tags/银行/"},{"name":"技术","slug":"技术","permalink":"http://www.sillystone.info/tags/技术/"}]},{"title":"项目管理之夕会","date":"2017-03-09T13:14:01.000Z","path":"2017/03/09/项目管理之夕会/","text":"近期项目管理过程中使用了 夕会 ，总结如下： 适用场景 项目团队成员较多，各自分工不同，互相间的工作有依赖或者有借鉴之处项目实施沟通交流效率不高，问题解决效率不高项目处于联调等需要紧密沟通，快速响应阶段解决成员工作效率低，质量低，降低项目进度风险 前提 项目整体计划明确，成员的每日工作目标明确项目管理成员持续跟踪项目进展，跟踪问题，收集反馈，更新问题解决进展收集整理夕会要点 要求 参会人员准时参加会议要点描述清晰准确会议时间尽量短 步骤 项目经理（项目跟踪人）讲述跟踪问题的进展，明确问题的责任人和完成计划与会人员可对跟踪问题的提意见/建议，但不展开讨论与会人员补充：待跟进事项，会上明确责任人和反馈时间与会人员向大家通知重要决策和决定 产出物：跟踪事项要点 责任人时间职责交付物 补充夕会 是日计划的一部分，与之对应的有 晨会，晨会主要明确成员的当日工作目标 日计划主要用于项目经理跟踪计划的完成度和完成质量，保证项目的关键任务及时完成 夕会 主要用于日计划的总结，问题的跟踪，明确人员职责","categories":[{"name":"管理","slug":"管理","permalink":"http://www.sillystone.info/categories/管理/"}],"tags":[{"name":"项目管理","slug":"项目管理","permalink":"http://www.sillystone.info/tags/项目管理/"},{"name":"夕会","slug":"夕会","permalink":"http://www.sillystone.info/tags/夕会/"}]},{"title":"吹风","date":"2017-03-05T09:40:03.000Z","path":"2017/03/05/吹风/","text":"屋里空荡荡 心中也空空的 阳光很好 风很大 有蓝天，有白云 背起相机 卸下思念 随手采几张照片 只为填满时间 大图，慎点","categories":[{"name":"摄影","slug":"摄影","permalink":"http://www.sillystone.info/categories/摄影/"}],"tags":[{"name":"摄影","slug":"摄影","permalink":"http://www.sillystone.info/tags/摄影/"}]},{"title":"养鱼记","date":"2017-03-04T01:19:51.000Z","path":"2017/03/04/养鱼记/","text":"我是一只离开水的鱼深夜里 我独自一人 在狭小水缸 思念着你 回忆着 一次又一次 拼尽全力 奇迹般的飞跃 向着美好的希望 只为你 无力的呼吸着 希望越来越远 心越来越静 空气很薄 你在哪儿 孔雀鱼今天发现有一条孔雀鱼总是偷袭其他鱼的尾巴，鱼缸里的大鱼也不放过，被他追的到处跑，看着好滑稽，百度了一下，说是有可能发情期，也可能其他鱼得病了。为了保全其他鱼的尾巴，只能把他隔离了；它游的好快，弄了半天才捞出来 悲剧的是，今天早上发现它不在小鱼缸里，最终发现在离鱼缸挺远的地上，已经变成鱼干了水面上有5/6厘米的高度，不知道怎么跳出来的。 那拼尽全力的一跃，垂死的挣扎，从阳台上坠落，爬了那么远，最终张着嘴却没有呼吸没有结果的结果","categories":[{"name":"随笔","slug":"随笔","permalink":"http://www.sillystone.info/categories/随笔/"}],"tags":[{"name":"诗","slug":"诗","permalink":"http://www.sillystone.info/tags/诗/"}]},{"title":"Sublime Text Tip","date":"2017-03-02T12:31:38.000Z","path":"2017/03/02/Sublime-Tip/","text":"定位 文件定位 CTRL + P 词语定位 CTRL + ; 函数定位 CTRL + R 行号定位 CTRL + G 合并选中的多行代码为一行 CTRL + J 快速折叠文件内所有函数 CTRL + K + 1 编辑 选择一个选中项的下一个匹配项，连续选中相同匹配项 CTRL + D 【MAC：⌘ + D】 选择一个选中项的所有匹配项 ALT + F3 【MAC：CTRL +⌘ + G】 选择与光标关联的开始和结束标签 CTRL + SHIFT + ` 【MAC：⌘+⇧+ K】 按内容层次选择内容，连续使用，选择内容逐渐扩大 CTRL + SHIFT + A 【MAC： CTRL + D】 按括号逐层选择内容，CTRL + SHIFT + M 【MAC：⌘ + ⇧ + Space】 复制行&amp; 复制选中的内容 CTRL + SHIFT + D 【MAC：⌘ + ⇧ + D】 增加 减少缩进 CTRL + [或] 【MAC：⌘ + [ 或 ]】 粘贴并保持缩进 CTRL + SHIFT + V 【MAC：⇧ + ⌘ + V】 用标签包裹行 alt+shift+w 【MAC：CTRL + ⇧ + W】 删除父标签 ctrl+shift+; 【MAC：⌘ + ‘】 计算数学表达式 ctrl+shift+y 【MAC：⌘ + ⇧ + Y】 数字自动增减，10为单位 alt+shift+↑ 或 ↓，ctrl+ ↑ 或 ↓ 【MAC：⇧+OPTION + ↑】 大小写 ctrl+k+u,ctrl+k+l 【MAC： ⌘ + K then U, ⌘ + K then L】 安装package： ctrl + shift + p","categories":[{"name":"技术","slug":"技术","permalink":"http://www.sillystone.info/categories/技术/"}],"tags":[{"name":"开发工具","slug":"开发工具","permalink":"http://www.sillystone.info/tags/开发工具/"},{"name":"IDE","slug":"IDE","permalink":"http://www.sillystone.info/tags/IDE/"}]},{"title":"零开始学coding","date":"2017-02-28T14:24:31.000Z","path":"2017/02/28/零开始学coding/","text":"最近学习前端的相关知识，感觉前端知识太多，变化太快，新的技术和组件，甚至是工具变化都很快，感觉学习前端要学好多东西，全栈工程师不容易啊，github上好多国内的高手推荐一个网站：FreeCodeCamp 中文网站： FreeCodeCamp中文网站是从知乎：零基础的前端开发初学者应如何系统地学习看到的，试了一下感觉还不错，交互做的不错。 适合初学者，用来教小朋友也可以。 对于有代码经验的，开始的步骤有些繁琐。 只进行了一部分，不知道后边关于nodejs怎么讲解的","categories":[{"name":"技术","slug":"技术","permalink":"http://www.sillystone.info/categories/技术/"}],"tags":[{"name":"编码，学习","slug":"编码，学习","permalink":"http://www.sillystone.info/tags/编码，学习/"}]},{"title":"难得北京蓝","date":"2017-02-25T13:22:42.000Z","path":"2017/02/25/难得北京蓝/","text":"北京蓝遇上ofo周末活动，回归街拍生活 图片较大,请在wifi环境查看 据说 姚振华 最近很火，来张宝能大厦","categories":[{"name":"摄影","slug":"摄影","permalink":"http://www.sillystone.info/categories/摄影/"}],"tags":[{"name":"摄影","slug":"摄影","permalink":"http://www.sillystone.info/tags/摄影/"},{"name":"街拍","slug":"街拍","permalink":"http://www.sillystone.info/tags/街拍/"}]},{"title":"真","date":"2017-02-25T11:51:16.000Z","path":"2017/02/25/真/","text":"严歌苓 《霜降》 述认识 严歌苓 是从她的作品 《寄居者》 开始，她的小说大多是描述特定的时代，建国前后，人命如草，道德模糊，故事不断。 霜降 是个农村进京的漂亮小姑娘，进了程家的大院，进了一个她奢望但无法进入的阶层。那个年代所有人都被禁锢着，不只是 霜降 这样的小民，也包括大院里的所有人。每个人都无法跑出那个时代，四星 或许最终成功了，出国了。 书的封面讲述了 霜降 的故事 爱，在若有似无的触碰中绝望冬，将临近幸福，如履薄冰。。。。 真 原来爱与过活是两回事，爱一定要过渡到过活才能自然长久地存在下去，过活却不需要爱，过活自身是独立和成熟的，因此它自身能够自然长久地存在。过活不需要你挺累地将目光弄得曲折，将笑摆得那么巧。过活是大米饭，你饿，它结实地填饱你，朴实得让人感动。 真，就是你在眼前，陪伴比爱更直接 引 一个曾经被牢记的人，被人忘记是挺惨的一件事他站在窗前，好似一缕魂看着人间长长一段宁静淡然成了虚伪伦理报复了道德，喜剧报复了悲剧，冤孽报复了冤孽","categories":[{"name":"随笔","slug":"随笔","permalink":"http://www.sillystone.info/categories/随笔/"}],"tags":[{"name":"日记","slug":"日记","permalink":"http://www.sillystone.info/tags/日记/"},{"name":"读后感","slug":"读后感","permalink":"http://www.sillystone.info/tags/读后感/"}]},{"title":"记忆","date":"2017-02-22T16:00:00.000Z","path":"2017/02/23/记忆/","text":"读 村田喜代子 《八口小锅》 锅中 有感 孩子们发掘奶奶记忆的故事一直在农村生活的奶奶虽然身体健康，但记性却很糟糕，记忆总是忽然被触动，又很快淡去故事里的奶奶一直独自居住在村子里，八十岁的她在享受自己的最后时光，对生活似乎没有更多的要求，只是静静的过好每一天，忙碌于生活琐事，间歇努力找寻曾经的回忆。几个孙辈孩子们的到来给她带来很多快乐，当然也触动她久远的回忆，那里有逝去的亲人和他们的子女，那里有清晰的呼唤和模糊的面孔，多年感情在记忆闪现的瞬间澎湃不已，搅动起难以平息的痛。 忙碌的我们基本没有时间思考生命，时光，过去的回忆，直到我们老去 故事里慈祥、安静的奶奶和孩子们的快乐日子让我羡慕不已， 我的这片感情是空白 乡村生活，小菜园子，池塘，庙，大树，青蛙，蚂蚁，好怀念小时候的日子 文中的多美 是个会做菜的孩子，口水流不停啊 摘一段文字 我曾想某一天将奶奶脑子里的情形一探究竟，看看这几十年的记忆是以怎样的形式重叠起来。那时候可能会看到雾气之类的笼罩在这些记忆上。但是，我可以推想，古老的记忆现在就像这些相片一样已经是丢失了专有名词、失去了前后关联、犹如零散胶卷的东西了。 自然就像一个深不见底的大碗。。。。我想","categories":[{"name":"随笔","slug":"随笔","permalink":"http://www.sillystone.info/categories/随笔/"}],"tags":[{"name":"日记","slug":"日记","permalink":"http://www.sillystone.info/tags/日记/"},{"name":"读后感","slug":"读后感","permalink":"http://www.sillystone.info/tags/读后感/"}]}]